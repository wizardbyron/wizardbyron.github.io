<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>流量测试 on 顾宇的研习笔记</title>
    <link>https://www.guyu.me/tags/%E6%B5%81%E9%87%8F%E6%B5%8B%E8%AF%95/</link>
    <description>Recent content in 流量测试 on 顾宇的研习笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 08 Aug 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.guyu.me/tags/%E6%B5%81%E9%87%8F%E6%B5%8B%E8%AF%95/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>公有云(AWS)上的生产环境架构优化案例和迁移套路总结</title>
      <link>https://www.guyu.me/2018/2018-08-08-architecutre-optimization-case-study/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-08-08-architecutre-optimization-case-study/</guid>
      <description>本文是我在 gitchat 上的文章云计算生产环境架构性能调优和迁移套路总结（以 AWS 为例）的后半部分，本文对原文有所修改和总结。交流实录请点击这里。
在AWS 上的生产环境性能分析案例一文中，记录了我对客户应用生产环境的一次性能分析。接下来，我们要根据所发现的性能问题进行架构优化，以提升可用性和性能。同时，这篇文章也总结了应用迁移到云上的套路。
设计云计算平台迁移计划和方案 将应用程序迁移到云计算平台上主要的目的是把自行构建的高风险高成本应用以及组件替换为云计算平台上的高可靠性低成本组件/服务。
应用架构的迁移有两种方案：
一种是整体一次性迁移，即重新实现一个架构并完成部署，然后通过金丝雀发布或者蓝绿发布切换。这种方式的好处是简单，直接，有效，一开始就能按照最佳实践构建应用架构。而且对于现有系统来说影响不大。但如果方案没设计好，容易造成高级别的风险，所以应当进行大量的测试以确保可靠性。
另一种是持续部分迁移，每次引入一点风险，保证风险可控，但缺点就是优化步骤较多。虽然持续部分迁移步骤多，但是总体时间并不一定会比整体迁移更高。
注意：由于自动化基础设施和架构设计会带来一些副作用，特别是配置间的耦合。因此，对于生产环境的直接优化要慎用自动化。如果一定要用，请务必在测试环境上做好测试。但如果你能做到自动化并且有完好的测试，不如直接做整体一次性迁移方案得了。
一般说来，一个完整的云平台迁移方案会分为以下三大阶段：
第一阶段：构建高可用架构以实施水平扩展，从而保证了应用的稳定运行。
第二阶段：引入 APM 并根据 APM 数据进行定向优化，采用云计算的服务来优化应用的资源使用。
第三阶段：构建应用端的持续部署，构建 DevOps 的工作模式。
这三个阶段是大的顺序，而每个大的阶段里又会相互掺杂一些其它阶段的内容。但无论什么样的迁移方案，一定要通过度量进行风险/收益比排序，最先完成代价最小，收益最大的内容。
第一阶段：构建高可用架构 我们之前说过，一个应用架构的第一追求就是业务的连续性和抗风险能力。一个高可用的架构能够在你的应用面对压力的时候从容不迫。因为如果资源满负荷运转，新的请求会因为没有可用资源而导致排队。这是常见的停机或者性能降低的原因。这就是 AFK 扩展矩阵常说的 X 轴扩展：通过复制自己扩展资源从而达到降低排队等待的时间。此外，水平扩展出来的机器同样也是一个预留资源，能够提高应用的可用性。应用架构不仅仅是应用程序的事情，也包含着资源的分配，二者是相辅相成的。
一般会经历如下几步：
 第一步，有状态和无状态分离 第二步，牲畜化（Cattlize）应用实例 第三步，自动化水平扩展（AutoScaling）  第一步：有状态和无状态分离 先回顾一下当前应用的架构 ： 状态分离的目标是把有状态的组件和无状态的组件分开，以便在做复制的时候降低不一致性。最简单的判定办法是：如果复制当前的虚拟资源，并通过负载均衡随机分配请求访问，哪些部分会造成不一致。
常见的有状态内容比如数据库，上传的文件。所以，我们要把它们独立出来。在“萨瓦迪卡”的例子中，我们首先把数据库独立了出来。如下图所示：
在这个过程中，我们采用 RDS 而不是另外一个 EC2 上构建一套 MySQL 来完成数据库的分离。最主要的原因就是 RDS 提供了更好的可用性和数据库维护支持，例如自动备份，更多的监控指标，更自动的数据库迁移和维护窗口等。我们采用 Aurora 引擎的 MySQL 模式，这可以将数据库做成一个集群并让另外一个只读分片，降低数据库的负担。
在分离数据库的时候，要注意以下几点：
 数据库分离的性能基线就是在同样的负载测试下，不能够比没分离之前更差。 数据库的网络建立在一个私有的子网中，除了应用子网内的 IP 不能访问数据库，从而提高安全性。 构建一个私有域名来访问数据库，这样可以固定应用的内部配置，减少对配置的修改。同时也给外部切换数据库主备等留下了更灵活的空间。 注意对原有数据库 MySQL 配置信息的复制，这会导致很大程度上的性能差异。 对于数据较大的数据库启动而言，会有一个几分钟的热身（Warm up）时间，这会导致性能下降。所以，做切换的时候提前启动数据库以做好准备。 不要用默认的 root 账户作为应用的访问账户。 由于 RDS 可以在不影响数据完整性和一致性的情况下降低使用配置，在最开始的时候采用较高的配置。随着优化的不断进行，可以采用维护时间窗口（Maintenance Time Window）在低流量时段对 RDS 实例的配置进行降级，以节约成本。  完成了数据库的隔离，我们就可以依法炮制文件的隔离了。最简单有效的方案是把文件存储在对象存储服务中。AWS S3 就是这样一种服务。避免自己构建共享文件系统或者共享存储设备。</description>
    </item>
    
    <item>
      <title>公有云(AWS)上的生产环境性能分析案例</title>
      <link>https://www.guyu.me/2018/2018-08-07-performance-analysis-case-study/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-08-07-performance-analysis-case-study/</guid>
      <description>本文是我在 gitchat 上的文章云计算生产环境架构性能调优和迁移套路总结（以 AWS 为例）的前半部分，本文对原文有所修改和总结。交流实录请点击这里。
案例背景 案例是一个泰国网站的生产环境（请脑补一句“萨瓦迪卡”，为了叙述方便，下文中均以&amp;rdquo;萨瓦迪卡&amp;rdquo;指代这个网站。）“萨瓦迪卡”是一个 采用 Wordpress + MySQL搭建的应用。这个遗留系统已经工作了五年。客户已经把在其它 VPS 上平移到 AWS 上。平移（lift and shift）是说原样复制，而迁移（migration）还要进行改造。而客户唯一发挥 AWS 优势的一点就是用了一个配置很高的 EC2 虚拟机 —— m4.4xlarge。这样一台配置的虚拟机有 16 个虚拟 CPU，64 GiB 的内存，以及 2000 Mbps 的网络带宽，最高 3000 IOPS 的 200GiB 的块存储设备（也就是硬盘）。
知识点： GiB 是用二进制计算的，GB 是用十进制计算的。1 GiB 是 2的30 次方，而1 GB 是10 的 9 次方，1 GiB 略大于 1GB。 而且，AWS 的 FreeTier 免费计划是按 GB 计算的哦！
除了基本的网络和虚拟机以外，“萨瓦迪卡” 的所有东西都放在一台虚拟机上。没错，是所有东西——Web 服务器，反向代理，数据库，上传的文件——都放在一台虚拟机上。唯一个一个负载均衡用来承载 HTTPS 证书，没有使用集群，没有高可用，没有数据库/应用分离，没有防火墙，没有 WAF，没有 APM，没有 CDN 而且，没有持续交付流水线，所有部署都要 ssh 到机器上进行操作。如图所示：</description>
    </item>
    
    <item>
      <title>一怒之下，我又写了一个开源流量测试工具</title>
      <link>https://www.guyu.me/2018/2018-07-07-why-do-i-write-wade/</link>
      <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-07-07-why-do-i-write-wade/</guid>
      <description>继一怒之下我写出了 Vivian（详见“测试驱动开发 Nginx 配置”）之后。又在等待客户审批流程的时间里自己写了一个流量测试工具。
背景 客户的站点是通过 Wordpress 搭建的，这个应用放在一台 EC2 虚拟机上。奇葩的是，这个应用的 MySQL 数据库也在这台虚拟机上，之前做过一次 RDS 迁移，失败了，原因未知。看起来这个应用和数据库就像筷子兄弟一样，不离不弃，而且没有办法通过 AutoScaling Group 进行水平扩展。也就是说，所有的东西都在一台虚拟机上。
我所要做的，就是把这个架构重新变成可自动水平扩展且高可用高性能有缓存低消耗具备监控和更加安全且有版本控制并可以通过持续交付流水线来半自动部署的架构。你可以重新读一下上一句加粗文字的内容。没错，目前他们连版本控制都没有，所有的操作在服务器上通过 mv 之间 scp 进行。
很不巧的时候，这个“筷子兄弟”应用在上周开始，晚上随机的 Down 机，表现为数据库被删。但通过日志可以发现，是由于内存资源不足导致的 MySQL 数据引擎加载不了导致的。
由于需要做“筷子兄弟”拆分手术，目的是要把数据库和应用程序分开，并且需要进行一些服务的重启和拆分。这些操作中会导致停机时间，为了能够度量这个停机时间，便于做出更好的决策，客户希望在测试环境上能够通过模拟生产环境的工作状态来完成这个任务。我设计了方案，包括以下几点：
 知道每一个可能引起停机的操作引起停机的时长。 测试 RDS 能带来多少的性能提升。 找出整个架构引起停机的根本问题。 在 500 个并发用户访问的情况下，会出现的性能拐点。 能够度量应用的资源损耗。  客户已经购买了 NewRelic 和 Flood.io （我在 17 期技术雷达里提交的条目，叉会腰。）但是 Flood.io 的账号分配需要一个额外的审批才可以使用，也就是说，我得等到第二天才能使用。
我想，也许 github 上会有这样的工具能够满足我这个简单的需求，搜了一圈，没有合适的。
于是，一怒之下，我用了大概两个小时的时间用 Python 编写了这样一个测试工具。
工具的设计  There are only two hard things in Computer Science: cache invalidation and naming things.</description>
    </item>
    
    <item>
      <title>测试驱动开发 Nginx 配置</title>
      <link>https://www.guyu.me/2018/2018-06-12-tdd-in-nginx/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.guyu.me/2018/2018-06-12-tdd-in-nginx/</guid>
      <description>2017年中，我参与了一个亚太地区互联网公司并购的项目，客户收购了亚太地区 7 个国家的同行业互联网企业和产品。我作为其中的 DevOps 咨询师和 DevOps 工程师，和客户一起完成并购后的产品迁移和技术能力提升的设计、实施和培训。
客户希望采用新的统一产品，并根据不同地区的业务特色进行一些定制，与此同时，需要进行数据迁移以保证业务可以继续运行。其中一个很关键的步骤是把原系统的 URL 通过重定向的方式到新的产品中，因为有很多的第三方链接和搜索引擎依然保留了原系统中的链接。
初步统计了一下，将近有3000多个 URL 需要重定向，光是规则和正则表达式就写了 400 多条（没有统一模式的 URL 害死人啊），这就引发了一个问题：我该如何验证这些规则和覆盖这些 URL ？此外，大量的重定向不光对用户来讲不是很好的体验，如果我要优化这些规则，我如何保证我当前的转发规则不被破坏？
解决方案 最早，我们写了一个 Shell 脚本，用 curl命令来验证这些 URL，最初只需要验证 200 条就可以满足需求，时间也不到两分钟。后来，我们采用了一个 Excel 文件来跟踪这些 URL，产品经理只需要把新的重定向 URL 补充到上面，我们就依据这些 URL 来开发 nginx 的重定向规则。
这让我想到了 TDD：先写出一个自动化测试用例，然后修复这个自动化测试用例。更好的是，有了自动化的测试做保护，你可以放心和安全的对代码进行重构。
此外，随着更多的 URL 需要重定向，这个数字在不断的增加。原先的 Shell 脚本执行的时间也从最初的 2 分钟增长到了15分钟。
现有的工具满足不了要求，一怒之下，我决定开发一个自己的工具。它必须具备以下特点：
 可以通过文件读取规则，进行大批量验证。 多线程并发执行，可以提升效率。 很容易和 CI 集成。 能帮我做一定程度的重定向优化分析。  于是，我在一个周末的时间用 Python 写下了 vivian： 一个多线程的批量自动化重定向验证工具。
它把原先的 15 分钟的验证时间缩短到了 17 秒，效率提升了 5294 % !!
此外，我把测试用例集成到了代码库里。并把 vivian 提交到了 pipy，这样我就可以通过 pip 在初始化 CI 上安装了。也无需增加到代码库里变成一个需要维护的代码脚本。</description>
    </item>
    
  </channel>
</rss>